{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1a060b-286d-4cb6-be93-67ed7fa5b06a",
   "metadata": {},
   "source": [
    "Many of the posters have the column \"HIGHLIGHTED THEME (OPTIONAL)\" filled with values (breakdown as follows). There are also quite a few posters with blank themes. We use the LLM generated embeddings for each poster (title + abstract) as features, use the posters with themes as training data, and predict the themes for those posters with blank theme column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0d5c6e-2d07-4bd1-876b-daa3eedb6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c43585-4e77-41d8-a4b9-b5061082f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('accepted_poster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e75e77-64cb-4b67-b9a0-2e06dc8e566c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HIGHLIGHTED THEME (OPTIONAL)\n",
       "Harnessing the Power of Large Language Models in Health Data Science                                            29\n",
       "Real-World Evidence in Informatics: Bridging the Gap between Research and Practice                              26\n",
       "Implementation Science and Deployment in Informatics: From Theory to Practice                                   15\n",
       "Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics               14\n",
       "Integrating Multi-Modal health Data to Enhance the Power of Informatics                                         13\n",
       "Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation            8\n",
       "Proactive Machine Learning in Biomedical Applications: The Power of Generative AI and Reinforcement Learning     4\n",
       "Citizen Science and Democratizing AI and Informatics for Healthcare                                              2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HIGHLIGHTED THEME (OPTIONAL)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fdd8ca4-6764-481b-b4b3-5e2d11eef93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "themed = df[df['HIGHLIGHTED THEME (OPTIONAL)'].notna()]\n",
    "unthemed = df[df['HIGHLIGHTED THEME (OPTIONAL)'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1533d058-6e04-49ec-9507-3e510af59cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "themed_text = ('TITLE: ' + themed.submission_TITLE + 'ABSTRACT: '+themed.submission_ABSTRACT).tolist()\n",
    "unthemed_text = ('TITLE: ' + unthemed.submission_TITLE + 'ABSTRACT: '+unthemed.submission_ABSTRACT).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0ed3f6-b7e1-453b-8a17-bcdb3aa75c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c901e2-6299-4a88-a2d2-354201a6d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "themed.loc[:,'label'] = label_encoder.fit_transform(themed['HIGHLIGHTED THEME (OPTIONAL)'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843cffec-52e3-4777-89d1-f4b742dd8d4b",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcecde7d-0a95-4237-bbb1-88914260caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.openai.com/v1/embeddings\"\n",
    "access_token = \"sk-xxx\" # please replace with your openai token\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {access_token}'\n",
    "}\n",
    "\n",
    "\n",
    "def get_GPT_embedding(txt):\n",
    "    return requests.post(url, headers=headers, json={\n",
    "        \"input\": txt,\n",
    "        \"model\": \"text-embedding-ada-002\"}).json()['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc999eb-0772-4062-8f65-0fb18fbda3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 111/111 [00:32<00:00,  3.38it/s]\n",
      "100%|███████████████████████████████████████████| 59/59 [00:18<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "themed_gpt_embed = [get_GPT_embedding(t) for t in tqdm(themed_text)]\n",
    "unthemed_gpt_embed = [get_GPT_embedding(t) for t in tqdm(unthemed_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ac7bc3f-e480-499d-a50e-9f2fcb5e9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(themed_gpt_embed, themed.label.tolist())\n",
    "unthemed.loc[:,'label'] = knn.predict(unthemed_gpt_embed)\n",
    "unthemed.loc[:,'GPT_theme'] = label_encoder.inverse_transform(unthemed.loc[:,'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94646389-f6fd-494e-b860-31a2dbbf8171",
   "metadata": {},
   "source": [
    "# Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03033885-4e74-4bee-9be6-2f819dcddcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b294cfff6c34125b55fa8871681ae85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_id = 'SeanLee97/angle-llama-7b-nli-v2'\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/HF/'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, cache_dir=\"/data/HF/\", do_sample=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, cache_dir=\"/data/HF/\", do_sample=True).bfloat16().cuda()\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, cache_dir=\"/data/HF/\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "261cb0da-d92a-40a8-baf5-5e430925bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_embedding(txt):\n",
    "    tok = tokenizer([txt], return_tensors='pt')\n",
    "    for k, v in tok.items():\n",
    "        tok[k] = v.cuda()\n",
    "    return model(output_hidden_states=True, **tok).hidden_states[-1][:, -1].float().detach().cpu().numpy()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d006cadd-4d45-4cd8-ae77-8d93d2e64e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 111/111 [00:41<00:00,  2.71it/s]\n",
      "100%|███████████████████████████████████████████| 59/59 [00:21<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "themed_llama_embed = [get_llama_embedding(t) for t in tqdm(themed_text)]\n",
    "unthemed_llama_embed = [get_llama_embedding(t) for t in tqdm(unthemed_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c58da0e1-761e-46cb-8e25-1202cf767106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(themed_llama_embed, themed.label.tolist())\n",
    "unthemed.loc[:,'label'] = knn.predict(unthemed_llama_embed)\n",
    "unthemed.loc[:,'llama_theme'] = label_encoder.inverse_transform(unthemed.loc[:,'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08857812-0568-48a2-8cb9-2ba9bac6a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(unthemed[['row_id','GPT_theme', 'llama_theme']], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568cea98-df57-46e5-b543-5c99dae5c188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
