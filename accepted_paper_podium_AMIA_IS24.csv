submission_TITLE,submission_ABSTRACT,KEYWORDS_SELECTION
An Explainable Artificial Intelligence-enabled ECG Framework for the Prediction of Subclinical Coronary Atherosclerosis,"Coronary artery calcium (CAC) as assessed by computed tomography (CT) is a marker of subclinical coronary atherosclerosis. However, routine application of CAC scoring via CT is limited by high costs and accessibility. An electrocardiogram (ECG) is a widely-used, sensitive, cost-effective, non-invasive, and radiation-free diagnostic tool. Considering this, if artificial intelligence (AI)-enabled electrocardiograms (ECGs) could opportunistically detect CAC, it would be particularly beneficial for the asymptomatic or subclinical populations, acting as an initial screening measure, paving the way for further confirmatory tests and preventive strategies, a step ahead of conventional practices. With this aim, we developed an AI-enabled ECG framework that not only predicts a CAC score =400 but also offers a visual explanation of the associated potential morphological ECG changes, and tested its efficacy on individuals undergoing health checkups, a group primarily comprising healthy or subclinical individuals. To ensure broader applicability, we performed external validation at a separate institution.","['Data-driven research and discovery', 'Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling']"
Investigating Cross-Domain Binary Relation Classification in Clinical Natural Language Processing,"This paper addresses the challenge of binary relation classification in clinical Natural Language Processing (NLP), focusing on diverse domains including gene-disease associations, compound protein interactions, and social determinants of health (SDOH). We evaluate different approaches, including fine-tuning Bidirectional Encoder Representations from Transformers (BERT) models and generative Large Language Models (LLMs), and examine their performance in zero and few-shot settings. We also introduce a novel dataset of clinical text annotated with social and clinical entities to facilitate research into relation classification. Our results underscore the continued complexity of this task for both humans and models. BERT-based models trained on domain-specific data excelled in certain domains and achieved comparable performance and generalization power to generative LLMs in others. Despite these encouraging results, these models are still far from achieving human-level performance. We also highlight the significance of high-quality training data and domain-specific fine-tuning on the performance of all the considered models.","['Natural Language Processing', 'Social determinants of health', 'Machine learning and predictive modeling']"
Uncertainty-Aware Deep Learning Differentiates Cancers of the Central Nervous System -- A Multi-Center Study,"Glioblastoma and primary central nervous system lymphoma (PCNSL) have overlapping pathology profiles but require different treatments. To address this clinical challenge, we developed the Pathology Image Characterization Tool with Uncertainty-aware Rapid Evaluation (PICTURE) using 4,135 pathology slides from multiple hospitals. Leveraging uncertainty quantification, PICTURE distinguished glioblastoma and PCNSL with expert-level performance and flagged rare brain cancers that are neither glioblastoma nor PCNSL. Our approaches provide a generalizable machine learning framework for rapid pathology diagnosis.","['Medical Imaging', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
Healthcare Utilization is an Important Methodological Consideration for EHR-based Association Analyses,"Association analyses using electronic health records (EHRs) can uncover risk factors for medical conditions. However, patients with these medical conditions often have increased healthcare utilization, which can lead to increased incidental diagnoses, thereby potentially inflating estimated associations. Here, we analyze how controlling for healthcare utilization impacts association results for recurrent pregnancy loss from two independent medical centers. While utilization substantially affected one center's results, inter-center validation identified associations that were robust across center-specific utilization patterns.","['Phenomics and phenome-wide association studies', 'Secondary use of EHR data', 'Data mining and knowledge discovery']"
Development and Validation of a Smartphone App for Automated Knee Range of Motion Measurement in a Clinical Setting,"Knee range of motion (ROM) analysis has been a longstanding diagnostic tool employed to assess functionality and ability of the knee joint to move through its full range of motion. This type of analysis is often performed by a healthcare provider, physical therapist, or orthopedic surgeon either visually or with the assistance of a goniometer. While in the preoperative setting, knee range of motion analysis can help determine an appropriate surgical approach, in the postoperative setting, it can be used to monitor the patient's progress and ensure that the surgical intervention has been successful. However, a list of patients particularly from underserved communities may not be able to accurately assess their knee ROM outside of a clinical setting in comparison to a healthcare professional cite{ref3}. Thus, a smartphone application that provides patients with the ability to assess their knee ROM offers a more accessible method to regaining function and enhances health equity, providing a convenient way to access exercises, track progress, and communicate with healthcare providers. The purpose of this study is to validate a smartphone application that has been developed to measure knee ROM automatically and objectively. The study will compare the accuracy of the smartphone app to traditional methods of measuring knee ROM, including visual-based and goniometer-based measurements.","['Public health informatics', 'Mobile Health, wearable devices and patient-generated health data', 'Advanced data visualization tools and techniques']"
Discovering Intersectional Sociodemographic Risk of Child Maltreatment during Child Welfare Using Competing Event Machine Learning Models,"Child maltreatment is a critical issue with far-reaching consequences. Four competing risk machine learning models to predict first maltreatment during child welfare were compared: cause-specific hazard regressions, subdistribution hazard regressions, random survival forest, and dynamic DeepHit. The Random Survival Forest performed best, and it revealed that institutional bias goes beyond race and involves intricate interactions involving race, socio-economic status, and rural/urban conditions. This insight informs the development of more precise and equitable intervention strategies.","['Public health informatics', 'Machine learning and predictive modeling', 'Ethical, legal, and social issues']"
Clean noisy training labels with inductive conformal prediction in multi-modal biomedical data mining,"Labeling biomedical data accurately remains a challenging endeavor. Traditional semi-supervised learning methods often fail to fully harness the potential of available unlabeled data. In response, we introduce an innovative approach centered on reliability-based training data cleaning, incorporating inductive conformal prediction (ICP). This method capitalizes on a limited set of precisely labeled training data and exploits the reliability metrics computed by ICP to rectify mislabeled data points and outliers within extensive, noisy training datasets. To gauge the effectiveness of our approach, we conducted experiments across three classification tasks spanning diverse modalities: filtering drug-induced liver injury (DILI) literature based on title and abstract; predicting ICU admission of COVID-19 patients by employing CT radiomics and electronic health records; subtyping breast cancer through RNA-sequencing data. We systematically introduced varying degrees of noise to the training labels through label permutation. The results reveal substantial enhancements in classification performance: an increase in accuracy across 86 out of 96 DILI experiments (up to 11.4%), improvements in AUROC and AUPRC in all 48 COVID-19 experiments (up to 23.8% and 69.8%, respectively), and enhancements in accuracy and macro-average F1 score in 47 out of 48 RNA-sequencing experiments (up to 74.6% and 89.0%, respectively). Our method presents the potential to significantly elevate classification performance in multi-modal biomedical machine learning tasks. Importantly, it achieves this without the need for an excessive volume of meticulously curated training data.","['Data mining and knowledge discovery', 'Natural Language Processing', 'Machine learning and predictive modeling']"
Automated HIV Case Identification from the MIMIC-IV Database,"Automatic HIV phenotyping is needed for HIV research based on electronic health records (EHRs). MIMIC-IV, an extension of MIMIC-III, contains more than 520,000 hospital admissions and has become a valuable EHR database for secondary medical research. However, there was no prior phenotyping algorithm to extract HIV cases from MIMIC-IV, which requires a comprehensive knowledge of the database. Moreover, previous HIV phenotyping algorithms did not consider the new HIV-1/HIV-2 antibody differentiation immunoassay tests that MIMIC-IV contains. Our work provided insight into the structure and data elements in MIMIC-IV and proposed a new HIV phenotyping algorithm to fill in these gaps. The results included MIMIC-IV's data tables and elements used, 1,781 and 1,843 HIV cases from MIMIC-IV's versions 0.4 and 2.1, respectively, and summary statistics of these two HIV case cohorts. They could be used for the development of statistical and machine learning models in future studies about the disease.","['Cohort discovery', 'EHR-based phenotyping', 'Secondary use of EHR data']"
Learning Phenotypic Associations for Parkinson's Disease with Longitudinal Clinical Records,"Parkinson's disease (PD) is associated with multiple clinical motor and non-motor manifestations. Understanding of PD etiologies has been informed by a growing number of genetic mutations and various fluid-based and brain imaging biomarkers. However, the mechanisms underlying its varied phenotypic features remain elusive. The present work introduces a data-driven approach for generating phenotypic association graphs for PD cohorts. Data collected by the Parkinson's Progression Markers Initiative (PPMI), the Parkinson's Disease Biomarkers Program (PDBP), and the Fox Investigation for New Discovery of Biomarkers (BioFIND) were analyzed by this approach to identify heterogeneous and longitudinal phenotypic associations that may provide insight into the pathology of this complex disease. Findings based on the phenotypic association graphs could improve understanding of longitudinal PD pathologies and how these relate to patient symptomology.","['Data mining and knowledge discovery', 'Data-driven research and discovery', 'EHR-based phenotyping']"
David (LLaMA) takes on Goliath (GPT-4) in an NLP Task of Extracting Adverse Drug Reactions from DailyMed,"We instruction-tuned LLaMA on the task of extracting adverse drug reactions from free text of DailyMed articles and compared that with a one-shot learning approach with InstructGPT and GPT-4. We found that parameter efficient fine-tuning (PEFT) and instruction-tuning approaches are highly effective and competitive, and are suitable for biomedical NLP tasks.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling']"
Pre-test Prediction of Non-ischemic Cardiomyopathies using Time-Series EHR Data,"Clinical imaging is an important diagnostic test to diagnose non-ischemic cardiomyopathies (NICM). However, accurate interpretation of imaging studies often requires readers to review patient histories, a time consuming and tedious task. We propose to use time-series analysis to predict the most likely NICMs using longitudinal electronic health records (EHR) as a pseudo-summary of EHR records. Time-series formatted EHR data can provide temporality information important towards accurate prediction of disease. Specifically, we leverage ICD-10 codes and various recurrent neural network architectures for predictive modeling. We trained our models on a large cohort of NICM patients who underwent cardiac magnetic resonance imaging (CMR) and a smaller cohort undergoing echocardiogram. The performance of the proposed technique achieved good micro-area under the curve (0.8357), F1 score (0.5708) and precision at 3 (0.8078) across all models for cardiac magnetic resonance imaging (CMR) but only moderate performance for transthoracic echocardiogram (TTE) of 0.6938, 0.4399 and 0.5864 respectively. We show that our model has the potential to provide accurate pre-test differential diagnosis, thereby potentially reducing clerical burden on physicians.","['Secondary use of EHR data', 'Medical Imaging', 'Machine learning and predictive modeling']"
Identify Repurposing Drugs with Reversal Gene Expression via Targeting Glioblastoma Expression Profile,"To address challenges in Glioblastoma (GBM) drug repurposing, we constructed a GBM expression profile from integrative analysis of transcriptomics and proteomics analysis, enabling identification of repurposing candidates. Our study identified 119 repurposing candidates and evaluated several repurposing candidates on their potential effect mechanism on GBM. We propose a promising strategy for unraveling GBM mechanisms and identifying repurposing candidates, extending insights into rare disease drug repurposing.","['Integrative omic analysis', 'Informatics research/biomedical informatics research methods', 'Drug discovery, repurposing, and side-effect discovery']"
Genome-wide DNA methylation profiling and identification of potential pan-cancer and tumor-specific biomarkers,"Aberrant DNA methylation is a hallmark of cancer making it a promising source of biomarkers, namely due to its stability, frequency, and accessibility in bodily fluids. The advent of minimally invasive methods such as liquid biopsies provide the perfect setting for methylation-based biomarker development and application. We developed a computational method to profile genome-wide methylation changes and identify both pan-cancer and type-specific markers for several cancer types, which we tested in a novel methylation assay.","['Biomarker discovery and development', 'Epigenomics', 'Machine learning and predictive modeling']"
Text and Audio Simplification: Human vs. ChatGPT,"Text and audio simplification to increase information comprehension are important in healthcare and with the introduction of ChatGPT, an evaluation of its simplification performance is needed. We provide a systematic comparison of human and ChatGPT simplified texts using fourteen metrics indicative of text difficulty. We briefly introduce our online editor where these simplification tools, including ChatGPT for simplification, are available. We scored twelve corpora using our metrics: six text, one audio, and five ChatGPT simplified corpora (using five different prompts). We compare these corpora with texts simplified and verified in a prior user study. Finally, a medical domain expert evaluated these texts and five, new ChatGPT simplifications. We found that simple corpora show higher similarity with the human simplified texts. ChatGPT simplification moves metrics in the right direction. The medical domain expert's evaluation showed a preference for the ChatGPT style, but the text itself was rated lower for content retention.","['Health literacy issues and solutions', 'Natural Language Processing', 'Health Information and biomedical data dissemination strategies']"
Enrichment Analysis and Unsupervised Clustering of Electronic Health Records Reveals Endometriosis Patient Subpopulations,"We apply enrichment analysis and unsupervised clustering to electronic health record (EHR) data from a large cohort of endometriosis patients to understand clinical associations and disease heterogeneity. We identify a wide array of diagnoses significantly enriched in cases and discover several distinct clusters of patients based on associated conditions. Our results confirm previous findings, lay groundwork for targeted investigations, and demonstrate how EHR data can dissect a complex disease at the clinical level.","['Data-driven research and discovery', 'EHR-based phenotyping', 'Secondary use of EHR data']"
Intracerebral Hemorrhage Segmentation: Leveraging Foundation Models for Specific Clinical Needs,"In this work we addressed the critical issue of intracerebral hemorrhage segmentation from NCCT scans by fine-tuning the Segment Anything Model providing just bounding box labels. The approach reduces manual labor, minimizes inter-operator variability, and demonstrates superior segmentation performance when compared to a conventional 3D-UNet model. This study underscores the potential of adapting foundation models for specific tasks in challenging contexts with limited data and resources, offering hope for addressing complex clinical scenarios.","['Medical Imaging', 'Bioimaging techniques and applications', 'Machine learning and predictive modeling']"
Leveraging GPT-4 for Identifying Clinical Phenotypes in Electronic Health Records,"This study evaluates OpenAI's GPT-4 model for identifying clinical phenotypes in non-small cell lung cancer patients from Electronic Health Records. Compared to scispaCy and medspaCy, GPT-4 achieves higher performance demonstrated by high F1 scores. GPT-3.5 performs similar to that of GPT-4. While rule-based models remain useful for some tasks, GPT models offer improved contextual understanding of the data, providing better insights into the clinical text and improving our ability to provide better care to patients.","['Natural Language Processing', 'EHR-based phenotyping', 'Data mining and knowledge discovery']"
Predicting Patient-Level Risk Associated with ECMO Utilizing the N3C Data Set,"Extracorporeal membrane oxygenation (ECMO) resource allocation in intensive care units lacks objective decision support tools, as evidenced during COVID-19 pandemic. We developed a multimodal predictive model incorporating static and time-series features from large high-resolution national database (N3C), outperforming all comparator models at all time-points up to 48-hours prior to extracorporeal use. Such models could provide the basis for clinically applicable decision support tools, derived from high-volume public repositories overcoming local data scale and content limitations.","['Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling']"
Enabling Semantic Topic Modeling on Twitter Using MetaMap,"Topic modeling performs poorly on short phrases or sentences and ever-changing slang, which are common in social media, such as X, formerly known as Twitter. This study investigates whether concept annotation tools such as MetaMap can enable topic modeling at the semantic level. Using tweets mentioning hydroxychloroquine for a case study, we extracted 56,017 posted between 03/01/2020-12/31/2021. The tweets were run through MetaMap to encode concepts with UMLS Concept Unique Identifiers (CUIs) and then we used Latent Dirichlet Allocation (LDA) to identify the optimal model for two datasets: 1) tweets with the original text and 2) tweets with the replaced CUIs. We found that the MetaMap LDA models outperformed the non-MetaMap models in terms of coherence and representativeness and identified topics timely relevant to social and political discussions. We concluded that integrating MetaMap to standardize tweets through UMLS concepts improved semantic topic modeling performance amidst noise in the text.","['Public health informatics', 'Natural Language Processing', 'Health Information and biomedical data dissemination strategies']"
Improving Clinical NLP Performance through Language Model-Generated Synthetic Clinical Data,"The challenge of building reliable pipelines for clinical natural language processing (NLP) often hinges on the availability of large expert-annotated datasets. Generating these datasets is time- and expertise-intensive, holding patient privacy and data sharing challenges. Our work explores new methods to release this bottleneck using synthetic data generated by large language models (LLM). Preliminary results show the promise of LLM-generated synthetic data to improve the performance and potential privacy concerns of clinical NLP methods.","['Natural Language Processing', 'Data quality', 'Clinical and research data collection, curation, preservation, or sharing']"
Inherently interpretable neural network with plausible explanations for ICU mortality prediction,"The study proposes a novel, inherently interpretable neural network architecture that predicts high-level concepts supervised by domain expert knowledge (SOFA organ-specific scores) as auxiliary tasks and uses them as units of explanation to predict longitudinal ICU mortality. The model performs at par with a baseline model without the explanations indicating no performance-explainability tradeoff. The explanations along with attention weights provide insights into which organ system failures can lead to future mortality.","['Data mining and knowledge discovery', 'Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling']"
CLASSify: A Web-Based Tool for Machine Learning,"Machine learning classification problems are widespread in bioinformatics, but the technical knowledge required to perform model training, optimization, and inference can prevent researchers from utilizing this technology. This article presents an automated tool for machine learning classification problems to simplify the process of training models and producing results while providing informative visualizations and insights into the data. This tool supports both binary and multiclass classification problems, and it provides access to a variety of models and methods. Synthetic data can be generated within the interface to fill missing values, balance class labels, or generate entirely new datasets. It also provides support for feature evaluation and generates explainability scores to indicate which features influence the output the most. We present CLASSify, an open-source tool for simplifying the user experience of solving classification problems without the need for knowledge of machine learning.","['Data-driven research and discovery', 'Machine learning and predictive modeling', 'Clinical and research data collection, curation, preservation, or sharing']"
Extraction of Chemotherapy Treatment Timelines from EHR Notes and Temporal Modeling of Cancer Treatment in Adult and Pediatric Patients,"Detailed information about tumor biology and effects of chemotherapy is key to understanding the outcomes of cancer patients. Given the complexity of cancer treatment, mapping tumor pathology and genetics to known therapy regimens is needed to decipher the effects of single or multiple medications within individualized treatment plans. To create these mappings, we must extract tumor biology and treatment medication information from the patient Electronic Health Record (EHR) at scale and align it with fine-grained representations of complex cancer treatments. Frequently, the information is not available as structured data; therefore, extraction from EHR notes is necessary. We developed to our knowledge the first end-to-end pipeline to extract chemotherapy events from EHR clinical narrative across all types of notes and to assemble a patient timeline. To represent the complexity of cancer treatments, we developed definitions of key concepts including protocols, regimens, phases, and treatment exposures. A dataset of pediatric patients with acute myeloid leukemia (AML) was used to develop the definitions, which were aligned with treatment protocol information as represented on HemOnc.org. This allowed us to develop a Web Ontology Language (OWL) information model and a model of pediatric AML regimens.","['Natural Language Processing', 'Cohort discovery', 'Knowledge representation, management, or engineering']"
Logical Form Translation for Clinical Trial Eligibility Criteria using Large Language Models,"Determining patients eligible for randomized clinical trials is an ongoing challenge. Often this stems from difficulties in determining eligible patients, which may be reviewed manually through chart review or with the assistance of technical personnel with informatics expertise. An alternative approach is the use of natural language interface tools such as LeafAI, a state-of-the-art system which uses a combination of deep learning models and rule-based methods to generate SQL database queries and identify eligible patients from free-text eligibility criteria. A key component ofthis process is the transformation of eligibility criteria into logical forms, machine-readable representations of underlying logic behind a given criteria. In this study, we study the capabilities of two widely used LLMs, GPT-3.5-turbo and GPT-4, in the logical form transformation task. In our experiments, we compare these LLMs against the original LeafAI architecture using a fine-tuned T5 model. We measure performance against a human-annotated gold standard and conduct an error analysis by categorizing types of errors from GPT-4.","['Clinical trials innovations', 'Data-driven research and discovery', 'Natural Language Processing']"
Deep Learning Approaches to Predict Exercise Exertion Levels Using Wearable Physiological Data,"Using physiological data from wearable devices, the study aimed to predict exercise exertion levels by building deep learning classification and regression models. Ten healthy individuals performed 16-minute cycling exercise sessions. During each session, real-time ECG, pulse rate, oxygen saturation, and revolutions per minute (RPM) data were collected at three intensity levels. Subjects' ratings of perceived exertion (RPE) were collected once per minute. Each 16-minute exercise session was divided into eight 2-minute windows. The self-reported RPEs, heart rate, RPMs, and oxygen saturation levels were averaged for each window to form the predictive features. In addition, heart rate variability (HRV) features were extracted from the ECG for each window. Different feature selection algorithms were used to choose top-ranked predictors. The best predictors were then used to train and test deep learning models for regression and classification analysis. Our results showed the highest accuracy and F1 score of 98.2% and 98%, respectively in training the models. For testing the models, the highest accuracy and F1 score were 80%.","['Machine learning and predictive modeling', 'Mobile Health, wearable devices and patient-generated health data', 'Knowledge representation, management, or engineering']"
FAIR privacy-preserving operation of large genomic variant calling format (VCF) data without download or installation,"Motivation: The proliferation of genetic testing and consumer genomics represents a logistic challenge to the personalized use of GWAS data in VCF format: the retrieval of target genetic variation from large compressed files with reference variant information that is mostly irrelevant to the phenotype in question. Compounding the data traversal challenge, privacy-sensitive VCF files are typically managed as stand-alone single files (no companion index file) composed of variable-sized compressed chunks governed by a vetted Cloud middlelayer, like Box.com, with no support for hosted execution.Results: A portable JavaScript module was developed to support fetching partial content using byte range requests; decompressing them from irregularly positioned of compressed chunks; by an efficient divide-and-conquer (binary) search algorithm iteratively identifying chromosome-position ranges in the remote compressed unindexed reference. This zero-footprint solution (no downloads, no installations) enables the interoperability, reusability, and user-facing governance advanced by the FAIR principles for stewardship of scientific data.","['Data commons', 'Data sharing / interoperability', 'Genotype-phenotype association studies (including GWAS)']"
DeepPhe-CR: Natural Language Processing Software Services for Cancer Registrar Case Abstraction,"The manual extraction of case details from patient records for cancer surveillance is a resource-intensive task. Natural Language Processing (NLP) techniques have been proposed for automating the identification of key details in clinical notes. Our goal was to develop NLP application programming interfaces (APIs) for integration into cancer registry data abstraction tools in a computer-assisted abstraction setting. We used cancer registry manual abstraction processes to guide the design of DeepPhe-CR, a web-based NLP service API. The extraction of key variables was done through NLP methods validated using established workflows. A container-based implementation of the NLP methods and the supporting infrastructure was developed. Existing registry data abstraction software was modified to include results from DeepPhe-CR. An initial usability study with data registrars provided early validation of the feasibility of the DeepPhe-CR tools.","['Natural Language Processing', 'Clinical and research data collection, curation, preservation, or sharing', 'Knowledge representation, management, or engineering']"
Development of a Study Protocol for Evaluation of a Novel Measure to Incorporate Information Freshness into Network Analysis of Online Resources for COVID-19,"We proposed a novel measure, Degree of Connectivity with Integration of Freshness (DCIF), to incorporate information freshness into analysis of online resource networks. We conducted a pilot study to apply this new measure to a dataset of online information resources related to COVID-19 risk assessment. Among the 52 nodes, we recorded statistically significant difference between the numerical values of DCIF and the traditional structural measure Degree of Connectivity (DC). Manual reviews of 18 selected nodes showed that DCIF outperformed DC in 11 of them, suggesting potential promise of the proposed new measure. We finalized the protocol for manual review based on the pilot and started a full-scale study. The proposed new measure has the potential to provide quantitative assessment on information freshness for timely and effective dissemination of clinical evidence. Further research is required to address the limitations of this pilot study and to examine the generalization of the findings.","['Data mining and knowledge discovery', 'Ontologies', 'Knowledge representation, management, or engineering']"
"AI Chatbot Influence on Medical Decision-Making, Bias, and Equity: A Randomized Study of Clinicians Evaluating Clinical Vignettes","Amid increasing AI integration in healthcare, potential bias concerns arise. This study assessed whether combining clinical expertise with AI, specifically, a large language model (GPT-4), could enhance medical decision-making without introducing demographic bias. 50 physicians evaluated clinical vignettes of chest pain, portrayed by actors of different races. The intervention significantly improved participant scores across groups comparably, not introducing or exacerbating any race or gender biases.","['Clinical decision support for translational/data science interventions', 'Natural Language Processing', 'Machine learning and predictive modeling']"
Knowledge Engineering of Lexicon Resources of Food and Housing Insecurity from Multi-source Evidence,"The World Health Organization defines Social and Behavioral Determinants of Health (SDoH) as the conditions in which people are born, grow, live, work, and age. These determinants, including income, education, ethnicity, social activity, and physical activities, play a significant role in shaping people's health, healthcare outcomes, and healthcare fairness and disparity. To facilitate the widespread application of SDoH information derived from real-world evidence, we propose the development of lexicon resources for food and housing insecurity concepts. We employed three distinct approaches (UMLS, Literature, and LLM) to create these lexicon resources. Sentence-level annotation and error analysis were conducted to evaluate the precision of each method. Our study revealed that cross-referencing with UMLS was the most effective method. The LLM method achieved relatively good precision at the expense of identifying fewer results from EHRs for food insecurity. The overarching intention of our study, rather than comparing the performance of each source, is to evaluate the effectiveness of each approach in the given context in order to help design a hybrid solution by leveraging all combinations of each source to provide the best solution. In future studies, we aim to collaborate with the University of Kentucky and the University of Pittsburgh to expand these lexicon resources into robust NLP models and perform cross-validation.","['Natural Language Processing', 'Secondary use of EHR data', 'Social determinants of health']"
Topology-based Clustering of Functional Brain Networks in an Alzheimer's Disease Cohort,"Alzheimer's disease is a progressive neurodegenerative disease with many identifying biomarkers for diagnosis. However, whole-brain phenomena, particularly in functional MRI modalities, are not fully understood nor characterized. Here we employ the novel application of topological data analysis (TDA)-based methods of persistent homology to functional brain networks from ADNI-3 cohort to perform a subtyping experiment using unsupervised clustering techniques. We then investigate variations in QT-PAD challenge features across the identified clusters. Using a Wasserstein distance kernel with a variety of clustering algorithms, we found that the 0th-homology Wasserstein distance kernel and spectral clustering yielded clusters with significant differences in whole brain and medial temporal lobe (MTL) volume, thus demonstrating an intrinsic link between whole brain functional topology and brain morphometric structure. These findings demonstrate the importance of MTL in functional connectivity and the efficacy of using TDA-based machine learning methods in network neuroscience and neurodegenerative disease subtyping.","['Medical Imaging', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
Interpretability Study for Long Interview Transcripts from Behavior Intervention Sessions for Family Caregivers of Dementia Patients,"Mental health challenges are significant global public health concerns, affecting millions of people and impacting individuals, families, and communities alike. Therapists play a crucial role in supporting those with mental health issues by providing emotional, practical, and financial assistance, as well as facilitating access to treatment and services. Utilizing one-to-one interviews is an effective approach that yields valuable transcripts for further study. In this paper, we focus on interview transcripts between therapists and caregivers with family members suffering from dementia. We propose a method to efficiently handle long interview transcripts for classification. Then we employ the Shapley-value based interpretability technique to identify important contents that significantly contribute to classification results and build a corpus containing sentences potentially beneficial to the therapy. This approach offers valuable insights for enhancing the treatment of mental health issues.","['Data-driven research and discovery', 'Natural Language Processing', 'Machine learning and predictive modeling']"
Comparison of Manual and Automated Cutaneous T-cell Lymphoma Chart Review via NLP,"Cutaneous T-cell lymphomas (CTCL) are non-Hodgkin's lymphomas that are difficult to diagnose. We performed manual chart review and compared it to a novel natural language processing pipeline to identify early clues for CTCL diagnosis. Both human review and NLP found similar trends pre-diagnosis. Differences may be due to errors in human or machine processing, different notes included, or false positives. We discuss implications for designing and evaluating NLP systems for extracting clinical features from notes.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Clinical and research data collection, curation, preservation, or sharing']"
Clinical Note Structural Knowledge Improves Word Sense Disambiguation,"Clinical notes are full of ambiguous medical abbreviations. Contextual knowledge has been leveraged by recent learning-based approaches for sense disambiguation. Previous findings indicated that structural elements of clinical notes entail useful characteristics for informing different interpretations of abbreviations, yet they have remained underutilized and have not been fully investigated. To our best knowledge, the only study exploring note structures simply enumerated the headers in the notes, where such representations are not semantically meaningful. This paper describes a learning-based approach using the note structure represented by the semantic types predefined in Unified Medical Language System (UMLS). We evaluated the representation in addition to the widely used N-gram with three learning models on two different datasets. Experiments indicate that our feature augmentation consistently improved model performance for abbreviation disambiguation, with the optimal F1 score of 0.93.","['Natural Language Processing', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
Age-related Modifications in Inter-tissue Coordinated Gene-expression Patterns,"Aging in humans is one of the most complex biological processes and is a known risk factor for various diseases. Current genomic studies focus on finding factors associated with aging within a distinct tissue. As aging is a systematic process, involving many genes and biological pathways across multiple tissues, generating a global view can provide valuable insights into aging mechanisms. Understanding the underlying molecular mechanisms in aging and how molecular pathways interplay with each other between tissues is still lacking. We propose a novel computational framework to identify and characterize how aging affects the coordinated patterns of gene-expression in three tissues (Adipose, Muscle and Brain). We refined a weighted gene co-expression network analysis algorithm to represent a multi-layer network of inter-and intra-tissue associations in a balanced way. The network was generated across ~1000 samples for old and young age groups, which simultaneously captures gene interactions within and across multiple tissues. We then quantified the changes in connectivity in the young versus the old group. We show a significant age-related decrease in inter-tissue coordination, followed by a connectivity loss of genes. Specifically, we detected metabolic and immune pathways inter-tissue coordination changes to play a critical role in the progression of aging. Finally, we used single-sample pathway analysis (ssPA) as features fed into the Random Forest (RF) model (AUC=0.7) to detect key changes in inter-tissue synchronization of biological pathways in the aging process.Our novel framework highlights the importance of understanding the inter-tissue coordination processes underlying healthy aging.","['Systems biology and network analysis', 'Transcriptomics', 'Data-driven research and discovery']"
The Role of Augmented Reality in Advancing Medical Training Techniques: A Study on Cricothyroidotomy,"In the realm of difficult airway management, Cricothyroidotomy stands as a critical procedure, yet it remains infrequently encountered, leaving many healthcare professionals unfamiliar with its intricacies. This study aimed to develop an Augmented Reality (AR) training program for Cricothyroidotomy, leveraging the growing role of AR in medical education, and assess its effectiveness compared to traditional training methods. The investigation unfolded at Seoul's Samsung Medical Center (SMC) over November to December 2022, enrolling doctors and Emergency Medical Technicians (EMTs) who were novices to the HoloLens technology. A total of 30 participants were randomly allocated to two groups: one utilizing PowerPoint presentations (PPT), and the other embracing AR-based training.Participants engaged in five training sessions, and a follow-up session after two weeks gauged their retention of the procedure. The primary outcome measure was the total procedure time. Secondary outcomes encompassed self-reported confidence, satisfaction, and pre-post assessments conducted through surveys. Additionally, researchers evaluated participants' Cricothyroidotomy skills and assessed HoloLens2 usability using the System Usability Scale (SUS) and HoloLens Likert feedback surveys.Results unveiled comparable procedure times between the two groups, with no significant differences in performance satisfaction. Notably, short-term memory retention was evident through pre-post exam analysis, coupled with high levels of educational satisfaction. These findings underscore the viability of this training approach, especially in contexts necessitating remote learning, such as those influenced by the constraints of the COVID-19 pandemic.","['Education and Training', 'Outcomes research, clinical epidemiology, population health']"
Low-Cost Histopathological Mitosis Detection for Microscope-acquired Images,"Cancer outcomes are poor in resource-limited countries owing to high costs and insufficient pathologist-population ratio. The advent of digital pathology has assisted in improving cancer outcomes, however, Whole Slide Image scan- ners are expensive and not affordable in low-income countries. Microscope-acquired images on the other hand are cheap to collect and can be more viable for automation of cancer detection. In this study, we propose LCH-Network, a novel method to identify the cancer mitotic count from microscope-acquired images. We introduced Label Mix, and also synthesized images using GANs to handle data imbalance. Moreover, we applied progressive resolution to handle different image scales for mitotic localization. We achieved F1-Score of 0.71 and outperformed other existing techniques. Our findings enable mitotic count estimation from microscopic images with a low-cost setup. Clinically, our method could help avoid presumptive treatment without a confirmed cancer diagnosis.","['Medical Imaging', 'Public health informatics', 'Machine learning and predictive modeling']"
Developing a Reusable Clinical Decision Support System Module for Immunization Recommendations: a Case Study with OpenEMR and OpenMRS,"This project aims to design a common clinical decision support (CDS) module by leveraging machine-readable CDS rules, specifically CDC-recommended immunization schedules. Currently, we use OpenMRS and OpenEMR as test beds. The development and implementation take advantage of commonalities between both systems, HL7 Fast Healthcare Interoperability Resources (FHIR) and web technologies. We aim to provide a common CDS framework that can be used repeatedly in cloud-based electronic health record systems with FHIR support.","['Clinical decision support for translational/data science interventions', 'FHIR', 'Data/system integration, standardization and interoperability']"
CGG Short Tandem Repeat Expansions are Overrepresented in Neurodevelopmental Disorders,"Short tandem repeats (STRs) are common in the human genome, constituting around 3% of it. Among these, CGG STRs are notable as they are frequently found in and around genes. CGG STRs are particularly associated with neurodevelopmental disorders (NDDs). Expansions of these repeats can lead to gene silencing through hypermethylation. We examined 5963 CGG STR loci in a large NDD cohort of 15,996 individuals using whole genome sequencing. We identified 419 significant CGG STR expansions in 142 unique loci within 118 genes. These genes were enriched for functions related to DNA binding, regulation, and transcription, with expression in brain tissues, particularly the cerebral cortex and cerebellum.In individuals with autism spectrum disorder (ASD), we observed a 2.9-fold increased likelihood of large CGG STR expansion compared to unaffected parents. We found CGG repeat expansions in over 30 genes previously linked to various disorders, most of which are related to neurodevelopment. By combining our expansion data with haploinsufficiency and variant analyses, we identified promising candidate genes like RGPD2 and SAMD1, potentially involved in recessive NDDs. This study not only reveals novel candidate genes associated with CGG expansion disorders but also strengthens the connection between CGG STRs and NDDs.","['Informatics research/biomedical informatics research methods', 'Clinical genomics/omics and interventions based on omics data', 'Genomics/Omic data interpretation']"
Ensemble pretrained language models to extract biomedical knowledge from literature,"In this paper, we introduce a novel NLP system we built for the LitCoin NLP challenge, organized by the National Center for Advancing Translational Science, which achieved 1st place in Phase I - Named Entity Recognition (NER) and 2nd place in Phase II - Relation Extraction (RE) and Novelty Prediction among more than 200 teams. Our results demonstrate potential applications in downstream tasks such as knowledge graph construction and hypothesis generation for biomedical research.","['Natural Language Processing', 'Data mining and knowledge discovery', 'Data-driven research and discovery']"
Comparison of Three Deep Learning Models in Accurate Classification of 770 Dermoscopy Skin Lesion Images,"Accurately determining and classifying different types of skin cancers is critical for early diagnosis. In this work, we propose a novel use of deep learning for classification of benign and malignant skin lesions using dermoscopy images. We obtained 770 de-identified dermoscopy images from the University of Missouri (MU) Healthcare. We created three unique image datasets that contained the original images and images obtained after applying a hair removal algorithm. We trained three popular deep learning models, namely, ResNet50, DenseNet121, and Inception-V3. We evaluated the accuracy and the area under the curve (AUC) receiver operating characteristic (ROC) for each model and dataset. DenseNet121 achieved the best accuracy (80.52%) and AUC ROC score (0.81) on the third dataset. For this dataset, the sensitivity and specificity were 0.80 and 0.81, respectively. We also present the SHAP (SHapley Additive exPlanations) values for the predictions made by different models to understand their interpretability.","['Medical Imaging', 'Patient centered research and care', 'Machine learning and predictive modeling']"
A Survey on the Utilization of Online Peer Support Among Informal Dementia Caregivers,"Informal dementia caregivers often face substantial caregiving challenges. Online communities provide a cheap and convenient way to obtain support and resources, but most studies in this area are biased toward caregivers who are already online users. This survey investigated how informal dementia caregivers, in general, perceive or utilize peer support from online communities. The research findings can serve as a base for investigations using online peer support to assist informal dementia caregivers.","['Public health informatics', 'Patient centered research and care', 'Education and Training']"
SABER: Statistical Identification of Loci of Interest in GWAS Summary Statistics using a Bayesian Gaussian Mixture Model,"Genome-wide association studies (GWAS) remain a popular method for identifying novel genetic associations with human phenotypes and have provided many insights into the etiology of many diseases. However, GWAS provide limited support for how a genetic association might contribute to disease due to inherent limitations, such as linkage disequilibrium. As such, many methods that operate on GWAS summary statistics have been developed to generate evidence for functional pathways or for variants of interest, but they require defining the genomic region bounds for loci of interest. At present, there are limited methods for determining these bounds in a rigorous, reproducible way. We present a novel statistical method, Statistical Analysis for Bayesian Estimation of Regions (SABER), that uses Bayesian Gaussian mixture models to reproducibly generate ratios that quantify whether particular genomic positions represent the bounds of loci of interest and can be used to delineate genomic regions for downstream analyses.","['Reproducible research methods and tools', 'Genotype-phenotype association studies (including GWAS)', 'Genomics/Omic data interpretation']"
Local Large Language Models for Complex Structured Tasks,"This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex language tasks. The authors demonstrate their approach by extracting structured condition codes from pathology reports. The proposed approach utilizes local, fine-tuned LLMs to respond to specific generative instructions and provide structured outputs. Over 150k uncurated surgical pathology reports containing gross descriptions, final diagnoses, and condition codes were used. Different model architectures were trained and evaluated, including LLaMA, BERT, and LongFormer. The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics. LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks. Overall, this work presents an effective approach for utilizing LLMs to perform structured generative tasks on domain-specific language in the medical domain.","['Data-driven research and discovery', 'Machine learning and predictive modeling', 'Clinical and research data collection, curation, preservation, or sharing']"
Adaptation and Implementation of the ECHO Model for Hypertension Management in A Low- and Middle-Income Country,"Healthcare workers (HCWs) in the Federal Capital Territory (FCT), Nigeria participated in a hypertension focused training series following the Extension for Community Health Outcomes (ECHO) model. We sought to evaluate the effect of the hypertension training series on service delivery and patient level outcomes including hypertension treatment and control rates, medication, and referral patterns. HCWs from 12 sites participating in the Hypertension Treatment in Nigeria (HTN) Program participated in a seven-part hypertension ECHO training series between August 2022 to April 2023. Trainings focused on varied domains of hypertension patient management. Patient level data from the Hypertension Treatment in Nigeria program registry concurrent with the training period were used to evaluate the effectiveness of the training program on patient level outcomes. Outcomes were compared between the 12 sites which participated in the ECHO program and the sites which were not.","['Health Information and biomedical data dissemination strategies', 'Implementation Science', 'Stakeholder (i.e., patients or community) engagement']"
Characterizing protein structural features of alternative splicing and isoforms using AlphaFold 2,"AlphaFold 2 provides a great opportunity for a comprehensive analysis of the relationship between alternative splicing and protein structure. We analyzed alternative splicing across ~3,500 human genes and observed post-splicing structural changes predominantly in coils and beta-sheets. Intrinsically disordered residues were found enriched in spliced regions. Furthermore, we gained significant insight into splicing by analyzing the Septin-9 protein and the Tau protein. Our study underscores the intricate relationships among alternative splicing, evolution, and disease.","['Biomarker discovery and development', 'Data-driven research and discovery', 'Genomics/Omic data interpretation']"
Multimodal Data Hybrid Fusion and Natural Language Processing for Clinical Prediction Models,"We presented a comprehensive framework that integrated multimodal data sources, including textual clinical notes, structured electronic health records (EHRs), and relevant clinical data from National Electronic Injury Surveillance System (NEISS) datasets. We proposed a novel hybrid fusion method, which incorporated state-of-the-art pre-trained language model, to integrate unstructured clinical text with structured EHR data and other multimodal sources, thereby capturing a more comprehensive representation of patient information. The experimental results demonstrated that the hybrid fusion approach significantly improved the performance of clinical prediction models compared to traditional fusion frameworks and unimodal models that rely solely on structured data or text information alone. The proposed hybrid fusion system with RoBERTa language encoder achieved the best prediction of the Top 1 injury with an accuracy of 75.00% and Top 3 injuries with an accuracy of 93.54%. Our study highlights the potential of integrating natural language processing (NLP) techniques with multimodal data fusion for enhancing clinical prediction models' performances. By leveraging the rich information present in clinical text and combining it with structured EHR data, the proposed approach can improve the accuracy and robustness of predictive models. The approach has the potential to advance clinical decision support systems, enable personalized medicine, and facilitate evidence-based health care practices. Future research can further explore the application of this hybrid fusion approach in real-world clinical settings and investigate its impact on improving patient outcomes.","['Data-driven research and discovery', 'Natural Language Processing', 'Machine learning and predictive modeling']"
Linking Cancer Clinical Trials to their Result Publications,"The results of clinical trials are a valuable source of evidence for researchers, policy makers, and healthcare professionals. However, online trial registries do not always contain links to the publications that report on their results, instead requiring a time-consuming manual search. Here, we explored the application of pre-trained transformer-based language models to automatically identify result-reporting publications of cancer clinical trials by computing dense vectors and performing semantic search. Models were fine-tuned on text data from trial registry fields and article metadata using a contrastive learning approach. The best performing model was PubMedBERT, which achieved a mean average precision of 0.592 and ranked 70.3% of a trial's publications in the top 5 results when tested on the holdout test trials. Our results suggest that semantic search using embeddings from transformer models may be an effective approach to the task of linking trials to their publications.","['Natural Language Processing', 'Clinical trials innovations', 'Machine learning and predictive modeling']"
MENDS-on-FHIR: A pipeline to convert OMOP data into HL7 R4/US Core complaint FHIR data,"This abstract describes a pipeline for converting data stored in OMOP CDM 5.3 into a set of HL7 R4/US Core complaint FHIR resources using the Whistle Engine. The pipeline was developed for the Multi-State EHR-Based Network for Disease Surveillance (MENDS) project. We mapped data for the following MENDS domains: patient, encounter, prescription, lab result, social history, and immunization. The FHIR data generated was validated using the FHIR validator tool and imported to HAPI FHIR server.","['Data transformation/ETL', 'FHIR', 'Data/system integration, standardization and interoperability']"
Timely Follow-Up on Abnormal Mammography Results: Design and Development of a Novel Electronic Clinical Quality Measure (eCQM),"Based on an environmental scan and stakeholder consultations, we designed and developed an electronic clinical quality measure to report the rate of timely follow-up on abnormal mammography results. The specifications are defined using routinely collected electronic health record (EHR) data. Chart reviews demonstrated that the data are accurately documented in the EHR and generally stored in structured fields. One challenge is extraction of abnormal results from mammography reports, which is addressed using natural language processing.","['Secondary use of EHR data', 'Measuring outcomes', 'Patient centered research and care']"
Fine-tuning a Hierarchical Attention Based BiLSTM-CRF Model Using Minimal Labeled Data,"Ontology construction and updates can be facilitated by identifying keyphrases in existing literature automatically, a complement to the manual process. We developed a BiLSTM-CRF model that utilizes natural language processing, hierarchical attention, and deep learning techniques for this purpose. To explore the model's performance, we conducted experiments where we fine-tuned it by adding labeled data during training and analyzed the results. We observed that the model yields satisfactory results even with minimal labeled data.","['Data-driven research and discovery', 'Natural Language Processing', 'Machine learning and predictive modeling']"
"A Multi-Modal Geomarker Pipeline for Assessing the Impact of Social, Economic, and Environmental Factors on Pediatric Hospitalization","Given the wide range of data types and linkage methods, FAIR computational pipelines and research software for geospatial, community, and environmental data require special considerations. Our overall objective was to create a computational pipeline for attaching place-based data to electronic health records at scale to assess the impact of social, economic, and environmental factors on population-wide pediatric hospitalizations across Hamilton County, Ohio. To assess the impact of place-based characteristics (termed geomarkers) on hospital admissions, we aimed to link patient hospitalizations to multi-modal, extant data sources grouped into four major categories: (1) temporal geomarkers linked by date, (2) exact location geomarkers linked by geocoding residential addresses, (3) census tract geomarkers linked by geocoding to census tract boundaries, and (4) parcel geomarkers linked through probabilistic address matching. We compared combinations of two natural language address parsers and two matching algorithms to link addresses to parcel identifiers at scale. Our population-wide sample of hospitalizations across seven yearsin Hamilton County, Ohio consisted of 124,244 hospitalizations experienced by 69,842 children and adolescents living at 19,364 unique parcels. Within the RISEUP geomarker pipeline, we were able to use {parcel} to link 74.8% (or 41,667 of 55,684 hospitalizations) within Hamilton County, Ohio.","['Informatics research/biomedical informatics research methods', 'Social determinants of health', 'Secondary use of EHR data']"
Classifying Concepts in Clinical Notes for Patient Relevance,"Patient notes often contain mentions of medical terms that are not direct descriptions of the patient's current or previous status (e.g., rule outs, family history). Recently, a concept property named 'TermExists' has been proposed that captures the fact that the term does apply to the patient. TermExists property can be valuable for many downstream use cases where characterizing the patient by only their directly applicable concepts is the primary goal. This property has previously been defined in terms of a combination of other properties. Here, we develop methods to directly classify clinical concepts for TermExists, using a derived gold-standard labeling that takes advantage of existing datasets. We show that directly classifying the TermExists variable is as accurate as a composite system, while requiring fewer classifiers.","['Natural Language Processing', 'EHR-based phenotyping', 'Knowledge representation, management, or engineering']"
Mechanisms for Integrating Real Data into Search Game Simulations: An Application to Winter Health Service Pressures and Preventative Policies,"While modelling and simulation are powerful techniques for exploring complex phenomena, if they are not coupled with suitable real-world data any results obtained are likely to require extensive validation. We consider this problem in the context of search game modelling, and suggest that both demographic and behaviour data are used to configure certain model parameters. We show this integration in practice by using a combined dataset of over 150,000 individuals to configure a specific search game model that captures the environment, population, interventions and individual behaviours relating to winter health service pressures. The presence of this data enables us to more accurately explore the potential impact of service pressure interventions, which we do across 33,000 simulations using a computational version of the model. We find government advice to be the best-performing intervention in simulation, in respect of improved health, reduced health inequalities, and thus reduced pressure on health service utilisation.","['Data-driven research and discovery', 'Public health informatics', 'Social determinants of health']"
"ChatGPT and Vaccine Hesitancy: A Comparison of English, Spanish, and French Responses Using a Validated Scale","ChatGPT is a popular information system (over 1 billion visits in August 2023) that can generate natural language responses to user queries. It is important to study the quality and equity of its responses on health-related topics, such as vaccination, as they may influence public health decision-making. We use the Vaccine Hesitancy Scale (VHS) proposed by Shapiro et al.1 to measure the hesitancy of ChatGPT responses in English, Spanish, and French. We find that: (a) ChatGPT responses indicate less hesitancy than those reported for human respondents in past literature; (b) ChatGPT responses vary significantly across languages, with English responses being the most hesitant on average and Spanish being the least; (c) ChatGPT responses are largely consistent across different model parameters but show some variations across the scale factors (vaccine competency, risk). Results have implications for researchers interested in evaluating and improving the quality and equity of health-related web information.","['Public health informatics', 'Health literacy issues and solutions', 'Ethical, legal, and social issues']"
Using Structured and Unstructured EHR Features to Quantify Delayed Diagnosis of Venous Thromboembolism (VTE) in Primary Care: a Multi-Site Study,"Venous Thromboembolism (VTE) is a serious, preventable public health problem requiring timely treatment. Because VTE symptoms are non-specific, diagnosis is often delayed. Today there are no federal measurement tools in place to track delayed diagnosis of VTE. We validated our electronic clinical quality measure (eCQM) to quantify Diagnostic Delay of Venous Thromboembolism (DOVE) in primary care settings in a geographically distant integrated care delivery system and found DOVE rates >80%, consistent with previous testing.","['Measuring outcomes', 'Data standards', 'Natural Language Processing']"
Machine Learning for Equitable Prediction of Opioid Use Disorder: A Bias Mitigation Algorithm Towards Accurate and Fair Outcomes,"In this study, we proposed a bias mitigation algorithm and a weighted majority voting (WMV) classifier for fairness-aware prediction of opioid use disorder. The proposed algorithm achieved a bias improvement of 16.96% (gender), 8.87% (marital status), 8.45% (working condition), 41.62% (race), and 0.20% (income). The WMV classifier also achieved a recall of 92.68%, a specificity of 90.20%, and an accuracy of 90.21%. The results confirm the effectiveness of proposed methods in real-world applications.","['Public health informatics', 'Ethical, legal, and social issues', 'Machine learning and predictive modeling']"
An Explainable Machine Learning Framework to Predict Opioid Use Disorder Treatment Discontinuation and Stratify Patients into Risk Subgroups: Retrospective Study on MarketScan Commercial Claims Data,"In the face of the US opioid crisis, effective buprenorphine treatment for opioid use disorder is often prematurely discontinued. Using 2018-2021 MarketScan data, we developed a two-stage machine learning framework to predict discontinuation within one year after treatment initiation and stratified patients by discontinuation risk. Results indicated that early medication adherence, age, and initial days of supply were significant predictors. By categorizing patients into risk subgroups, our approach enables targeted interventions, enhancing clinical decision-making.","['Public health informatics', 'Machine learning and predictive modeling', 'Outcomes research, clinical epidemiology, population health']"
Pathophysiological Features in Electronic Medical Records Sustain Model Performance under Temporal Dataset Shift,"Access to real-world data streams like electronic medical records (EMRs) has accelerated the development of supervised machine learning (ML) models for clinical applications. However, few studies investigate the differential impact of particular features in the EMR on model performance under temporal dataset shift. To explain how features in the EMR impact models over time, this study aggregates features into feature groups by their source (e.g. medication orders, diagnosis codes and lab results) and feature categories based on their reflection of patient pathophysiology or healthcare processes. We adapt Shapley values to explain feature groups' and feature categories' marginal contribution to initial and sustained model performance. We investigate three standard clinical prediction tasks and find that while feature contributions to initial performance differ across tasks, pathophysiological features help mitigate temporal discrimination deterioration. These results provide interpretable insights on how specific feature groups contribute to model performance and robustness to temporal dataset shift.","['Clinical decision support for translational/data science interventions', 'Implementation Science', 'Machine learning and predictive modeling']"
Diverse diagnoses associated with spontaneous and indicated preterm birth in an electronic health record cohort,"Background: While some clinical risk factors for preterm birth (PTB) are known, a study using electronic health records (EHR) to identify conditions associated with PTB may identify novel risk factors. The novel associations may help identify those at risk for PTB and provide new insight into potential pathways of PTB.Objective: To identify novel clinical associations with PTB overall and by spontaneous and indicated subtype.Methods: This retrospective cohort study was performed in a large EHR system. We identified 10,643 deliveries to birthing people who had a diagnosis recorded prior to conception. We performed multivariate logistic regression on every diagnosed condition (N=1,326) to identify those associated with preterm birth in the full cohort and in the indicated and spontaneous subpopulations.Results: We found 18 diagnoses significantly associated with PTB in the overall group, and 30 in the indicated group. No significant associations were found in the spontaneous group. In both the overall and indicated group, the conditions most significantly associated with PTB replicated previously known risk factors (including hypertension and diabetes), while other conditions such as decreased white blood cell count and lung diseases are less established.Conclusions: In a large EHR system, we replicated known associations between diagnosed conditions and PTB, as well as finding associations of interest for further study. Further study is needed in a large cohort of spontaneous deliveries to better understand this heterogeneous group.","['Data-driven research and discovery', 'Secondary use of EHR data', 'Data Integration']"
Measuring and Reducing Racial Bias in a Pediatric Urinary Tract Infection Model,"Clinical predictive models that include race as a predictor have the potential to exacerbate disparities in healthcare. Such models can be respecified to exclude race or optimized to reduce racial bias. We investigated the impact of such respecifications in a predictive model UTICalc, which was designed to reduce catheterizations in young childrenwith suspected urinary tract infections. To reduce racial bias, race was removed from the UTICalc logistic regression model and replaced with two new features. We compared the two versions of UTICalc using fairness and predictive performance metrics to understand the effects on racial bias. In addition, we derived three new models for UTICalc tospecifically improve racial fairness. Our results show that, as predicted by previously described impossibility results, fairness cannot be simultaneously improved on all fairness metrics, and model respecification may improve racial fairness but decrease overall predictive performance.","['Social determinants of health', 'Ethical, legal, and social issues', 'Machine learning and predictive modeling']"
Towards Predicting Smoking Events for Just-in-time Interventions,"Consumer-grade heart rate (HR) sensors are widely used for tracking physical and mental health status. We explore the feasibility of using Polar H10 electrocardiogram (ECG) sensor to detect and predict cigarette smoking events in naturalistic settings with several machine learning approaches. We have collected and analyzed data for 28 participants observed over a two-week period. We found that using bidirectional long short-term memory (BiLSTM) with ECG-derived and GPS location input features yielded the highest mean accuracy of 69% for smoking event detection. For predicting smoking events, the highest accuracy of 67% was achieved using the fine-tuned LSTM approach. We also found a significant correlation between accuracy and the number of smoking events available from each participant. Our findings indicate that both detection and prediction of smoking events are feasible but require an individualized approach to training the models, particularly for prediction.","['Data-driven research and discovery', 'Mobile Health, wearable devices and patient-generated health data', 'Machine learning and predictive modeling']"
Clinical Significance of Marital Status and Changes in Status Extracted from Unstructured Clinical Notes,"Stressful family events like marriage or divorce are important social determinants of health which can be crucial for clinical decision support. Yet data about such life events is rarely present inside electronic health records in structured form. This project explores a method to identify stressful family changes using natural language processing. After extracting events, we show that any change in marital status correlates with worse health outcomes compared to the 'no change' group.","['Natural Language Processing', 'Social determinants of health', 'Clinical and research data collection, curation, preservation, or sharing']"
A TBI Prescreening Tool for IPV Patients Using Initial Clinical Reports and Machine Learning,"Research studies have presented an unappreciated relationship between intimate partner violence (IPV) survivors and symptoms of traumatic brain injuries (TBI). Within these IPV survivors, resulting TBIs are not always identified during emergency room visits. This demonstrates a need for a prescreening tool that identifies IPV survivors who should receive TBI screening. We present a model that measures similarities to clinical reports for confirmed TBI cases to identify whether a patient should be screened for TBI. This is done through an ensemble of three supervised learning classifiers which work in two distinct feature spaces. Individual classifiers are trained on clinical reports and then used to create an ensemble that needs only one positive label to indicate a patient should be screened for TBI.","['Natural Language Processing', 'EHR-based phenotyping', 'Machine learning and predictive modeling']"
An Exploration of Minimally Stable Feature Set Discovery by Consensus-based Feature Selection Approach for Early Detection of Amyotrophic Lateral Sclerosis,"Amyotrophic lateral sclerosis (ALS) is characterized by symptom heterogeneity and similarity to other neurological disorders, which can lead to delays in diagnosis. Early detection of ALS prompts timely interventions and slow down the progression, which can potentially be achieved by leveraging accurate predictive models with feature selection (FS). However, current state-of-arts FS algorithms based on high-dimensional real-world data often suffer from lack of stability and parsimony, resulting in non-reproducibility and non-generalizability. In this work, we proposed a consensus-based FS approach to identify a minimal feature set that are predictive and stable for early prediction of ALS diagnosis. The proposed method selects a parsimonious set of features by seeking consensus on direction of associations across perturbated samples, over time and between models. Our findings showed great promises in identifying a small set of stable features to predict initial ALS diagnosis even 18 months ahead.","['Data mining and knowledge discovery', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
Concordance between Self-Reported and Prescribed Medications in UKBiobank,"UKBiobank contains self-reported medications and prescription records in primary care. Numerous studies rely on self-reported medications alone for epidemiological and genome-wide association studies. It is unclear whether they have high condordance. In this study, we systematically mapped UKB medication codes into RxNORM and Anatomical Therapeutic Chemical Classification (ATC), and assessed the concordance between two sources of medication records. We found various levels of concordance among different medications, and conclude that one should consider both sources to avoid reporting bias.","['Genotype-phenotype association studies (including GWAS)', 'Cohort discovery', 'Data sharing / interoperability']"
Using Systems Dynamics Modeling to Engage Developers and Users to Understand the Acceptability of a Clinical Decision Support Tool,"To improve adoption of Clinical Decision Support (CDS), developers and end users must have a common understanding of the problem and buy-in of solutions. We applied, Participatory System Dynamics Modeling,an adaptation of a systems thinking approach that engaged developers and end users to identify barriers to using CDS in practice. This process revealed new insights for each group about key leverage points and brought developers' and users' views about a CDS tool closer in alignment.","['Clinical decision support for translational/data science interventions', 'Implementation Science', 'Machine learning and predictive modeling']"
Best of Both Worlds: Bridging One Model for All and Group-Specific Model Approaches using Ensemble-based Subpopulation Modeling,"Subpopulation models have become of increasing interest in prediction of clinical outcomes because they promise to perform better for underrepresented patient subgroups. However, the personalization benefits gained from these models tradeoff their statistical power, and can be impractical when the subpopulation's sample size is small. We hypothesize that a hierarchical model in which population information is integrated into subpopulation models would preserve the personalization benefits and offset the loss of power. In this work, we integrate ideas from ensemble modeling, personalization, and hierarchical modeling and build ensemble-based subpopulation models in which specialization relies on whole group samples. This approach significantly improves the precision of the positive class, especially for the underrepresented subgroups, with minimal cost to the recall. It consistently outperforms one model for all and one model for each subgroup approaches, especially in the presence of a high class-imbalance, for subgroups with at least 380 training samples.","['Secondary use of EHR data', 'Patient centered research and care', 'Machine learning and predictive modeling']"
Identifying Mentions of Social Support and Social Isolation from Clinical Notes of Psychiatric Patients,"Extensive research has established a clear connection between social isolation and the absence of so- cial support with elevated risks for both physical and mental health conditions. These health issues encompass a range of ailments, including cardiovascular diseases, obesity, depression, premature mortality, and Alzheimer's disease.1 On the other hand, social support and related concepts including emotional support, instrumental support, and social networkhavebeenassociatedwithimprovedhealthoutcomes.2 Moreover,ithasalsobeenfoundthatdifferentcompo- nents of social isolation and support may have differing effects on mental and physical health. Within large healthcare systems, identifying patients with social isolation and social support would benefit researchers and clinicians alike to better characterize illness and health within a psychosocial context. Electronic health records (EHRs) represent a valuable repository of patient data to do so; however, information related to social support and isolation is typically only found in the narrative of clinician notes. The manual extraction of such data is labor-intensive. To address this challenge, we examined a combination of regular expressions and machine learning-based natural language processing (NLP) techniques. These approaches were aimed at automating the extraction of mentions pertaining to social support and isolation from clinical encounter notes efficiently.","['Natural Language Processing', 'Social determinants of health', 'Data-driven research and discovery']"
Cross-phenotype associations between Alzheimer's Disease and its comorbidities may provide clues to progression,"Alzheimer's disease (AD) is the most prevalent neurodegenerative disease worldwide, with one in nine people over the age of 65 living with the disease in 2023. In this study, we used a phenome wide association study (PheWAS) approach to identify cross-phenotype associations between previously identified genetic AD and for electronic health record (EHR) diagnoses from the UK Biobank (UKBB) (n=361,194 of European ancestry) and the eMERGE Network (n=105,108 of diverse ancestry). Based on 497 previously identified AD-associated variants from the Alzheimer's Disease Variant Portal (ADVP), we found significant associations primarily in immune and cardiac related diseases in our PheWAS. Replicating variants have widespread impacts on immune genes in diverse tissue types. This study demonstrates the potential of using the PheWAS strategy to improve our understanding of AD progression as well as identify potential drug repurposing opportunities for new treatment and disease prevention strategies.","['Phenomics and phenome-wide association studies', 'EHR-based phenotyping', 'Clinical genomics/omics and interventions based on omics data']"
Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction,"In this study, we investigated the potential of GPT-3 for the anti-cancer drug sensitivity prediction task using structured pharmacogenomics data across five tissue types and evaluated its performance with zero-shot prompting and fine-tuning paradigms. The drug's smile representation and cell line's genomic mutation features were predictive of the drug response. The results from this study have the potential to pave the way for designing more efficient treatment protocols in precision oncology.","['Pharmacogenomics', 'Natural Language Processing', 'Machine learning and predictive modeling']"
LitCoin: Changing the Currency of Scientific Research,"The landscape of FAIR biomedical knowledge is ever-expanding, requiring significant curation to maintain accuracy. LitCoin will allow biomedical researchers to generate highly connected, curated knowledge graphs representing their research using the current publishing pipeline and without requiring in-depth understanding of bioinformatics tools. NCATS is partnering with the HEAL program to pilot the LitCoin system in the field of pain and addiction before expanding it to other fields.","['Health Information and biomedical data dissemination strategies', 'Natural Language Processing', 'Data mining and knowledge discovery']"
Using Discrete Event Simulation to Design and Assess an AI-aided Workflow for Same-day Diagnostic Testing of Women Undergoing Breast Screening,"Patients undergoing breast cancer screening suffer from anxiety while waiting for diagnostic examinations after an abnormal screening mammogram. Artificial intelligence (AI)-aided reading could reduce the number of recalls after screening mammograms. We proposed an AI-aided same-day diagnostic workup to alleviate patient anxiety while aiming to reduce unnecessary diagnostic testing after an abnormal screening mammogram. However, the potential unintended consequences of introducing this workflow in a high-volume breast imaging center are unknown. Using discrete event simulation, we observed that implementing the AI-aided workflow would reduce daily patient volume by 4%, increase the time a patient would be at the clinic by 24%, and increase waiting times by 13-31%. We discussed how changing the hours of operation and introducing new imaging equipment and personnel may alleviate these negative impacts. These findings provide quantitative insights that can be used to minimize potential negative impacts associated with implementing an AI-aided same-day diagnostic testing workflow.","['Clinical decision support for translational/data science interventions', 'Informatics research/biomedical informatics research methods', 'Implementation Science']"
Identifying and Characterizing the Transgender and Nonbinary Population Presenting to Pediatric Psychiatry Emergency Services,"Transgender and nonbinary (TGNB) individuals have an increased risk of certain mental health outcomes, such as depression and suicide attempts. This population skews younger in the United States and prior studies have not included TGNB patients for the entire pediatric age range in an emergency department (ED) setting. The present study aimed to examine gender identity documentation in the electronic health record and then use that information to identify and further characterize the pediatric TGNB population presenting to a psychiatric emergency service. Preliminary findings include a greater percentage of TGNB patients compared to non-TGNB individuals who had repeat visits to the ED for high acuity psychiatric concerns. A larger portion of TGNB patients also had at least one evaluation that included suicidal ideation. These results call for increased attention on the quality of mental healthcare for TGNB youth both inside and outside of the ED.","['Social determinants of health', 'Secondary use of EHR data', 'Ethical, legal, and social issues']"
A Novel Explainable AI Method to Assess the Association between Temporal Patterns in Cardiorespiratory Fitness and ADRD Risks,"A novel explainable AI method was developed and applied to a hybrid value-aware Transformer model to assess the association between the temporal patterns of the cardiorespiratory fitness levels and the risks in developing Alzheimer's disease and related dementias. The temporal patterns were expressed in two new variables called the temporal mean and the temporal slope, and the associations were expressed in impact scores and impacts. Previously unknown associations were discovered, and interpretations were provided.","['Data mining and knowledge discovery', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
Using external data to estimate the observability of an outcome in a target EHR dataset,"The degree to which patient information is captured in the EHR is referred to as observability. We propose the use of external data with full observability to assess the degree of outcome observability in a target EHR dataset. We conduct simulations to show the conditions needed to obtain proper inference. As an application, we consider hospital readmissions as our outcome of interest, and use administrative claims data, as fully observed external data.","['Data quality', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
Predictive Modeling of Surgical Site Infections: Integrating Machine Learning Structured Clinical Data Attributes with EHR Clinical Notes,"Recognizing the significant impact of surgical site infections on patient outcomes and costs, we developed a model combining EPIC electronic health record structured data attributes with features from clinical notes. Employing Logistic Regression and Random Forest algorithms, our models attained AUC values of 0.80 and 0.65, respectively. This work highlights AI's potential in improving SSI prediction and enhancing healthcare outcomes.","['Clinical decision support for translational/data science interventions', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
Prognostic Cachexia Sub-phenotypes in Weight Loss Severity Trajectories,"Cachexia is a muscle-wasting syndrome observed in roughly half of patients with cancer. Clinically, cachexia is diagnosed and graded using consensus criteria measures, which are limited by their inability to account for the longitudinal progression of cachexia over time. In this study, we report a method for identifying subphenotypes of temporal cachexia progression in electronic health record data and show its superior ability in stratifying patient outcomes than measures collected at a single time point.","['EHR-based phenotyping', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
Prioritizing Clinically Significant Lung Cancer Somatic Mutations for Targeted Therapy Through Efficient NGS Data Filtering System,"Effective precision oncology relies on the accurate identification and prioritization of clinically significant somatic mutations in lung cancer patients. In this study, we present an innovative NGS data filtering system that seamlessly integrates multiple data sources, including genetic variants, genes, clinical evidence, and literature knowledge. Through rigorous filtration, we efficiently narrow down a vast dataset to prioritize 420 genes and 1,193 variants of high clinical significance. Furthermore, we meticulously review and select 80 variants with compelling clinical relevance. Our approach aligns with FDA-approved drugs, NCCN guidelines, and curated literature, aiding oncologists in suggesting targeted therapeutic strategies. Validated using real-world lung adenocarcinoma NGS data, our system demonstrates its potential to expedite precision oncology and enhance treatment outcomes. As part of future developments, we aim to expand our system to include additional data types and provide a user-friendly interface for seamless data access and information sharing.","['Clinical genomics/omics and interventions based on omics data', 'Informatics research/biomedical informatics research methods', 'Genomics/Omic data interpretation']"
Comparative Analysis of Fusion Strategies for Imaging and Non-imaging Data - Use-case of Hospital Discharge Prediction,"Accurate prediction of future clinical events such as discharge from hospital can not only improve hospital resource management but also provide an indicator of a patient's clinical condition. Within the scope of this work, we perform a comparative analysis of deep learning based fusion strategies against traditional single source models for prediction of discharge from hospital by fusing information encoded in two diverse but relevant data modalities, i.e., chest X-ray images and tabular electronic health records (EHR). We evaluate multiple fusion strategies including late, early and joint fusion in terms of their efficacy for target prediction compared to EHR-only and Image-only predictive models. Results indicated the importance of merging information from two modalities for prediction as fusion models tended to outperform single modality models and also indicate that the joint fusion scheme was the most effective for target prediction. Joint fusion model merges the two modalities through a branched neural network that is jointly trained in an end-to-end fashion to extract target-relevant information from both modalities.","['Health Information and biomedical data dissemination strategies', 'Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling']"
Development of an Electronic Clinical Quality Measure (eCQM) to Report Timely Follow-up on Abnormal Stool-based Tests for Colorectal Cancer Screening: An Environmental Scan,"This environmental scan aims to inform the development of an electronic clinical quality measure (eCQM) that calculates the rates of timely diagnostic follow-up after abnormal stool-based CRC screening tests within the Mass General Brigham (MGB) health system. It synthesizes the current literature on the impact of follow-up delays on patient outcomes and guideline information on screening and diagnostic processes. While patients who experienced a follow-up diagnostic delay of more than six months had greater odds of developing early and advanced stages of colorectal cancer, follow-up rates across health systems in the U.S. were low on average, with timely follow-up ranging from 43.3 in 90 days to 56.1% in 360 days.","['Measuring outcomes', 'Informatics research/biomedical informatics research methods', 'Clinical and research data collection, curation, preservation, or sharing']"
Assessing the Barriers and Facilitators to Pulmonary Rehabilitation Referrals Using the Consolidated Framework for Implementation Research (CFIR),"Chronic obstructive pulmonary disease (COPD) is a global health issue causing significant illness and death. Pulmonary Rehabilitation (PR) offers non-pharmacological treatment, including education, exercise, and psychological support which was shown to improve clinical outcomes. In both stable COPD and after an acute exacerbation, PR has been demonstrated to increase exercise capacity, decrease dyspnea, and enhance quality of life. Despite these benefits, referrals for PR for COPD treatment remain low. This study aims to evaluate the perceptions of healthcare providers for referring a COPD patient to PR. Semi-structured qualitative interviews were conducted with pulmonary specialists, hospitalists, and emergency department physicians. Domains and constructs from the Consolidated Framework for Implementation Research (CFIR) were applied to the qualitative data to organize, analyze, and identify the barriers and facilitators to referring COPD patients. The findings from this study will help guide strategies to improve the referral process for PR.","['Patient centered research and care', 'Implementation Science', 'Clinical and research data collection, curation, preservation, or sharing']"
Pragmatic De-Identification of Cross-Domain Unstructured Documents: A Utility-Preserving Approach with Relation Extraction Filtering,"The volume of information, and in particular personal information, generated each day is increasing at a staggering rate. The ability to leverage such information depends greatly on being able to satisfy the many compliance and privacy regulations that are appearing all over the world. We present READI, a utility preserving framework for the unstructured document de-identification. READI leverages Named Entity Recognition and Relation Extraction technology to improve the quality of the entity detection, thus improving the overall quality of the data de-identification process. We evaluate the proposed approach on two different datasets and compare with the existing state-of-the-art approaches. We show that Relation Extraction-based Approach for De-Identification (READI) notably reduces the number of false positives and improves the utility of the de-identified text.","['Data security and privacy', 'Natural Language Processing', 'Machine learning and predictive modeling']"
Travel Distance as a Potential Impediment to Clinical Trial Participation: a GIS Analysis of New England NCI-Designated Centers,"Clinical trials provide patients with cancer access to experimental treatments and are a crucial to improving the standard of care in oncology. Long travel times to NCI-designated clinics potentially exclude patients from clinical trials, creating health inequities and limiting trial-participant diversity. We evaluated disparities in clinical trial accessibility in New England by determining what proportion of the population can reach an NCI-designated clinic in various driving time thresholds ranging from 15 to 120 minutes.","['Learning healthcare system', 'Patient centered research and care', 'Geographical information systems (GIS)']"
Aiming for Relevance,"Vital signs are crucial in intensive care units (ICUs). They are used to track the patient's state and to identify clinically significant changes. Predicting vital sign trajectories is valuable for early detection of adverse events. However, conventional machine learning metrics like RMSE often fail to capture the true clinical relevance of such predictions. We introduce novel vital sign prediction performance metrics that align with clinical contexts, focusing on deviations from clinical norms, overall trends, and trend deviations. These metrics are derived from empirical utility curves obtained in a previous study through interviews with ICU clinicians. We validate the metrics' usefulness using simulated and real clinical datasets (MIMIC and eICU). Furthermore, we employ these metrics as loss functions for neural networks, resulting in models that excel in predicting clinically significant events. This research paves the way for clinically relevant machine learning model evaluation and optimization, promising to improve ICU patient care.","['Measuring outcomes', 'Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling']"
Large Language Models for Efficient Medical Information Extraction,"Extracting valuable insights from unstructured clinical narrative reports is a challenging yet crucial task in the healthcare domain as it allows healthcare workers to treat patients more efficiently and improves the overall standard of care. We employ ChatGPT, a Large language model (LLM), and compare its performance to manual reviewers. The review focuses on four key conditions: family history of heart disease, depression, heavy smoking, and cancer. The evaluation of a diverse sample of History and Physical (H&P) Notes, demonstrates ChatGPT's remarkable capabilities. Notably, it exhibits exemplary results in sensitivity for depression and heavy smokers and specificity for cancer. We identify areas for improvement as well, particularly in capturing nuanced semantic information related to family history of heart disease and cancer. With further investigation, ChatGPT holds substantial potential for advancements in medical information extraction.","['Clinical decision support for translational/data science interventions', 'Secondary use of EHR data', 'Natural Language Processing']"
Identifying Referral Candidates for Community Health Worker Interventions by Using Electronic Health Records and Machine Learning,"The increasing recognition of Social Determinants of Health necessitates effective tools for the healthcare system to address patients' unmet social needs. Utilizing machine learning on electronic health records, this study aimed to optimize the recommendation process for Community Health Worker referrals. Our best model achieved an f-score of 0.81 and AUROC of 0.86. The promising results supported feasibility of machine-assisted referral, along with an automated mechanism to detect informative predictors and data sources.","['Social determinants of health', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
Development of a Common Longitudinal Intensive Format (CLIF) to Streamline Multi-center Clinical Research in Critically Ill Patients,"Traditional multi-centre research on critically ill patients is challenging because of data use agreements, and site-specific idiosyncrasies such as inconsistent syntax and data vocabularies. The Common Longitudinal Intensive data Format (CLIF) aims to overcome these challenges by (1) capturing key elements of a critically ill patient's hospital course, (2) embracing human readable table structure, (3) defining minimum data requirements and standard vocabularies, and (4) developing an extensive code repository with standardized analysis scripts.","['Data transformation/ETL', 'Data standards', 'Clinical and research data collection, curation, preservation, or sharing']"
Effects of Added Emphasis and Pause in Audio Delivery of Health Information,"Health literacy is crucial and a major national goal. Audio delivery of information is becoming more popular. In this study, we evaluate the effect of audio enhancements in the form of information emphasis and pauses among health texts of varying difficulty on health information comprehension and retention. We produced audio snippets from difficult and easy text and conducted the study on Amazon Mechanical Turk (AMT). Our findings suggest that emphasis matters for both information comprehension and retention. When there is no added pause, emphasizing significant information can lower the perceived difficulty for difficult and easy texts. Comprehension is also higher (54%) with rightly placed emphasis for the difficult texts compared to not adding emphasis (50%). Adding a pause lowers perceived difficulty and can improve retention but adversely affects information comprehension.","['Health Information and biomedical data dissemination strategies', 'Natural Language Processing', 'Health literacy issues and solutions']"
Connecting With Peers: Examining Sentiment Change of Informal Caregivers for People With Alzheimer's Disease or Related Dementias in Two Online Communities,"Alzheimer's disease or related dementias (ADRD) challenge caregivers globally, with online communities offering important support. Our study investigates sentiment changes in two ADRD forums, ALZConnected and TalkingPoint. We find significant sentiment improvement of the topic starters' posts at the thread level, varying emotional shifts tied to different topics, and improved sentiment for long-term users over time. Our research highlights the positive impact of online peer support on informal ADRD caregivers' emotional well-being.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Ethical, legal, and social issues']"
A Roadmap for Improving Telemedicine Support Operations,"Since COVID-19 Penn Medicine has conducted over 2.3 million telehealth visits. A key to telemedicine's success is the interdisciplinary team that supports it. One of the most critical responsibilities of the support team is to answer end user questions (i.e. providers, administrators) excluding patients. Topics range from getting initial access to telemedicine platforms to software/hardware issues and beyond. The process for addressing these questions is laborious and complex. The PennChart Advanced Clinical Education (PACE) team primarily exists to educate clinicians on how to use PennChart (Penn Medicine's EHR); however, they have developed a key role in triaging telemedicine specific tickets. Through this responsibility, they spend an average of 24 hours per week on ticket triaging alone or 15% of their time. To optimize the delivery of telemedicine and the efficiency of its support, we designed and implemented a ticket management pilot to better manage this system. The results are discussed below.","['Reproducible research methods and tools', 'Natural Language Processing', 'Implementation Science']"
Automated Extraction of Key Fibroid Characteristics from Free-text Pelvic Ultrasound Reports using Rule-based Natural Language Processing,"This study aims to develop a rule-based Natural Language Processing algorithm for extracting essential fibroid information from free-text non-obstetric pelvic ultrasound, and to explore the distribution of the largest fibroid dimension identified by the developed algorithm across race and age groups as a proof of concept of the algorithm's utility. The validated NLP algorithm obtained fibroid measures efficiently that could be applied to examine the associations between fibroid characteristics and clinical care and treatment patterns.","['Natural Language Processing', 'Medical Imaging', 'Outcomes research, clinical epidemiology, population health']"
Generative adversarial networks for generating integrated multi-omics data: An application with Alzheimer's Disease,"Alzheimer's Disease (AD) is a neurodegenerative condition characterized by progressive cognitive decline leading to dementia. Early detection and accurate prediction of AD-related pathology are crucial for developing effective interventions and treatment strategies. Applying machine learning, including deep learning to classify AD outcomes is a promising approach. Developing robust algorithms that can process complex data, integrating multiple biological data, and provide accurate predictions is an ongoing research area. We introduce a generative adversarial network tailored for generating integrated multi-omics data for Alzheimer's disease outcome classification. Our method harmonizes three datasets and their interaction networks. Using the proposed method, we seamlessly merge these omics profiles and their associated networks to generate synthetic datasets with mRNA expression, miRNA expression, and DNA methylation. The model yields significant results, achieving more stable prediction accuracies with synthetic and original datasets compared to using only original datasets.","['Biomedical informatics and data science workforce education', 'Data Integration', 'Genomics/Omic data interpretation']"
Hardware-Software Co-Design Enables High-Resolution Machine Learning for Gigapixel Pathology Image Evaluation,"The standard pathology image processing method divides gigapixel images into small patches, which neglects the tissue context in heterogeneous samples. To address this issue, we propose a Co-design for High-resolution Integrated Pathology System (CHIPS) using novel deep-learning accelerators. We demonstrated the importance of broad spatial tissue contexts in molecular subtyping and survival prediction tasks. Our hardware-software co-design approach identified the optimal configurations for each task with improved performance in automated pathology evaluation and prediction.","['Medical Imaging', 'Digital research enterprise', 'Machine learning and predictive modeling']"
Cluster Analysis of Cortical Amyloid Burden for Identifying Imaging-driven Subtypes in Mild Cognitive Impairment,"Over the past decade, Alzheimer's disease (AD) has become increasingly severe and gained greater attention. Mild Cognitive Impairment (MCI) serves as an important prodromal stage of AD, highlighting the urgency of early diagnosis for timely treatment and control of the condition. Identifying the subtypes of MCI patients exhibits importance for dissecting the heterogeneity of this complex disorder and facilitating more effective target discovery and therapeutic development. Conventional method uses clinical measurements such as cognitive score and neurophysical assessment to stratify MCI patients into two groups with early MCI (EMCI) and late MCI (LMCI), which shows their progressive stages. However, such clinical method is not designed to de-convolute the heterogeneity of the disorder. This study uses a data-driven approach to divide MCI patients into a novel grouping of two subtypes based on an amyloid dataset of 68 cortical features from positron emission tomography (PET), where each subtype has a homogeneous cortical amyloid burden pattern. Experimental evaluation including visual two-dimensional cluster distribution, Kaplan-Meier plot, genetic association studies, and biomarker distribution analysis demonstrates that the identified subtypes performs better across all metrics than the conventional EMCI and LMCI grouping.","['Medical Imaging', 'Data-driven research and discovery', 'Genotype-phenotype association studies (including GWAS)']"
Link Between Viral Variants and Long COVID Characteristics: An Insight from Unsupervised Learning Analysis,"Long COVID represents a multi-system illness involving myalgic encephalomyelitis/chronic fatigue syndrome, dysautonomia, effects on various organ systems, and irregularities in vascular and clotting functions. The outcome of the ongoing global pandemic triggered by the SARS-CoV-2 virus (COVID-19), which has resulted in substantial levels of both fatalities and sickness worldwide, remains uncertain due to the diversity within the long COVID syndrome. This study addresses the uncertainty surrounding the relationship between the biological diversity of SARS-CoV-2 lineages and the clinical variations seen in long COVID. It utilizes statistical tests and unsupervised machine learning techniques to investigate the connection between viral variants from the initial COVID episode and long COVID characteristics. Our comprehensive analysis sheds light on the genetic diversity and potential functional implications of these variants, offering insights into the distinctive features of long COVID.","['Advanced data visualization tools and techniques', 'Genomics/Omic data interpretation']"
Clarifying Chronic Obstructive Pulmonary Disease Genetic Associations Observed in Biobanks via Mediation Analysis of Smoking,"Varying case definitions of COPD have heterogenous genetic risk profiles, potentially reflective of disease subtypes identified under different diagnostic criteria or of bias in how people are categorized into the various groups (e.g., smokers more likely to be categorized as having COPD than non-smokers). We sought to better understand differences in genetic loci associated with ICD-defined COPD versus spirometry-defined COPD by contrasting GWAS results for these traits with GWAS results for heavy smoking among 337,138 UK Biobank participants. Overlapping risk regions were found in/near the genes ZEB2, FAM136B, CHRNA3, and CHRNA4, with a CHRNA3 locus shared across all three traits. Causal mediation analysis to estimate the proportion of the effect of the lead genotyped SNP in these overlapping risk regions on COPD that was mediated by smoking behavior found that there were significant indirect effects for the FAM136B, CHRNA3, and CHRNA4 loci to influence COPD according to both of its definitions. After adjustment for confounders of smoking and COPD, we observed modest attenuation of indirect effects, except for in the CHRNA4 region for the spirometry-defined COPD where the proportion mediated increased an additional 8.47%. Our analysis suggests that the major differences between ICD-defined and spirometry-defined COPD associated genetic loci are not due to the influence of smoking behavior on their definitions.","['Genotype-phenotype association studies (including GWAS)', 'EHR-based phenotyping', 'Genomics/Omic data interpretation']"
Association of Diagnostic Discrepancy with Length of Stay and Mortality in Congestive Heart Failure Patients Admitted to the Emergency Department,"The goal of this study was to analyze diagnostic discrepancies between emergency department (ED) and hospital discharge diagnoses in patients with congestive heart failure admitted to the ED. Using a synthetic dataset from the Department of Veterans Affairs, the patients' primary diagnoses were compared at two levels: diagnostic category and body system. With 12,621 patients and 24,235 admission cases, the study found a 58% mismatch rate at the category level, which was reduced to 30% at the body system level. Diagnostic categories associated with higher levels of mismatch included aplastic anemia, pneumonia, and bacterial infections. In contrast, diagnostic categories associated with lower levels of mismatch included alcohol-related disorders, COVID-19, cardiac dysrhythmias, and gastrointestinal hemorrhage. Further investigation revealed that diagnostic mismatches are associated with longer hospital stays and higher mortality rates. These findings highlight the importance of reducing diagnostic uncertainty, particularly in specific diagnostic categories and body systems, to improve patient care following ED admission.","['Secondary use of EHR data', 'Data-driven research and discovery', 'Outcomes research, clinical epidemiology, population health']"
"Exploring Large Language Models for Acronym, Symbol Sense Disambiguation, and Semantic Similarity and Relatedness Assessment","Acronyms, abbreviations, and symbols are widely used in clinical notes. Acronym and symbol sense disambiguation are an important type of NLP task which ensures the clarity and consistency of clinical notes and downstream NLP processing. Prior study using traditional machine learning methods are relatively successful in solving this problem. In this study, we evaluated large language models (LLM) (i.e., ChatGPT 3.5 and Bert-based models) on three NLP tasks: acronym and symbol sense disambiguation, semantic similarity and relatedness. Our findings highlight the superior performance of Bert-based models over previous machine learning approaches. These models can attain an impressive over 95% accuracy rate, demonstrating their effectiveness in addressing the challenge of acronym and symbol sense disambiguation. Additionally, ChatGPT showcased its ability to distinguish between senses, even with minimal or zero-shot training. Moreover, it exhibited a strong correlation, surpassing 70%, with human gold standards in evaluating similarity and relatedness.","['Natural Language Processing', 'Data mining and knowledge discovery', 'Clinical decision support for translational/data science interventions']"
An Automated Approach for Identifying Erroneous IS-A Relations in SNOMED CT,"SNOMED CT is the most comprehensive clinical terminology utilized on a global scale. It is crucial to perform quality assurance tasks on SNOMED CT to enhance its accuracy. In this work, we introduce an automated approach to identifying erroneous IS-A relations in SNOMED CT. We first extract linked concept pairs from which we generate Term Difference Pairs (TDPs). Given a TDP, if the reversed TDP also exists and the number of linked pairs generating this TDP is less than that generating the reversed TDP, then we suggest linked pairs generating the given TDP as potentially erroneous IS-A relations. We applied this approach to the Clinical finding and Procedure subhierarchies of the 2022 March US Edition of SNOMED CT, and obtained 52 potentially erroneous IS-A relations and a candidate list of 48 linked pairs. A domain expert confirmed that 41 out of 52 (78.8%) are valid and identified 26 erroneous IS-A relations out of 48 linked pairs.","['Ontologies', 'Knowledge representation, management, or engineering', 'Data/system integration, standardization and interoperability']"
Compulsory Indications in Hospital Prescribing Software Tested with Antibacterial Prescriptions,"The aim was to assess how making the indication field compulsory in our electronic prescribing system influenced free text documentation and to visualise prescriber behaviour. The indication field was made compulsory for seven antibacterial medicines. Text recorded in the indication field was manually classified as 'indication present', 'other text', 'rubbish text', or 'blank'. The proportion of prescriptions with an indication was compared for four weeks before and after the intervention. Indication provision increased from 10.6% to 72.4% (p0.01), and 'rubbish text' from 0.0% to 0.6% (p<0.01). Introducing the compulsory indication field increased indication documentation substantially with only a small increase in 'rubbish text'. An interactive report was developed using a live data extract to illustrate indication provision for all medicines prescribed at our tertiary hospital. The interactive report was validated and locally published to support audit and quality improvement projects.","['Clinical decision support for translational/data science interventions', 'Secondary use of EHR data', 'Advanced data visualization tools and techniques']"
Detecting Cerebral Ischemia from Electroencephalography During Carotid Endarterectomy Using Machine Learning,"Intraoperative stroke is a major concern during high-risk surgical procedures such as carotid endarterectomy (CEA). Ischemia, a stroke precursor, can be detected using continuous electroencephalographic (cEEG) monitoring of electrical changes caused by changes in cerebral blood flow. However, monitoring by experts is currently resource-intensive and prone to error. We investigated if supervised machine learning (ML) could detect ischemia accurately using intraoperative cEEG. Using cEEG recordings from 802 patients, we trained six ML models, including nave Bayes, logistic regression, support vector classifier, random forest (RF), light gradient-boosting machine (LGBM), and eXtreme Gradient Boosting with random forest (XGBoost RF), and tested them on a validation dataset of 30 patients. Each cEEG recording in the validation dataset was labeled independently by five expert neurophysiologists who regularly perform intraoperative neuromonitoring. We did not derive consensus labels but rather evaluated an ML model in a pairwise fashion using one expert as a reference at a time, due to the experts' variability in label determination, which is typical for clinical tasks. The tree-based ML models, including RF, LGBM, and XGBoost RF, performed best, with AUROC values ranging from 0.92 to 0.93 and AUPRC values ranging from 0.79 to 0.83. Our findings suggest that ML models can serve as the foundation for a real-time intraoperative monitoring system that can assist the neurophysiologist in monitoring patients.","['Clinical decision support for translational/data science interventions', 'Patient centered research and care', 'Machine learning and predictive modeling']"
Enhancing Health Data Interoperability with Large Language Models: A FHIR Study,"In this study, we investigated the ability of the large language model (LLM) to enhance healthcare data interoperability. We leveraged the LLM to convert clinical texts into their corresponding FHIR resources. Our experiments, conducted on 3,671 snippets of clinical text, demonstrated that the LLM not only streamlines the multi-step natural language processing and human calibration processes but also achieves an exceptional accuracy rate of over 90% in exact matches when compared to human annotations.","['FHIR', 'Data sharing / interoperability', 'Natural Language Processing']"
Automating Clinical Trial Matches Via Natural Language Processing of Synthetic Electronic Health Records and Clinical Trial Eligibility Criteria,"Clinical trials are critical to many medical advances; however, recruiting patients remains a persistent obstacle. Automated clinical trial matching could expedite recruitment across all trial phases. We detail our initial efforts towards automating the matching process by linking realistic synthetic electronic health records to clinical trial eligibility criteria using natural language processing methods. We also demonstrate how the Srensen-Dice Index can be adapted to quantify match quality between a patient and a clinical trial.","['Natural Language Processing', 'Clinical trials innovations', 'Recruitment technologies']"
Evaluating the Association of Neighborhood Socioeconomic Disadvantage and Risk of Cognitive Decline Using Longitudinal Electronic Health Records,"We investigated the association between living in a disadvantaged area and cognitive decline using a large EHR dataset. Cox proportional hazards models were used to explore the relationship between the area deprivation index and incident MCI/dementia. We found that patients in the top state quintile had a higher incidence rate of MCI/dementia than those in the bottom four quintiles, with a hazard ratio of 1.19 (95% CI 1.06, 1.29) (p<0.01).","['Natural Language Processing', 'Social determinants of health', 'Measuring outcomes']"
Electronic Phenotyping of Urinary Tract Infections as a Silver Standard Label for Machine Learning,"This study explored the efficacy of electronic phenotyping in data labeling for machine learning with a focus on urinary tract infections (UTIs). We contrasted labels from electronic phenotyping against previously published labels such as urine culture positivity. In comparison, electronic phenotyping showed enhanced specificity in UTI labeling while maintaining similar sensitivity and was easily scaled for application to a large dataset suitable for machine learning, which we used to train and validate a machine learning model. Electronic phenotyping offers a valuable method for machine learning label generation in healthcare, with potential benefits for patient care and antimicrobial stewardship. Further research will expand its application and optimize techniques for increased performance.","['EHR-based phenotyping', 'Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling']"
Selection and Implementation of Virtual Scribe Solutions to Reduce Documentation Burden: A Mixed Methods Pilot,"Electronic health record (EHR) documentation is a leading reason for clinician burnout. While technology-enabled solutions like virtual and digital scribes aim to improve this, there is limited evidence of their effectiveness and minimal guidance for healthcare systems around solution selection and implementation. A transdisciplinary approach, informed by clinician interviews and other considerations, was used to evaluate and select a virtual scribe solution to pilot in a rapid iterative sprint over 12 weeks. Surveys, interviews, and EHR metadata were analyzed over a staggered 30 day implementation with live and asynchronous virtual scribe solutions. Among 16 pilot clinicians, documentation burden metrics decreased for some but not all. Some clinicians had highly positive comments, and others had concerns regarding scribe training and quality. Our findings demonstrate that virtual scribes may reduce documentation burden for some clinicians and describe a method for a collaborative and iterative technology selection process for digital tools in practice.","['Reproducible research methods and tools', 'Implementation Science', 'Stakeholder (i.e., patients or community) engagement']"
Latent classes of polysubstance use disorders among US youth and suicide risks: A nationwide EHR Study,"Objective: This study aimed to investigate clinically diagnosed polysubstance use disorders (PUDs) phenotypes and their associated risks for suicidal ideation and suicide attempts among US youth.Methods: This retrospective cohort study uses electronic health record data from HealthJump, including individuals aged 10-25 diagnosed with substance use disorder (SUD) between January 1, 2015, and September 30, 2022. Participants were youth diagnosed with more than one type of SUD within one year of their first SUD diagnosis. Outcomes were suicidal ideation and suicide attempts diagnosed within one and two years after the first SUD diagnosis.Results: Among 89,522 individuals diagnosed with SUD, 13,399 (15.0%) had PUDs. Latent class analysis identified three PUD phenotypes: opioid and unspecified/other PUD phenotype (4,256 [31.8%]); alcohol and cannabis PUD phenotype (4,770 [35.6%]); and cannabis and unspecified/other PUD phenotype (4,373 [32.6%]). Compared to the opioid and unspecified/other PUD phenotype, individuals had a greater likelihood of suicidal ideation in the alcohol and cannabis PUD phenotype (odds ratio [OR] 1.9, 95% CI [1.4-2.5]) and cannabis and unspecified/other PUD phenotype (one-year: 2.1 [1.6-2.8]; two-year: 2.3 [1.8-3.0]). Individuals in the cannabis and unspecified/other PUD phenotype (1.5 [1.1-2.1]) were more likely to have suicide attempts within two years. Conclusions: This study highlights novel US youth PUD phenotypes and reveals that those with cannabis and unspecified/other PUD phenotypes are more likely to experience subsequent suicidal ideation and suicide attempts compared to the opioid and unspecified/other PUD phenotype. Targeted screening and assessment of these phenotypes may contribute to preventing youth suicide.","['EHR-based phenotyping', 'Phenomics and phenome-wide association studies', 'Machine learning and predictive modeling']"
GATEHR: representation learning on electronic health records using pedigree-based graph attention networks,"Recent years have seen a surge of research into methods for modeling disease risk, onset, and progression from electronic health records data. Although it has been well known that family health history is a major predictor for a wide spectrum of diseases, research so far has adopted a limited view of family relations at best, essentially treating individual patients as independent samples. In this work, we address this limitation by building upon recent progress in predicting family relations from electronic health records. We present GATEHR, which models predicted family relations as edges in a graph attention network, and directly integrates this with a medical ontology representation. Taking disease risk prediction as a use case, we demonstrate that GATEHR outperforms state-of-the-art methods across the medical ontology. Additionally, we illustrate the high degree of interpretability of GATEHR by analyzing how its attention mechanism allows us to link a patient's disease risk to the clinical profiles of his/her relatives. We demonstrated that our proposed GATEHR model holds significant potential in electronic health records modeling and patient representation learning. Particularly noteworthy is our model's impact in analyzing Nonalcoholic Fatty Liver Disease (NAFLD) and Nonalcoholic Steatohepatitis (NASH), common liver conditions that are often underdiagnosed. GATEHR has shown promise in identifying NASH patients within the broader NAFLD population, a crucial step in ensuring these patients receive appropriate care. Overall, we believe our results show that GATEHR can be a valuable tool in electronic health records modeling and patient representation learning.","['Secondary use of EHR data', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
VisualSphere: a Web-based Interactive Visualization System for Clinical Research Data,"Clinical research data visualization is integral to making sense of biomedical research and healthcare data. The complexity and diversity of data, along with the need for solid programming skills, can hinder advances in clinical research data visualization. To overcome these challenges, we introduce VisualSphere, a web-based interactive visualization system that directly interfaces with clinical research data repositories, streamlining and simplifying the visualization workflow. VisualSphere is founded on three primary component modules: Connection, Configuration, and Visualization. An end-user can set up connections to the data repositories, create charts by selecting the desired tables and variables, and render visualization dashboards generated by Plotly and R/Shiny. We performed a preliminary evaluation of VisualSphere, which achieved high user satisfaction. VisualSphere has the potential to serve as a versatile tool for various clinical research data repositories, enabling researchers to explore and interact with clinical research data efficiently and effectively.","['Data-driven research and discovery', 'Informatics research/biomedical informatics research methods', 'Advanced data visualization tools and techniques']"
Utilizing Large Language Models to Increase the Performance of Classification Neural Networks,"An important problem impacting healthcare is the lack of available experts. Machine learning (ML) models may help resolve this by aiding in screening and diagnosing patients. However, creating large, representative datasets to train models can be difficult and costly. We evaluated large language models (LLMs) for data creation and augmentation. Using Autism Spectrum Disorders (ASD) as a test, we prompted GPT 3.5 and GPT 4 to generate 4,200 synthetic examples of child behaviors to augment the actual medical observations in the dataset. We used a BERT classifier pretrained on biomedical literature to assess the difference in performance between the datasets. A random sample (N=140) from the LLM-generated data was evaluated by a clinician and found to contain 83% completely correct prompts corresponding to the given label. Augmenting the dataset increased recall by 13.0% but decreased precision by 16.0%. Future work will investigate how different synthetic data characteristics affect ML outcomes.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Data quality']"
Gender Confounding Effects in Dementia Detection with BERT,"Deep learning models have shown promising results in many biomedical tasks. The Cookie Theft picture description task is a standard test for dementia assessments, and Natural Language Processing (NLP) models can take their transcripts to predict dementia cases. However, gender distribution in the training data may confound the target prediction and lead to impaired performance at the time of deployment. In this work, we explore whether such confounding effects exist and evaluate one mitigation approach.","['Informatics research/biomedical informatics research methods', 'Natural Language Processing', 'Machine learning and predictive modeling']"
Evaluation of the Federal Communications Commission Rural Health Care Program's Impacts on Broadband Infrastructures and Telehealth Utilization in Rural Health Clinics,"In this study, we aim to evaluate the Federal Communications Commission fund program for improving healthcare connectivity of rural health clinics using the Center for Medicare and Medicaid Services Limited Data Set claims data. To assess the effectiveness, we investigate the effects of the fund program on the improvement of broadband speeds and the utilization of telehealth using an event study framework.","['Social determinants of health', 'Public health informatics', 'Mobile Health, wearable devices and patient-generated health data']"
Assessing Clinical Acuity in the Emergency Department Using the GPT-3.5 Artificial Intelligence Model,"This paper evaluates the performance of the Chat Generative Pre-trained Transformer (ChatGPT; GPT-3.5) in accurately identifying higher acuity patients in a real-world clinical context. Using a dataset of 10,000 pairs of patient Emergency Department (ED) visits with varying acuity levels, we demonstrate that GPT-3.5 can successfully determine the patient with higher acuity based on clinical history sections extracted from ED physician notes. The model achieves an accuracy of 84% and an F1 score of 0.83, with improved performance for more disparate acuity scores. Among the 500 pair subsample that was also manually classified by a resident physician, GPT-3.5 achieved similar performance (Accuracy = 0.84; F1 score = 0.85) compared to the physician (Accuracy = 0.86, F1 score = 0.87). Our results suggest that, in real-world settings, GPT-3.5 can perform comparably to physicians on the clinical reasoning task of ED acuity determination.","['Natural Language Processing', 'Clinical decision support for translational/data science interventions', 'Public health informatics']"
Multivariate mediation analysis with voxel-based morphometry revealed the neurodegeneration pathways from genetic variants to Alzheimer's Disease,"Neurodegenerative processes are increasingly recognized as potential causative factors in Alzheimer's disease (AD) pathogenesis. While many studies have leveraged mediation analysis models to elucidate the underlying mechanisms linking genetic variants to AD diagnostic outcomes, the majority have predominantly focused on regional brain measure as a mediator, thereby compromising the granularity of the imaging data. In our investigation, using the imaging genetics data from a landmark AD cohort, we contrasted both region-based and voxel-based brain measurements as imaging endophenotypes, and examined their roles in mediating genetic effects on AD outcomes. Our findings underscored that using voxel-based morphometry offers enhanced statistical power. Moreover, we delineated specific mediation pathways between SNP, brain volume, and AD outcomes, shedding light on the intricate relationship among these variables.","['Genotype-phenotype association studies (including GWAS)', 'Biomarker discovery and development', 'Data-driven research and discovery']"
Comparison Between Patient Self-Reported Symptoms and Structured Physician Documentation at Primary Care Visits,Accuracy of symptomatology is critical to unbiased real-world data (RWD) studies with electronic health records (EHR). In this study we evaluated the accuracy and completeness of patient self-reported symptoms at primary care visits compared to physician coding in the EHR. We find that patients self-report symptoms up to nine times more than physician structured documentation. Our results suggest that combining structured codes and patient self-report should enhance the validity of symptom outcomes in RWD studies.,"['Data quality', 'Data/system integration, standardization and interoperability', 'Outcomes research, clinical epidemiology, population health']"
Prospective Performance and Clinical Burden Analysis of the Deterioration Risk Index,"In August 2021, we deployed the Deterioration Risk Index, a novel machine learning algorithm aimed at early identification of pediatric patients at risk of clinical deterioration. Our hospital has since achieved a 25% reduction in deterioration events, with DRI identifying 51% of deteriorating patients with at least 2 hours of lead time. Analysis of EHR data related to DRI alarms and associated situational awareness criteria highlight important opportunities for improved situational awareness program education.","['Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling', 'Implementation Science']"
Automated Information Extraction from Thyroid Operation Narrative: A Comparative Study of GPT-4 and fine-tuned KoELECTRA,"In the rapidly evolving field of healthcare, the integration of artificial intelligence (AI) has become a pivotal component in the automation of clinical workflows, ushering in a new era of efficiency and accuracy. This study focuses on the transformative capabilities of the fine-tuned KoELECTRA model in comparison to the GPT-4 model, aiming to facilitate automated information extraction from thyroid operation narratives. The current research landscape is dominated by traditional methods heavily reliant on regular expressions, which often face challenges in processing free-style text formats containing critical details of operation records, including frozen biopsy reports. Addressing this, the study leverages advanced natural language processing (NLP) techniques to foster a paradigm shift towards more sophisticated data processing systems. Through this comparative study, we aspire to unveil a more streamlined, precise, and efficient approach to document processing in the healthcare domain, potentially revolutionizing the way medical data is handled and analyzed.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Clinical and research data collection, curation, preservation, or sharing']"
Deep Cluster Interpretation of SDoH Subtypes: Towards Human-Centered AI Systems,"Although recent studies have identified social determinants of health (SDoH) subtypes, their interpretation requires human experts with domain knowledge that is broad and deep. Here we investigate whether and how large language models such as GPT-4, can complement human experts' interpretation of SDoH subtypes. The results suggest that while well-designed GPT-4 prompts can generate broad and systematic interpretations of SDoH subtypes, they lack deep integrative concepts spanning multiple subtypes generated by human experts.","['Social determinants of health', 'Data mining and knowledge discovery', 'Natural Language Processing']"
A Study of Biomedical Relation Extraction Using GPT Models,"Relation Extraction (RE) is a natural language processing (NLP) task for extracting the semantic relations between the biomedical entities. Recent developments in the pre-trained large language models (LLM) motivated the NLP researchers to use them for various NLP tasks. We investigated GPT-3.5-turbo and GPT-4 on extracting the relations from two standard datasets, EU-ADR and Gene Associations Database (GAD). Unlike the existing approaches using dataset with masked entities, we used three versions for each dataset for our experiment: a version with masked entities, a second version with original entities (unmasked), and a third version with abbreviations replaced with original terms. We developed the prompts for various versions and used the chat completion model from GPT API. Our approach achieved a F1-score of 0.4983 to 0.8092 for GPT-3.5-turbo, and a highest F1-score of 0.8462 for GPT-4. For certain experiments, the performance of GPT, BioBERT, and PubMedBERT are almost the same.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Reproducible research methods and tools']"
The Social Determinants of Health of Healthy Aging: An Investigation Using the All of Us Cohort,"An aging population is a salient issue worldwide. In this study, we investigated the relationship between social determinants of health (SDoH) and healthy aging. We created a composite healthy aging score considering an individual's age (>75), comorbidities, cognitive ability, and quality of life. We used the AllofUs dataset and exhaustively investigated various sources of SDoH information in AllofUs. Our results showed that various SDoH (e.g., access to free recreational facilities) are strong predictors of healthy aging.","['Data-driven research and discovery', 'Machine learning and predictive modeling', 'Outcomes research, clinical epidemiology, population health']"
Nurse Satisfaction with Machine Learning Derived Clinical Decision Support System Explanations: Examining the Influence of Design Features,"This study examined nurse satisfaction with explanatory displays for Machine Learning (ML) Clinical Decision Support (CDS) tools that predict patients at risk for adverse events. Participants rated displays higher for supporting understanding of ML model workings, explanation satisfaction, and usefulness. However, understanding tool usage, accuracy, and trust in the model received lower ratings. The format and complexity of displays did not significantly impact nurse satisfaction. Future research should emphasize real-world experiences across diverse healthcare settings.","['Clinical decision support for translational/data science interventions', 'Learning healthcare system', 'Machine learning and predictive modeling']"
Counterfactual Sepsis Outcome Prediction Under Dynamic and Time-Varying Treatment Regimes,"Sepsis is a life-threatening condition that occurs when the body's normal response to an infection is out of balance. A key part of managing sepsis involves the administration of intravenous fluids and vasopressors, but prescribing the correct balance of interventions is challenging since both under- and over-resuscitation can lead to adverse outcomes. In this work, we explore the development of G-Net, a deep learning approach to G-computation, to analyze outcomes under counterfactual treatment strategies in a real-world cohort of sepsis patients, using observational data collected from the intensive care unit. We evaluate multiple implementations of G-Net and find that an LSTM-based model performs better than its linear counterpart when predicting patient outcomes and changes in patient physiology over time. We then demonstrate that this model is able to generate counterfactual estimates under alternative regimes that are physiologically plausible as validated by expert clinicians. We hope this work may further improve treatment outcomes for sepsis patients in the ICU and contribute to the advancement of meaningful decision-making tools in clinical practice.","['Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling', 'Outcomes research, clinical epidemiology, population health']"
Synthetic Cohort Data Generation in the All of Us Research Program,"This abstract reports on two synthetically generated participant datasets in the All of Us Research Program, each corresponding to a predefined phenotype (type 2 diabetes and breast cancer). We briefly describe how we, a team affiliated with the Data and Research Center (DRC) of All of Us, developed and evaluated the generated synthetic data, as well as the policy and process designed to access the data for the broader research community.","['Data security and privacy', 'Data sharing / interoperability', 'Health Information and biomedical data dissemination strategies']"
Comparison of Prompt Engineering and Fine-Tuning Strategies in Large Language Models in the Classification of Clinical Notes,"The emerging large language models (LLMs) are actively evaluated in various business sectors including healthcare. Most studies have focused on established benchmarks and standard parameters; however, the variation and impact of prompt engineering and fine-tuning strategies have not been fully explored. Here, using the identification of patients with metastatic cancer from discharge summaries as an example, we extensively compared a wide range of prompting and fine-tuning approaches in popular LLMs including GPT-3.5, GPT-4, Bard, and Llama-7b. We also compared these with previously presented BERT models as well as results manually annotated by medical fellows. We observed that prompts with instruction of reasoning steps outperformed those with a simple description of the task and GPT-4 had the best overall performance among all LLMs. Interestingly, we did not observe additional benefits from few-shot learning or fine-tuning approaches. A well-crafted prompt under the context of zero-shot learning in GPT-4 resulted in remarkable performance, and the result remained robust even when keywords related to metastatic cancer were deleted or half of the tokens were randomly removed from the input text. Nevertheless, all the models are inferior to domain experts in this task, suggesting room for further improvement in LLMs. Moreover, due to privacy concerns about API-based tools, better fine-tuning strategies for open-source models are needed for implementation in the healthcare system.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling']"
FERI: A Multitask-based Fairness Achieving Algorithm with Applications to Fair Organ Transplantation,"Liver transplantation often faces fairness challenges across subgroups defined by sensitive attributes like age group, gender, and race/ethnicity. Machine learning models for outcome prediction can introduce additional biases. To address these, we introduce Fairness through the Equitable Rate of Improvement in Multitask Learning (FERI) algorithm for fair predictions of graft failure risk in liver transplant patients. FERI constrains subgroup loss by balancing learning rates and preventing subgroup dominance in the training process. Our experiments show that FERI maintains high predictive accuracy with AUROC and AUPRC comparable to baseline models. More importantly, FERI demonstrates an ability to improve fairness without sacrificing accuracy. Specifically, for gender, FERI reduces the demographic parity disparity by 71.74%, and for the age group, it decreases the equalized odds disparity by 40.46%. Therefore, the FERI algorithm advances fairness-aware predictive modeling in healthcare and provides an invaluable tool for equitable healthcare systems.","['Biomedical informatics and data science workforce education', 'Machine learning and predictive modeling', 'Ethical, legal, and social issues']"
Practical OMOP: Daily Updates Leveraging the Epic EHR's Native Tools,"To begin participating in OHDSI network studies, we leveraged Epic's Caboodle extract-transform-load (ETL) framework for efficient population of OMOP Common Data Model tables with a full set of our Epic EHR data. Our CTSA hub successfully implemented 25 OMOP tables as shareable Caboodle code, providing nightly updates covering one's full history on the Epic EHR. Using Caboodle's capabilities, health systems can streamline OMOP implementation, optimizing cost and broadening the OHDSI network representation.","['Data transformation/ETL', 'Open Science for biomedical research and translational medicine', 'Secondary use of EHR data']"
Transatlantic Phenotype Alignment for Post Acute Sequelae of SARS-CoV-2 (PASC): Mapping Challenges Across ICD10 and SNOMED Vocabularies,"This paper describes the unexpected challenges arising when translating across US- and UK-developed computable phenotypes arising from missing ICD10/SNOMED mappings for commonly-used diagnostic terms. These code-level disparities need to be addressed before we can focus on higher-level challenges such as population bias, and health system variations, all of which contribute to relatively few successful trans-Atlantic observational studies.","['EHR-based phenotyping', 'Ontologies']"
"RescueGPT: Recognition, Extraction, Surveillance, and Conceptualization Using Emergency Medical Service Notes with a Zero-Shot Approach with Large Language Models -- A Pilot Study","Our study aims to develop an automated tool to identify preventable adverse events in pediatric out-of-hospital cardiac arrest (OHCA) cases. The tool, called RescureGPT, leverages a language learning model (LLM) to analyze unstructured data from Emergency Medical Service notes. Our model extracts critical information from the notes, including patient age, rhythm, weight, and details of any procedural complications. Initial results show promising levels of accuracy and effectiveness. The tool has the potential to significantly improve the detection rate of adverse safety events, increasing the pace and scale of detection, while reducing costs.","['Data mining and knowledge discovery', 'Natural Language Processing', 'Ontologies']"
LLMs for Precision Psychiatry: A Preliminary Evaluation of Large Language Models for Automated Extraction of OPCRIT Symptom Rating,"Clinical notes contain valuable information about a patient's psychiatric symptoms and phenotypes. Manual review of notes to extract this information is inefficient. Recent advances in natural language processing using large language models present opportunities to accurately and automatically extract psychiatric phenotypes from free text. In this work, we evaluate large language models in a zero-shot setting for their ability to extract diverse psychiatric phenotypes that range from keyword identification corresponding to specific, directly observable symptoms like irritability, as well as abstract phenotypes requiring reading comprehension, such as responding to hallucinations.","['Natural Language Processing', 'EHR-based phenotyping', 'Data-driven research and discovery']"
Voice-Enabled Response Analysis Agent (VERAA): Leveraging Large Language Models to Map Voice Responses in SDoH Survey,"Social Determinants of Health (SDoH) have been shown to have profound impacts on health-related outcomes, yet this data suffers from high rates of missingness in electronic health records (EHR). Moreover, limited English proficiency in the United States can be a barrier to communication with health care providers. In this study, we have designed a multilingual conversational agent capable of conducting SDoH surveys for use in healthcare environments. The agent asks questions in the patient's native language, translates responses into English, and subsequently maps these responses via a large language model (LLM) to structured options in a SDoH survey. This tool can be extended to a variety of survey instruments in either hospital or home settings, enabling the extraction of structured insights from free-text answers. The proposed approach heralds a shift towards more inclusive and insightful data collection, marking a significant stride in SDoH data enrichment for optimizing health outcome predictions and interventions.","['Social determinants of health', 'Machine learning and predictive modeling', 'Clinical and research data collection, curation, preservation, or sharing']"
Predicting the Disposition of Patients Undergoing Primary Total Hip and Total Knee Arthroplasty Using Machine Learning,"Total knee replacement (TKR) and total hip replacement (THR) are frequently performed surgeries in the United States and the disposition at discharge (home vs. facility) is an important outcome with clinical and financial implications. Regional anesthesia has been associated to reduced hospital stay in the literature and to higher odds to be discharged home in a recent paper published by our department. Machine Learning (ML) has been frequently used in medicine but its use to predict disposition after surgery has not been explored before. Using the same dataset used in our prior publication on the association of type of anesthesia to disposition, we tested the ability of different ML models to correctly classify disposition after THK and THR using precision, recall, F-1 score, accuracy, area under the receiver operating characteristics curve (AUROC) and area under the precision-recall curve (AUPRC) as standard parameters. The 3 top-performing models were chosen for additional optimization and to be incorporated into 2 different ensemble methods: a simple Voting Classifier and a more complex Stacked Generalization. ML showed excellent performance, with ensemble methods resulting in slightly better prediction compared to single models alone. This study confirms that ML is an excellent tool for outcome prediction even in Anesthesiology and proves to be an indispensable tool for the future of Medical Informatics.","['Data-driven research and discovery', 'Measuring outcomes', 'Machine learning and predictive modeling']"
Automated Family Histories Significantly Improve Risk Prediction in an EHR,"We recently demonstrated that electronically constructed family pedigrees (e-pedigrees) have great value in epidemiologic research using electronic health record (EHR) data. Prior to this work, it has been well accepted that family health history is a major predictor for a wide spectrum of diseases, reflecting shared effects of genetics, environment, and lifestyle. With the widespread digitalization of patient data via EHRs, there is an unprecedented opportunity to use machine learning algorithms to better predict disease risk. Although predictive models have previously been constructed for a few important diseases, we currently know very little about how accurately the risk for most diseases can be predicted. It is further unknown if the incorporation of e-pedigrees in machine learning can improve the value of these models. In this study, we devised a family pedigree-driven high-throughput machine learning pipeline to simultaneously predict risks for thousands of diagnosis codes using thousands of input features. Models were built to predict future disease risk for three time windows using both Logistic Regression and XGBoost. For example, we achieved average areas under the receiver operating characteristic curves (AUCs) of 0.82, 0.77 and 0.71 for 1, 6, and 24 months, respectively using XGBoost and without e-pedigrees. When adding e-pedigree features to the XGBoost pipeline, AUCs increased to 0.83, 0.79 and 0.74 for the same three time periods, respectively. E-pedigrees similarly improved the predictions when using Logistic Regression. These results emphasize the potential value of incorporating family health history via e-pedigrees into machine learning with no further human time.","['Secondary use of EHR data', 'Public health informatics', 'Machine learning and predictive modeling']"
Developing an Accurate and Racially Unbiased Risk-based Model to Determine Lung Cancer Screening Eligibility among White and African American Smokers,"Developing an appropriate lung cancer screening (LCS) eligibility standard plays an important role in reducing lung cancer mortality rate. Machine learning (ML) approaches can be used to develop LCS eligibility models by predicting the risk of a smoker's getting lung cancer and classifying the smoker as LCS-eligible if his/her predicted risk exceeded a threshold. However, the training and testing datasets to generate and validate these risk-based ML models may include ingrained racial bias between White and African American (AA) smoker groups. The ML models developed from these datasets will reinforce the racial bias in determining smokers' LCS eligibility. The purpose of this study is to develop a racially unbiased LCS eligibility model to accurately and fairly pinpoint White and AA smokers at high risk. Before and after mitigating the racial bias, we developed ML models to predict lung cancer risk for the identification of LCS-eligible smokers and compared them to the USPSTF criteria in terms of accuracy and fairness. Numerical experiments show that there exists racial bias between White and AA smoker groups in our training and testing datasets. While the ML models can significantly improve the sensitivity of lung cancer prediction without loss of specificity compared to the 2021 USPSTF criteria, the ML model developed based on the biased datasets can lead to unfair LCS eligibility identification. Only the ML model with bias mitigation is an accurate and racially unbiased approach to determine smokers' LCS eligibility.","['Data-driven research and discovery', 'Machine learning and predictive modeling', 'Outcomes research, clinical epidemiology, population health']"
Real-Time Obstructive Sleep Apnea Detection from Raw ECG and SpO2 Signal Using Convolutional Neural Network,"Obstructive sleep apnea is a sleep disorder that is linked with many health complications and severe form of apnea can even be lethal. Overnight polysomnography is the gold standard for diagnosing apnea, which is expensive, time-consuming, and requires manual analysis by a sleep expert. Recently, there have been numerous studies demonstrating the application of artificial intelligence to detect apnea in real time. But the majority of these studies apply data pre-processing and feature extraction techniques resulting in a longer inference time that makes the real-time detection system inefficient. This study proposes a single convolutional neural network architecture that can automatically extract spatial features and detect apnea from both electrocardiogram (ECG) and blood-oxygen saturation (SpO2) signals. Using segments of 10s, the network classified apnea with an accuracy of 94.2% and 96% for ECG and SpO2 respectively. Moreover, the overall performance of both models was consistent with an AUC score of 0.99.","['Data-driven research and discovery', 'Mobile Health, wearable devices and patient-generated health data', 'Machine learning and predictive modeling']"
Automatic Population of the Case Report Forms for an International Multifactorial Adaptive Platform Trial Amid the COVID-19 Pandemic,"Objectives: To automatically populate the case report forms (CRFs) for an international, pragmatic, multifactorial, response-adaptive, Bayesian COVID-19 platform trial. Methods: The locations of focus included 27 hospitals and 2 large electronic health record (EHR) instances (1 Cerner Millennium and 1 Epic) that are part of the same health system in the United States. This paper describes our efforts to use EHR data to automatically populate four of the trial's forms: baseline, daily, discharge, and response-adaptive randomization. Results: Between April 2020 and May 2022, 417 patients from the UPMC health system were enrolled in the trial. A MySQL-based extract, transform, and load pipeline automatically populated 499 of 526 CRF variables. The populated forms were statistically and manually reviewed and then reported to the trial's international data coordinating center. Conclusions: We accomplished automatic population of CRFs in a large platform trial and made recommendations for improving this process for future trials.","['Clinical trials innovations', 'Clinical and research data collection, curation, preservation, or sharing']"
Enhancing Clinical Predictive Modeling through Model Complexity-Driven Class Proportion Tuning for Class Imbalanced Data: An Empirical Study on Opioid Overdose Prediction,"Class imbalance issues are prevalent in the medical field and significantly impact the performance of clinical predictive models. Traditional techniques to address this challenge aim to rebalance class proportions. They generally assume that the rebalanced proportions are derived from the original data, without considering the intricacies of the model utilized. This study challenges the prevailing assumption and introduces a new method that ties the optimal class proportions to model complexity. This approach allows for individualized tuning of class proportions for each model. Our experiments, centered on the opioid overdose prediction problem, highlight the performance gains achieved by this approach. Furthermore, rigorous regression analysis affirms the merits of the proposed theoretical framework, demonstrating a statistically significant correlation between hyperparameters controlling model complexity and the optimal class proportions.","['Data mining and knowledge discovery', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
Crowdsourcing with Enhanced Data Quality Assurance: An Efficient Approach to Mitigate Resource Scarcity Challenges in Training Large Language Models for Healthcare,"In artificial intelligence, Large Language Models (LLMs) have demonstrated immense potential across various applications, including healthcare. However, their efficacy is hindered by the resource-intensive nature of training and the need for high-quality labeled data, particularly in low-resource domains like healthcare. To address these challenges, we propose a crowdsourcing (CS) framework enriched with quality control measures at the pre-, real-time-, and post-data gathering stages. Our study evaluated the effectiveness in enhancing data quality through its impact on LLMs (Bio-BERT) for predicting autism-related symptoms. The results show that real-time quality control improves data quality by 19% compared to Pre quality control. Fine-tuning Bio-BERT using crowdsourced data also demonstrated notable performance enhancements, increasing precision (ranging 4%-10% across different labels) while maintaining recall. Our findings highlighted the potential of crowdsourcing and quality control in resource-constrained environments and offered insights into optimizing healthcare LLMs for informed decision-making and improved patient care.","['Data quality', 'Natural Language Processing', 'Machine learning and predictive modeling']"
PFERM: A Fair Empirical Risk Minimization Approach with Prior Knowledge,"Fairness is crucial in machine learning to prevent bias based on sensitive attributes in classifier predictions. However, the pursuit of strict fairness often sacrifices accuracy, particularly when significant prevalence disparities exist among groups, making classifiers less practical. For example, Alzheimer's disease (AD) is more prevalent in women than men, making equal treatment inequitable for females. Accounting for prevalence ratios among groups is essential for fair decision-making. In this paper, we introduce prior knowledge for fairness, which incorporates prevalence ratio information into the fairness constraint within the Empirical Risk Minimization (ERM) framework. We develop the Prior-knowledge-guided Fair ERM (PFERM) framework, aiming to minimize expected risk within a specified function class while adhering to a prior-knowledge-guided fairness constraint. This approach strikes a flexible balance between accuracy and fairness. Empirical results confirm its effectiveness in preserving fairness without compromising accuracy.","['Data-driven research and discovery', 'Public health informatics', 'Machine learning and predictive modeling']"
"FHIRing up OpenMRS: Architecture, Implementation and Real-World Use-Cases in Global Health","HL7 FHIR was created almost a decade ago and is seeing increasingly wide use in high income settings. Although some initial work was carried out in low and middle income (LMIC) settings there has been little impact until recently. The need for reliable and easy to implement interoperability between health information systems in LMICs is growing with large scale deployments of EHRs, national reporting systems and mHealth applications. The OpenMRS open source EHR has been deployed in more than 44 LMIC with increasing needs for interoperability with other HIS. We describe here the development and deployment of a new FHIR module supporting the latest standards and its use in interoperability with laboratory systems, mHealth applications, pharmacy dispensing system and as a tool for supporting advanced user interface designs. We also show how it facilitates date science projects and deployment of machine leaning based CDSS and precision medicine in LMICs.","['FHIR', 'Data/system integration, standardization and interoperability', 'Implementation Science']"
Improving Automating Quality Control in Radiology: Leveraging Large Language Models to Extract Correlative Findings in Radiology and Operative Reports,"Radiology plays a pivotal role in medical diagnostics, providing clinicians with insights into patient health and guiding the next steps in treatment. The true value of a radiological image lies in the accuracy of its accompanying report. To ensure the reliability of these reports, they are often cross-referenced with operative findings. The conventional method of manually comparing radiology and operative reports is labor-intensive and demands specialized knowledge. This research presents an innovative method using Natural Language Processing (NLP) to simplify this evaluation by automatically extracting pertinent details from these reports, focusing especially on the shoulder's primary anatomical structures. A fine-tuned Large Language Model efficiently identifies mentions of the supraspinatus tendon, infraspinatus tendon, subscapularis tendon, biceps tendon, and glenoid labrum in radiology and operative documents. Initial findings emphasize the model's capability to pinpoint relevant data, suggesting a transformative approach to the typical evaluation methods in radiology. This novel method not only makes the evaluation process more efficient but also offers potential enhancements to the learning curve for radiologists, promoting ongoing advancements in radiological assessments.","['Natural Language Processing', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
Leveraging GPT models to intuitively structure free-text clinical notes,"In this pilot study, we","['Informatics research/biomedical informatics research methods', 'Learning healthcare system', 'Knowledge representation, management, or engineering']"
Improving Digital Pathology Pipelines using Shapley-based Data Debugging,"Digital pathology pipelines have gained more prominence in recent years as a powerful method for automatically analyzing biomedical data and making predictions about diagnostic outcomes. However, due to the semi-supervised machine learning methods that are being used for their development, they are susceptible to data quality issues, and specifically mislabeled data examples. In this work, we apply data debugging methods that leverage the Shapley value as a measure of data importance in order to identify the data examples that are most likely causing pipelines to underperform. We show that by using these methods we can observe significant gains in pipeline performance and by removing 10% of the data examples we manage to gain around a 2% increase in pipeline quality scores.","['Data quality', 'Informatics research/biomedical informatics research methods', 'Biomedical informatics and data science workforce education']"
Development and Validation of an Individual Socioeconomic Deprivation Index (ISDI) in the NIH's All of Us Data Network,"Many of the existing composite social determinant of health indices, such as Area Deprivation Index, are constrained by their reliance on geographic approximations and American Community Survey data. This study builds on the body of literature around deprivation indices to construct an individual socioeconomic deprivation index (ISDI) within the NIH's All of Us Data Network by using weighted multiple correspondence analysis on SDOH data elements collected at the participant level. In this study, the correlation between ISDI and another area-approximated index is assessed to the extent possible, along with the changes in an AI models performance due to stratified sampling based on ISDI quintiles. Individual level deprivation indices may have a wide range of utility particularly in the context of precision medicine in both centralized and distributed data networks.","['Social determinants of health', 'Data/system integration, standardization and interoperability', 'Ethical, legal, and social issues']"
