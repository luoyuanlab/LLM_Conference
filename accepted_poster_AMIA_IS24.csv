row_id,submission_TITLE,HIGHLIGHTED THEME (OPTIONAL),submission_ABSTRACT,KEYWORDS_SELECTION
1,Evaluating the effect of frame rate in sequence-based classification of autism-related self-stimulatory hand idiosyncrasies,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","Autism spectrum disorder (ASD) affects a substantial population globally, necessitating efficient, scalable, and accessible detection methods. While machine learning offers promise, conventional CNN models have the propensity to overfit when trained on small datasets. In this study, we evaluated two models: an LSTM-based and a faster GRU-based model on the SSBD dataset. Both outperformed CNN models, with peak accuracies of 97.5% (LSTM) and 98.75% (GRU) achieved when sampling videos every 15 frames. We further find that sampling every other frame performs optimally compared with other sampling rates. Our work demonstrates the potential for low-parameter models to provide a solution to cost-effectiveA SD diagnosis, especially in developing countries.","['Clinical decision support for translational/data science interventions', 'Biomarker discovery and development', 'Machine learning and predictive modeling']"
2,Developing Prompts from Large Language Model for Extracting Clinical Information from Pathology and Ultrasound Reports in Breast Cancer,Harnessing the Power of Large Language Models in Health Data Science,"Objectives: We aimed to assess the efficiency, accuracy, and cost-effectiveness of utilizing a large language model (LLM) to extract clinical factors from surgical pathology and ultrasound reports of breast cancer patients.Methods: Data from breast cancer patients (2020-2022) undergoing radiotherapy were collected. The 'LLM' method, employing GPT for SheetsTM and DocsTM, was used to extract information. Prompt development time and cost were compared against 'Full manual' and 'LLM-assisted manual' methods. Accuracy was evaluated by comparing LLM-extracted data with 'Full manual' data for 60 randomly selected patients.Results: Data from 2,931 patients were collected. We created 12 prompts each for Extract and Format functions, achieving 88.3% overall accuracy. Notably, surgery type and lymphovascular invasion had 100% accuracy. Prompt development took 3.5 hours, processing 15 minutes. Using ChatGPT API incurred a $65.8 cost; including wage estimates totaled $91.7. 'LLM-assisted manual' and 'LLM' methods were efficient and cost-effective compared to 'Full manual'.Conclusion: Efficient prompt development for LLM facilitated the extraction of vital clinical information from extensive medical records, showcasing the potential of natural language processing with LLM models in breast cancer research. Our prompts can benefit other studies collecting clinical data. This study underscores the value of LLMs in enhancing clinical information extraction processes.","['Natural Language Processing', 'EHR-based phenotyping', 'Clinical and research data collection, curation, preservation, or sharing']"
3,Association Rule Mining of Real-World Data: Uncovering Risk Patterns for Suicide Attempts in Individuals with Diabetes,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"We included 3,266,856 people with diabetes from Cerner Real-World Data™ to identify a high-risk group of suicide attempts among patients with diabetes utilizing association rule mining. The study confirms the links between type 2 diabetes, anxiety, depression, and suicide attempts in individuals with diabetes. New findings associated with suicide attempts from our study included race identified as White, average blood glucose 100 mg/dl.","['Data mining and knowledge discovery', 'Data-driven research and discovery', 'Secondary use of EHR data']"
4,Cybersecurity in Disaster Telehealth: The National Emergency Tele-Critical Care Network (NETCCN) Experience,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","In recent decades, digital telehealth technologies have been deployed at an increasing rate. An important but under-reported aspect of this transformation has been an increase in the vulnerability of health care infrastructure to cybersecurity threats. This is true in everyday patient care, but also in disasters and mass casualties, where telehealth technologies may be rapidly deployed and scaled to address surge capacity and improve access to emergency or specialty care. Here we report on the cybersecurity threats encountered during early deployments of the National Emergency Tele-Critical Care Network, a web-enabled health information and communications platform designed to bring high-quality critical care expertise to any location in the United States.","['Data security and privacy', 'Mobile Health, wearable devices and patient-generated health data']"
5,GRU-D-Weibull: A Novel Real-Time Individualized Endpoint Prediction,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Accurate prediction models for individual-level endpoints and time-to-endpoints are crucial in clinical practice. In this study, we propose a novel approach, GRU-D-Weibull, which combines gated recurrent units with decay (GRU-D) to model the Weibull distribution. Our method enables real-time individualized endpoint prediction and population-level risk management. Using a cohort of 6,879 patients with stage 4 chronic kidney disease (CKD4), we evaluated the performance of GRU-D-Weibull in endpoint prediction. The C-index of GRU-D-Weibull was ~0.7 at the index date and increased to ~0.77 after 4.3 years of follow-up, similar to random survival forest. Our approach achieved an absolute L1-loss of ~1.1 years (SD=0.95) at the CKD4 index date and a minimum of ~0.45 years (SD=0.3) at 4 years of follow-up, outperforming competing methods significantly. GRU-D-Weibull consistently constrained the predicted survival probability at the time of an event within a smaller and more fixed range compared to other models throughout the follow-up period. We observed significant correlations between the error in point estimates and missing proportions of input features at the index date (correlations from ~0.1 to ~0.3), which diminished within 1 year as more data became available. By post-training recalibration, we aligned the predicted and observed survival probabilities across multiple prediction horizons at different time points during follow-up. The findings underscore the promise of the GRU-D-Weibull architecture as a suitable candidate for real-time individualized CKD4 endpoint risk management, calling for additional refinements and clinical confirmation.","['Data-driven research and discovery', 'Clinical decision support for translational/data science interventions', 'Secondary use of EHR data']"
6,Real World Evidence of Cardiotoxicity: Breast Cancer Oncology Regimens,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"This study investigates the cardiotoxicity effects of eight common chemotherapy drugs used in breast cancer treatment based on 6,299 de-identified patient records. The findings reveal elevated low-density lipoprotein cholesterol levels and marginal ejection fraction, among other conditions. These results underscore the need for clinicians to consider cardiovascular risks when planning cancer treatment. The study contributes real-world evidence to the cardio-oncology field, emphasizing the necessity for ongoing monitoring and further research to mitigate these complications.","['Informatics research/biomedical informatics research methods', 'Patient centered research and care', 'Informatics for cancer immunotherapy']"
7,"15,242 Ways to Die: Developing and testing a method to extract an inferred concept with Canary",,"Medical Examiner databases have a large proportion of unstructured text fields for capturing data for investigation of death, not research. As such, research documentation tends to be inferred from the notes rather than simply extracted electronically. This study seeks to determine the location and condition of the body at time of death, called cadaver condition, from scene and decedent notes in a medical examiner database. Natural Language Processing (NLP) was performed using Canary NLP software. After NLP, a set of rules were determined and applied to establish cadaver condition, as different combinations of text could be extracted. An F1 score of 0.86 on the testing sample indicates that the model works well to determine this inferred data. Although this field is difficult to electronically extract due a to lack of structured fields, NLP provides an option for ascertaining the cadaver condition of the decedent.",['Natural Language Processing']
8,Prediction and uncertainty quantification of medical diagnosis through neural machine translation of clinical procedure codes,,A Clinical Decision Support System (CDSS) is an interactive recommendation system that facilitates clinical decision-making. These systems suffer from challenges rooted in the high complexities of medical knowledge and low accessibility of patient data. We developed a framework capable of accurate prediction and uncertainty quantification (UQ) of medical diagnoses which is able to track and assess patients’ conditions via effective UQ through the utilization of neural machine translation of clinical procedure codes and Shannon’s entropy.,"['Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling']"
9,Retrospective evaluation of QTc Drug-Drug interaction (DDI) Clinical Decision Support (CDS) alerts and Tisdale risk score calculator utilization in the inpatient setting at Brigham and Women’s Hospital (BWH),Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,Clinical Decision Support (CDS) Drug-Drug Interaction (DDI) alerts in the electronic health record usually exclude patient-specific factors. The Tisdale risk score calculator uses clinical variables to predict which hospitalized patients are at high risk for QTc prolongation. The goal of the study was to determine the rate of QTc DDI overrides and Tisdale risk scores. A secondary outcome was to determine the rate of Adverse Drug Events associated with overrides.,"['Clinical decision support for translational/data science interventions', 'Measuring outcomes', 'Enterprise data warehouse/Data lake']"
10,Development of a Decision-Making Support System for Children with Pneumonia in Pediatric Intensive Care Units,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","This study leverages clinical data from the National Taiwan University Hospital Pediatric Intensive Care Unit (PICU) database to develop machine learning models for predicting mortality risk in pediatric patients with pneumonia. These models offer versatility, as they can be employed upon the ICU admission or during the ICU stay, even in cases where laboratory data is not readily available. The primary aim is to mitigate the burden on healthcare professionals and support clinical decision-making.","['Clinical decision support for translational/data science interventions', 'Measuring outcomes', 'Machine learning and predictive modeling']"
11,Classification of Ejection Fraction Values Using Large Language Models,Harnessing the Power of Large Language Models in Health Data Science,"Clinical Natural Language Processing has benefited from pre-trained Large Language Models (LLMs). This study applies LLMs to classify left ventricular ejection fraction (LVEF) values. Our models use a collection of phrases containing LVEF and quantitative values to assign each echocardiogram report one of three categories: ‘40% or below, ‘41 to 49%’, or ‘50% or above’. We hypothesize that LLMs with quantitative reasoning ability can improve classification of LVEF values at the document level. We created transformer-based models using various LLMs. We used the BlueBERT, GPT2 to fine-tune the target task. We also employed more recent LLMs such as DeBERTa and Flan-T5 which have better mechanisms to handle long sentences and represent each word more effectively. All LLM models outperformed the traditional machine learning model, which showed the efficiency of LLMs in handling quantitative values. DeBERTa and Flan-T5 were the best performing models despite not being pre-trained on medical texts. Our study showed that leveraging LLMs can improve text classification with numeric expressions.","['Natural Language Processing', 'Machine learning and predictive modeling']"
12,A Survey of Clinical Algorithms with Race,,"There is growing awareness that clinical algorithms that incorporate an individual’s race as an input variable may cause health care disparities, especially in racial minorities. To raise awareness of race in clinical decision making and track progress toward eliminating its inappropriate use, we identified 46 race-based clinical algorithms and characterized them on specialty, country of origin, model type, output type, and target user. We also built an online database of the identified algorithms.","['Social determinants of health', 'Patient centered research and care', 'Ethical, legal, and social issues']"
13,Develop a PCC surveillance database for tracking post-COVID-19 conditions by Microsoft Access,,"This project is an integral component of the CDC's PCC surveillance initiative. By employing Microsoft Access as our Database Management System, established a secure and HIPAA-compliant database for storing, analyzing, and tracking post-COVID-19 condition data. The objective of this project is to assess the suitability of Microsoft Access for creating user-friendly surveillance databases and to explore its potential utility in diverse COVID-19 research endeavors and beyond.","['Clinical and research data collection, curation, preservation, or sharing', 'Data/system integration, standardization and interoperability']"
14,Comparing Prevalence of Adverse Drug Events Identified in Structured EHR Data to Clinical Trial Benchmark,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,After-market surveillance of adverse drug events (ADEs) is a critical component of real-world data. Documentation of ADEs is often found in unstructured notes that can require complex methods and workflows to parse. This study explores methods for using structured electronic health record data to identify ADEs in patients receiving systemic anti-cancer therapy. The prevalence of ADEs using these methods is approximately one third of those reported in a clinical trial studying a similar patient population.,"['Data-driven research and discovery', 'Secondary use of EHR data', 'Drug discovery, repurposing, and side-effect discovery']"
15,Improving Discharge and Contingency Planning Using AI-Generated Feedback,,"This study explored the use of AI-generated feedback to improve discharge and contingency planning. Physicians created prompts for the GPT-4 AI system, allowing it to analyze medical notes and provide narrative feedback, including example discharge or contingency planning recommendations. Outputs were assessed using a 5-point Likert scale for understandability, bias, clinical relevance, and clinical usefulness. In total, 67 suggestions met the criteria for distribution, while 15 did not due to lack of clinical “usefulness”.","['Patient centered research and care', 'EHR-based phenotyping', 'Machine learning and predictive modeling']"
16,Characterizing Disclosures of Sexual Trauma in the Electronic Health Record Using Care Site Data and Natural Language Processing,,"This study explores the clinical contexts and a natural language processing model for the detection of references to sexual abuse (SA) in 3 million clinical notes from Vanderbilt University Medical Center. Psychiatric and obstetric specialties are over-represented in these references than would be expected by chance. The model has a precision of 0.97, a recall of 0.99, and an F1 score of 0.98. Researchers can use this methodology to advise decisions about SA screening protocols.","['Natural Language Processing', 'Secondary use of EHR data', 'Informatics research/biomedical informatics research methods']"
17,Identification of Ventilator-Associated Pneumonia: A Comparison of ICD Codes and Physician Review,,"Ventilator-associated pneumonia (VAP) is a frequent and serious complication in intensive care units with high mortality. Accurate identification of VAP has clinical, health system, and research implications. International Classification of Diseases (ICD) codes for VAP are routinely used for administrative and research purposes, the reliability has been questioned. Thus, this study compared the accuracy of ICD codes against physician review for the diagnosis of VAP.","['Data quality', 'EHR-based phenotyping', 'Clinical and research data collection, curation, preservation, or sharing']"
18,Addressing NC Children’s Mental Health Disparity with a Virtual Community House,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,"Recognizing the critical role of mental health in overall well-being, our project targets the concerning prevalence of child mental health issues in the United States, especially in North Carolina. We created a 3D virtual mental health community house on Roblox to educate, empower, and support children, with the potential to advance mental health education and research, benefiting both the mental health and informatics fields.","['Patient centered research and care', 'Education and Training', 'Stakeholder (i.e., patients or community) engagement']"
19,"Identifying Psychosis Episodes in Admission Notes: A Comparative Study of Rule-based Methods, Machine Learning Algorithms, and Pre-Trained Language Models",Harnessing the Power of Large Language Models in Health Data Science,"This study examined the efficacy of various methods for identifying psychosis in 4,732 psychiatric admission notes. We compared rule-based algorithms, machine learning classifiers like XGBoost, and pre-trained language models (PLMs). Results showed that XGBoost outperformed other methods, achieving an F1 score of 0.8881, while rule-based and PLMs lagged behind. The study emphasizes the potential of machine learning, especially XGBoost, in improving diagnostic accuracy in psychiatric care, and suggests further research on feature selection and error analysis.","['EHR-based phenotyping', 'Natural Language Processing', 'Machine learning and predictive modeling']"
20,Slow worsening toward acute cardiovascular diseases in patients with lifestyle-related diseases: Longitudinal study using a large clinical database at Kochi Medical School Hospital,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"BACKGROUND: Elderly patients having one or more of three major lifestyle-related diseases (LRDs), including diabetes mellitus, hypertension, and hyperlipidemia, are more likely to develop acute cardiovascular diseases (A-CVDs), such as acute cerebrovascular disease (A-CBVD) and acute ischemic heart disease (A-IHD). We investigated how status of LRD patients would slowly worsen toward the onset of A-CVDs several or more years in the future. METHODS: Coded data accumulated in a clinical database having about 340,000 patients at Kochi Medical School Hospital were used. Patients who were 51 years old or older, did not receive any cancer therapies, had one or more LRDs, and developed A-CVDs between five and ten years after LRD diagnosis were selected. Whether these patients developed increased LRDs or other diseases increasing the risk for A-CVDs, such as chronic kidney disease, chronic liver disease, and angina, was investigated. RESULTS: There were 55 cases of A-IHD and 377 of A-CBVD that appeared between five and ten years after LRD diagnosis. The percentages of cases having two or more LRDs or one or more risk diseases were 35% and 24% in A-IHD cases and A-CBVD cases, respectively, at the time of LRD diagnosis, and they increased greatly to 93% and 75% in A-IHD cases and A-CBVD cases, respectively, at the onset of A-IHD and A-CBVD. CONCLUSION: It was found that, in many patients developing A-CVDs between five and ten years after LRD diagnosis, their status clearly worsened slowly toward the onset of A-CVDs.","['Data-driven research and discovery', 'Outcomes research, clinical epidemiology, population health']"
21,Design and Validation of Machine Learning Models Utilizing Pre- and Intra-operative EHR Data to Predict Postoperative Delirium,Proactive Machine Learning in Biomedical Applications: The Power of Generative AI and Reinforcement Learning,"This study aims to design and validate machine learning models to predict postoperative delirium (POD) using preoperative and intraoperative features from patient EHR data, and to compare outcomes across cardiac and non-cardiac surgery cohorts. Utilizing both preoperative and intraoperative risk factors between these distinct patient groups is critical for a comprehensive understanding of patients’ risk of developing POD. This can guide tailoring of patient care to enhance patient prognosis and surgical decision-making across surgical subgroups.","['EHR-based phenotyping', 'Data mining and knowledge discovery', 'Machine learning and predictive modeling']"
22,THRESHOLD: A Comprehensive Transcriptomic Analysis Tool for Evaluating Gene Saturation and Impact in Disease Progression,Implementation Science and Deployment in Informatics: From Theory to Practice,"Gene expression analysis is fundamental in molecular biology for deciphering cellular function and understanding diseases. To tackle the complexities of large datasets, the THRESHOLD software was developed, employing Python and Java with essential libraries. It utilizes saturation analysis to identify highly expressed genes shared among diverse patient datasets, offering a novel approach to uncovering common gene expression patterns. THRESHOLD features 'Incremental Saturation' for in-depth analysis at specific ranks and 'Overall Saturation' for a comprehensive overview. Users can customize saturation types, restriction factors, and rank types, generating interactive saturation graphs and identifying saturated genes.THRESHOLD's significance lies in its ability to consistently identify regulated genes in diseases, with user-defined parameters, providing insights into potential drug targets, disease pathways, and gene networks. THRESHOLD has the potential to advance our understanding of molecular signatures, refine patient stratification, and facilitate tailored therapeutic interventions, making it a valuable resource in molecular biology research. THRESHOLD is freely available at https://github.com/alperuzun/THRESHOLD","['Transcriptomics', 'Data-driven research and discovery', 'Genomics/Omic data interpretation']"
23,"Data Governance for Sharing and Access to Real-World Data at University of Iowa Healthcare, a Case Study",,"Data governance enables secondary use of clinical data for research, including policies and procedures for managing data to ensure accuracy, completeness, consistency, and security. Establishing standards for collection, storage, sharing, and assigning roles and responsibilities for managing data is critical throughout a project’s lifecycle. This describes the evolution of UI HealthCare’s data governance for research, development of an external data sharing process, implementation of related processes, continuous improvement and ongoing observations of data governance maturity.","['Data sharing / interoperability', 'Enterprise data warehouse/Data lake', 'Sustainable research data infrastructure']"
24,Evaluating ChatGPT as an Adjunct for Clinical Data Extraction,Harnessing the Power of Large Language Models in Health Data Science,"This case report investigates the application of the GPT-4 language model in extracting clinically relevant information from medical reports across a variety of conditions. Key findings were identified by GPT-4 from diverse reports including Next-Generation Sequencing, Fluorescent In Situ Hybridization, Flow Cytometry, Chromosome Analysis, Echocardiogram, and Dual X-ray Absorptiometry scans. Preliminary results suggest that the GPT-4 model potentially improved data extraction efficiency by outperforming traditional SQL query practices by a factor of 4 to 9 in our specific setup, while also effectively managing data variations. These findings, although promising, need further validation through larger-scale studies. The initial evidence, however, underscores the potential utility of GPT-4 in enhancing the speed and accuracy of clinical data extraction, which can be beneficial in both research and clinical contexts.","['Data mining and knowledge discovery', 'Natural Language Processing', 'Clinical and research data collection, curation, preservation, or sharing']"
25,One Model Fits All? High-performing Multi-task Model of Urinary Tract Dilation (UTD) Classification Using NLP for Neonatal Ultrasound Reports,Harnessing the Power of Large Language Models in Health Data Science,"This study addresses the challenges in interpreting urinary tract dilation (UTD) in neonatal ultrasound reports due to inconsistent language. We developed a high-performing, multi-task and multi-class model using natural language processing (NLP), specifically BERT algorithms. The model was trained on ultrasound reports from Boston Children's Hospital, outperforming GPT-3.5 models in both '0-shot' and '3-shot' scenarios with an average F1 score of 0.942. The findings indicate its strong potential for reliable, automated extraction of UTD classifications, streamlining both clinical management and research in pediatric hydronephrosis.","['Natural Language Processing', 'EHR-based phenotyping', 'Machine learning and predictive modeling']"
26,Symptom Trajectories Prior to Out of Hospital Cardiac Arrest – Insights from Natural Language Processing,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"We leverage natural language processing (NLP) to analyze clinical notes within a healthcare system, aiming to uncover critical insights into the trajectories of symptoms leading up to out-of-hospital cardiac arrest (OHCA). Applying NLP to 2366 OHCA cases and 23,660 matched controls, we identified seven symptoms associated with a 40-100% increased odds of OHCA 30 days before the event. These symptoms exhibited a growing discrepancy in prevalence between cases and controls in the months preceding OHCA.","['Data mining and knowledge discovery', 'EHR-based phenotyping', 'Secondary use of EHR data']"
27,A Natural Language Processing Framework for the Retrospective Identification of Surgical Site Infections,Harnessing the Power of Large Language Models in Health Data Science,"The recognition and tracking of postoperative complications are important for patient care and quality improvement. Current practices are frequently inefficient or incomplete. We propose a machine learning framework for the automatic tracking of complications, with surgical site infections as an initial test case. A high-performing machine learning system for this purpose has the potential to improve record keeping, reduce cost, and support education and research.","['Data mining and knowledge discovery', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
28,Facilitators and Barriers to Implementation of EMPOWER mobile app for diabetes self-management,Implementation Science and Deployment in Informatics: From Theory to Practice,"This study aims to identify facilitators and barriers to implementation of EMPOWER app, a digital tool designed to promote behavioral changes for patients with type 2 diabetes. Limited ability in interpreting health indicators and navigating the EMPOWER app (Capability) were important determinants. Participants desired nudges that are compatible with their lifestyle (Physical Opportunity). Nudges served as a reminder to increase Automatic Motivation. Nevertheless, the lack of tangible results diminished Reflective Motivation for behavior change.","['Mobile Health, wearable devices and patient-generated health data', 'Implementation Science', 'Outcomes research, clinical epidemiology, population health']"
29,Development of A Gene-List Capable of Stratifying Mixed Aetiology Cardiomyopathy by Risk of Heart Failure Progression in Blood and Tissue Based Datasets,,"Early screening and diagnosis of heart failure remains an area if unmet clinical need. Using publicly available datasets, regression analysis and clustering in R, we have developed a gene-list capable of stratifying mixed aetiology cardiomyopathy by risk of heart failure progression in blood and tissue-based datasets. The gene-list shows potential to be developed into a non-invasive, predictive and diagnostic tool with translational clinical potential in cardiology.","['Transcriptomics', 'Biomarker discovery and development', 'Data mining and knowledge discovery']"
30,Prediction of Triple Vessels Disease using Fundus Photography and Clinical Risk Factors: A Prospective Cohort Study,,"Cardiovascular disease stratification is crucial for optimizing treatment selection and resource allocation. In recent years, fundus photography has unveiled the promising potential of retinal vascular features as predictive markers for major cardiovascular events and overall mortality[1]. The integration of artificial intelligence, particularly deep learning algorithms, into this field has opened up exciting new possibilities[2]. We conducted a prospective observational study aimed to compare the predictive value of TVD using fundus photography with a deep learning model, against machine learning model using clinical risk factors only.This study, conducted at a Singaporean tertiary referral center, enrolled high cardiovascular-risk patients undergoing angiography. Ethical approval and informed consent were obtained. TVD was defined as >50% stenosis in three or more major coronary vessels. A Swin Transformer-based deep learning model analyzed fundus photos, excluding unsuitable images. Each patient had at least two fundus photos, with 80% for training, 10% for validation, and 10% for testing. Clinical risk factors were analyzed using Autoscore, and outcomes were measured by the area under the receiver operating characteristic (AUROC) curve.Out of 279 patients, 28.0% had TVD, with a majority having hypertension (63.0%) and hyperlipidemia (81.0%), and 37.6% having diabetes history. Deep learning analysis of 1432 fundoscopy images showed higher TVD predictions compared to the best clinical risk-based machine learning model (AUROC 0.865 vs. 0.751).This study demonstrates the efficacy of fundus photography-based deep learning in predicting TVD. The model outperforms clinical risk-based machine learning in high-risk, prospective patient groups.","['Clinical decision support for translational/data science interventions', 'Medical Imaging', 'Machine learning and predictive modeling']"
31,Alternate Approaches to ICD-10CM Feature Reduction Variably Predict Pediatric Neurofibromatosis Type 1 Sub-Phenotypes,,"Electronic health records (EHR) data are valuable for predictive modeling of disease conditions but challenging to use in their raw form. In this study, using feature reduction and aggregation methods, we transform diagnostic codes into high-level feature sets which are used, with demographics, to predict neurofibromatosis type 1 (NF1) sub-phenotypes (OPG, ADHD, scoliosis) in children with NF1. We evaluate and compare the utility of the feature sets using various models (logistic regression, random forest, XGBoost).","['Secondary use of EHR data', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
32,OncQA: A Clinical Question-answering Benchmark for Oncology,Harnessing the Power of Large Language Models in Health Data Science,"OncQA aims to create a realistic clinical oncology question-answering dataset that is suitable for LLM-era evaluation. Using expert-curated question-answer pairs based on synthetic patient synopses and patient inbox messages, we produce a benchmark dataset for assessing clinical language models' capabilities and limitations in a real-world clinical context. We also investigate how LLM-generated responses compare to clinicians’ responses and impact human efficiency and behavior in answering patient questions.","['Natural Language Processing', 'Education and Training', 'Clinical and research data collection, curation, preservation, or sharing']"
33,"Language models, Explain these Clinical Trials to me as if I am a Sixth Grader!",Harnessing the Power of Large Language Models in Health Data Science,We developed methods using large language models to generate accessible summaries of cancer clinical trials from ClinicalTrials.gov tabular data. These summaries could support patients in self-education about potential trials. (stats one sentence highlight) Our techniques could amplify the impact of ClinicalTrials.gov by extending its role to patient-facing applications which could improve representation on clinical trials. We also release a novel summarization dataset and model.,"['Natural Language Processing', 'Clinical trials innovations', 'Clinical and research data collection, curation, preservation, or sharing']"
34,Going Beyond the Technology: Considerations in Translating Case Report Forms,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,"Translating case report forms is important to ensure inclusive, ethnically, and culturally diverse research study populations. Leveraging REDCap, we developed a process to manage, implement, and certify language translations to increase representation from study participants whose primary language is not English.","['Health literacy issues and solutions', 'Recruitment technologies', 'Clinical and research data collection, curation, preservation, or sharing']"
35,Generating Simpler Medical Synonyms Using Word Embeddings,,"We used the PubMed Open Access corpus to learn word embeddings to suggest easier synonyms for difficult terms. We evaluate cosine similarity to the difficult word to fine-tune the synonym list. On a sample of medical texts, the new synonyms provide coverage for a third of the difficult words with reasonable precision (26%). With increased similarity, precision improved. This approach is an efficient and generic method to generate simpler synonyms.","['Natural Language Processing', 'Health literacy issues and solutions', 'Data mining and knowledge discovery']"
36,Exploring GPT Prompt Engineering to Produce Structured Outputs,Harnessing the Power of Large Language Models in Health Data Science,"GPT models effectively extract targeted information from unstructured text in a variety of domains. However, their output tends to include superfluous text not conducive for downstream high-throughput computation. We examined how prompt engineering can produce more structured outputs and determined if there are tradeoffs to accuracy and reproducibility. Our results suggest a small tradeoff between optimizing structure versus accuracy of GPT output, the importance of which depends on the purpose of the information extracted.","['Data mining and knowledge discovery', 'Natural Language Processing', 'Knowledge representation, management, or engineering']"
37,A Text-Mining Model for Extracting Phenotypes from NF1 Clinical Notes,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Neurofibromatosis Type 1 (NF1) is a syndrome with variable expressivity, caused by mutations in the NF1 gene. Current management of the disorder is reactive due to the lack of early risk-stratification tools. This study develops and evaluates a model that extracts clinically-relevant phenotypes from progress notes to facilitate development of risk-stratification models for NF1. Evaluated against a manually-curated reference, F1-scores over 0.8 for X/Y phenotypes for 380 individuals indicate successful phenotyping by the model.","['EHR-based phenotyping', 'Secondary use of EHR data', 'Natural Language Processing']"
38,Comparing Colorectal Cancer Diagnosis Ascertainment Methods in the Million Veteran Program,,"The purpose was to describe rates and agreement of CRC cases in a Million Veteran Program (MVP) cohort (n=216,891) using four ascertainment approaches: 1) diagnosis codes (ICD), 2) ICD + natural language processing, 3) cancer registry, and 4) self-report. CRC case rates ranged 1.0-2.4% and 2.9% when combining all approaches. Agreement of the ascertainment approaches in most pairwise assessments was moderate to substantial. Discordant cases need examination, but combining approaches prevents excluding unrecognized cases.","['Informatics research/biomedical informatics research methods', 'Measuring outcomes', 'Reproducible research methods and tools']"
39,Capturing Novel Research Assays in a Common Data Model to Support Clinical Decision Support Tools,,The integration of data lakes into a relational database allows for the storage and retrieval of complex research assays that don’t match traditional data structures.,"['Clinical decision support for translational/data science interventions', 'Data transformation/ETL', 'Informatics research/biomedical informatics research methods']"
40,Predicting Recurrence of Low-Grade Glioma – A Deep Learning Approach,Proactive Machine Learning in Biomedical Applications: The Power of Generative AI and Reinforcement Learning,"Low-grade gliomas (LGGs) are a subset of primary grade I and grade II brain tumors characterized by their slow growth and high rates of relapse, with ~62% of patients experiencing recurrence within five years and 17%-32% progressing from low to high-grade glioma. Due to the slow progression, high recurrence, and relatively long survival of LGG, physicians must balance the benefits of intervention against possible treatment-related complications. Understanding a patient's likelihood of LGG recurrence can help physicians optimize treatment selection and surgical timing to improve overall outcomes, minimize treatment-related disability, and maximize quality of life. Deep learning techniques have shown increasing promise in various medical applications, including disease recurrence prediction. In this project, we examine the capacity of deep and machine learning models to predict LG recurrence using the tumor histology, variant (SNPs and indels) counts per gene, and mRNA expression Z- scores of 251 tumor samples in the TCGA Brain Lower Grade Glioma dataset (via cBioPortal). Our model achieved the highest ROC-AUC (0.860) and tied in accuracy (0.765) with Linear SVC. The 10 top selected features included RAB3GAP2, SLC7A9, GIMAP6, MET, SVIL, LAMA3, and CIC mutation counts, astrocytoma histology, and IDH1 and TP53 mutation counts. Although further investigation is required, as our model predicted LGG recurrence in a modest and racially homogenous (0.936 White, 0.044 Black, 0.004 Asian, 0.004 American Indian or Alaska Native), the selected features provide gene targets for consideration in future research on targeted therapies and mechanisms of recurrence.","['Clinical genomics/omics and interventions based on omics data', 'Machine learning and predictive modeling', 'Genomics/Omic data interpretation']"
41,The Atlas of Protein-Protein Interactions in Cancer,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Patients affected by one cancer type display significant heterogeneity, suggesting the need to characterize cancers into subtypes. We used publicly-available RNA-seq data of cancer patients across ten tissue types to define the protein-protein interactions (PPIs) of 26 cancer subtypes. We then developed the Atlas of Protein-Protein Interactions in Cancer, a web application that visualizes PPIs and aggregates biological/clinical information from databases. APPIC will advance the understanding of cancer subtype mechanisms and development of therapeutic strategies.","['Data Integration', 'Advanced data visualization tools and techniques', 'Clinical and research data collection, curation, preservation, or sharing']"
42,Derivation and Experimental Performance of Standard and Novel Uncertainty Calibration Techniques,,"To aid in the transparency of state-of-the-art machine learning models, there has been considerable research performed in uncertainty quantification (UQ). UQ aims to quantify what a model does not know by measuring variation of the model under stochastic conditions and has been demonstrated to be a potentially powerful tool for medical AI. Evaluation of UQ, however, is largely constrained to visual analysis. In this work, we expand upon the Rejection Classification Index (RC-Index) and introduce the relative RC-Index as measures of uncertainty based on rejection classification curves. We hypothesize that rejection classification curves can be used as a basis to derive a metric of how well a given arbitrary uncertainty quantification metric can identify potentially incorrect predictions by an ML model. We compare RC-Index and rRC-Index to established measures based on lift curves.","['Data mining and knowledge discovery', 'Machine learning and predictive modeling', 'Education and Training']"
43,"PrEP Prescribing and Adherence Patterns among Persons on Medicaid in Chicago, Illinois",Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Medicaid claims data contains real-world evidence about PrEP prescribing and adherence patterns in Chicago, Illinois, informing where there are areas of unmet need to target for more efficient healthcare delivery. While PrEP prescriptions in 2015 and 2016 reveal that a high percentage of days (median 95.6% and 89.0% respectively) are covered once a patient has been prescribed PrEP, there are clear geographic trends indicating an unmet need for PrEP on the South side of Chicago.","['Public health informatics', 'Secondary use of EHR data', 'Outcomes research, clinical epidemiology, population health']"
44,Developing Informatics Capacity for COVID-19 Surveillance in a National Research Network,,"The COVID-19 pandemic prompted the necessity for rapid, wide-reaching, and adaptable national surveillance that can accommodate new knowledge, policies, therapeutics, and vaccines. The COVID-19 Electronic Health Data Initiative utilizes PCORnet developed SAS-based tools to rapidly answer research questions and support surveillance initiatives across participating sites. Continued enhancements to the SAS based tools allowed over 50 query packages to be released while keeping pace with the changing nature of the pandemic.","['Public health informatics', 'Patient centered research and care']"
45,Analysis of Online Health Information Resource Networks at Multiple Levels of Semantic Granularities: A Case Study for COVID-19 Treatment,,"We conducted a case study to analyze the online information networks for COVID-19 treatment at four semantic granularity levels: treatment, medication, antiviral, and Paxlovid. The network size decreased as the semantic granularity refined. The lower-level networks retained most important nodes from the upper-levels. These findings suggested that we could focus on the lower-level networks for efficient data collection and analysis, and yet still achieve reasonably good results in identifying important online resources and hosting sites.","['Data mining and knowledge discovery', 'Ontologies', 'Knowledge representation, management, or engineering']"
46,Utilizing Decision Tree Model for Streamlined Cognitive Evaluation in Aging Populations with NIH Toolbox Assessments,,"In this study, data from ARMADA project was used to develop a predictive model for distinguishing between normal cognitive function, mild cognitive impairment (MCI), and Alzheimer's disease (AD). The model, based on cognitive, motor, emotional, and sensory performance measures, achieved high accuracy (macro-AUC: 0.92 training, 0.89 testing; micro-AUC: 0.91 training, 0.86 testing). The decision tree utilized memory and attention tests, emotional factors, and motor tests as key predictors, offering the potential for simplified cognitive assessments.","['Clinical decision support for translational/data science interventions', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
47,Role of Dependency Distance in Text Simplification: A Human vs ChatGPT Simplification Comparison,,"This study investigates human and ChatGPT text simplification and its relationship to dependency distance. A set of 220 sentences, with increasing grammatical difficulty as measured in a prior user study, were simplified by a human expert and using ChatGPT. We found that the three sentence sets all differed in mean dependency distances: the highest in the original sentence set, followed by ChatGPT simplified sentences, and the human simplified sentences showed the lowest mean dependency distance.","['Health literacy issues and solutions', 'Health Information and biomedical data dissemination strategies', 'Natural Language Processing']"
48,Development & Validation of ML Model to Predict Death Upon Admission,,"This project aimed to develop a model that would support consistent end-of-life care, validate the model against clinicians, and ultimately deploy this model into electronic medical record. Using primarily lab data, we developed a LASSO model that predicted death within 45 days of inpatient admission. This model had a Test AUC of 0.82 and generated predictions that significantly improved clinicians’ predictions.","['Clinical decision support for translational/data science interventions', 'EHR-based phenotyping', 'Machine learning and predictive modeling']"
49,"Designing and refining mobile health apps with perspectives from researchers, software engineers, and industry leaders",,"The past decade has witnessed a surge in the development of mobile health (mHealth) apps that cater to various public health concerns. With more than 85% of US adults owning smartphones, mHealth apps have become an attractive platform for delivering health services. These apps offer naturalistic, on-demand, and accessible clinical services, providing a standardized yet personalized care experience. However, translating behavioral healthcare into technical features can be challenging, especially due to the diverse backgrounds and design approaches of collaborators. Consequently, many mHealth apps are neither user-friendly nor clinically effective. This study seeks to offer insight into the interdisciplinary process of designing and refining mHealth apps. The goal is to highlight common mistakes and lessons learned to guide researchers new to mHealth apps. To achieve this, we conducted in-depth interviews with clinical researchers, software engineers, and leaders (e.g., founder, chief technology officer) of digital health companies (n = 11) who built mHealth apps aimed at reducing substance use (confirmed by a literature review). The interviews explored the experiences of participants in designing, refining, testing, and scaling up mHealth apps, both for research and enterprise purposes. By sharing these experiences, we aim to provide researchers with valuable information that can inform their approach to designing effective and user-friendly mHealth apps.","['Patient centered research and care', 'Mobile Health, wearable devices and patient-generated health data', 'Implementation Science']"
50,Risk Factors Predicting Efficacy of Immune Checkpoint Inhibitors on the Overall Survival of Patients with NSCLC and SCLC,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Immune checkpoint inhibitors (ICIs) have revolutionized lung cancer treatment. However, limited knowledges are available to predict which patients could benefit from ICI treatment. Our retrospective study indicated that patients with younger age, higher BMI, no metastasis, fewer lymph nodes involvement, higher albumin and lower lactate dehydrogenase level of blood would benefit more from ICI treatment, where blood albumin level is the common key factor in predicting ICI efficacy for both NSCLC and SCLC patients.","['Clinical decision support for translational/data science interventions', 'Data mining and knowledge discovery', 'Cohort discovery']"
51,The roles of electronic health records for conducting clinical trials in low-and middle-income countries,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Clinical research plays an important role in advancing medical knowledge, including the development of new treatments by forming the evidence base for safety and therapeutic efficacy. This scoping review aims to comprehensively identify the roles of EHRs in the life cycle of clinical trials, determine how electronic health records (EHRs) should be implemented in clinical research settings, and describe specifically how this technology is used to support different types of clinical trials with a low- and middle-income countries (LMICs) context. We aimed to determine the frequency of use of EHRs and describe possible applications of EHR technology in current practice, focusing on trials that were supported by the EHR rather than evaluating the EHR itself.","['Clinical trials innovations', 'Public health informatics', 'Health Information and biomedical data dissemination strategies']"
52,The role of artificial intelligence for the application of integrating electronic health records and patient-generated data in clinical decision support,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","This narrative review aims to identify and understand the role of artificial intelligence in the application of integrated electronic health records (EHRs) and patient-generated health data (PGHD) in clinical decision support. We focused on integrated data that combined PGHD and EHR data, and we investigated the role of artificial intelligence (AI) in the application. We used the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines to search articles in six databases: PubMed, Embase, Web of Science, Scopus, ACM Digital Library, and IEEE Computer Society Digital Library. In addition, we also synthesized seminal sources, including other systematic reviews, reports, and white papers, to inform the context, history, and development of this field. Twenty-six publications met the review criteria after screening. The EHR-integrated PGHD introduces benefits to health care, including empowering patients and families to engage via shared decision-making, improving the patient-provider relationship, and reducing the time and cost of clinical visits. AI’s roles include cleaning and management of heterogeneous datasets, assisting in identifying dynamic patterns to improve clinical care processes, and providing more sophisticated algorithms to better predict outcomes and propose precise recommendations based on the integrated data. Challenges mainly stem from the large volume of integrated data, data standards, data exchange and interoperability, security and privacy, interpretation, and meaningful use. The use of PGHD in health care is at a promising stage but needs further work for widespread adoption and seamless integration into health care systems.","['Clinical decision support for translational/data science interventions', 'Collaborative workflow systems', 'Implementation Science']"
53,Efficient Training Corpus Retrieval for Large Language Model Fine Tuning,Harnessing the Power of Large Language Models in Health Data Science,"Large language models (LLMs) excel in numerous natural language processing tasks but require domain-specific fine-tuning for optimal results. This study investigates the effectiveness of fine-tuned LLM (GPT-J-6.7B) with IL6 disease knowledge for question-answering. Proposed automated tool is used to extract knowledge from academic papers, including content, co-citation, and co-authorship networks. We leverage deep learning to train a retrieval-based chatbot on question-answer pairs obtained from refined data, to evaluate fine-tuned model performance.","['Data mining and knowledge discovery', 'Informatics research/biomedical informatics research methods', 'Data-driven research and discovery']"
54,Visualizing Patient Population Overlap Using the Redeveloped i2b2 Web Client,,"Integrating Biology and the Bedside (i2b2) is a widely adopted open source software platform for organizing and querying clinical and genomic data (https://www.i2b2.org). Its modular architecture enables organizations to extend the software to perform additional data analyses and visualization. This poster describes how to build plugins for the recently redesigned i2b2 user interface. We demonstrate this with a Venn Diagram plugin, which illustrates the overlap between multiple patient cohorts (https://github.com/neomancy/i2b2-venn-plugin).","['Cohort discovery', 'Secondary use of EHR data', 'Advanced data visualization tools and techniques']"
55,Longer and Greater Clinician Absenteeism Prolongs Patient Length of Stay Across a Simulated Network of Emergency Departments,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"When chronically strained emergency department (ED) staffing is further stressed by disasters such as the COVID-19 pandemic, patient care is slowed and compromised. We develop and explore a network simulation model to stress test ED staffing. Across the network, patient length of stay is unchanged at 25% absenteeism but increases with 1 day and 1 week of 50% clinician absenteeism. Our work builds the groundwork to stress test clinician staffing plans and improve ED resilience.","['Secondary use of EHR data', 'Learning healthcare system', 'Machine learning and predictive modeling']"
56,Using Matched Controls to Measure the Impact of Small Clinical and Translational Research Pilot Grants,,"Each year, the NIH Clinical and Translational Science Award (CTSA) program spends millions of dollars to fund hundreds of small pilot grant projects at academic medical centers across the country. We developed a novel method to evaluate the impact of these pilot grants compared to the baseline level of scientific productivity at an organization. We leveraged a collaboration software platform we created called Profiles, which automatically captures data about investigators using data mining algorithms.","['Collaborative workflow systems', 'Data mining and knowledge discovery', 'Informatics research/biomedical informatics research methods']"
57,Telemedicine in Peru: An examination of service disparities during the COVID-19 pandemics,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","Amidst the COVID-19 pandemic, while global telemedicine services surged, Peru observed a decline after an initial rise. From 2019-2023, nearly 35 million of telemedicine consultations were conducted across 7,844 health facilities (HFs) across Peru. Hospital healthcare HF from urban and wealthiest locations, especially those linked to the National Telemedicine Network, showed higher consultation rates. The data underscores pronounced service disparities, highlighting the urgent need for a more equitable distribution of telemedicine services throughout Peru.","['Public health informatics', 'Social determinants of health']"
58,Fairness-Aware Integral Regression (FAIReg) for Trustworthy Machine Learning in Healthcare,,"With machine learning playing a pivotal role in healthcare, concerns over fairness are paramount. This study introduces FAIReg, a transparent bias mitigation framework tackling the challenge of fairness versus model effectiveness. By optimizing nearly optimal models, FAIReg maintains effectiveness while enhancing fairness. Applied to healthcare datasets, FAIReg achieves an AUC comparable to the fairness-unaware counterpart, while notably excluding race/ethnicity and limiting gender/sex contributions and reducing the disparities measured by fairness metrics.","['Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling', 'Ethical, legal, and social issues']"
59,Large Language Model for Early Warning Score Prediction in Emergency Medicine,,"Efficient clinical assessment in the Emergency department is vital for resource allocation. Leveraging the capabilities of large language models, we investigated ChatGPT-4.0's predictive performance for NEWS-2 from the MIMIC-IV database. While ChatGPT exhibited an overall accuracy in NEWS-2 and ICU admission prediction, it showed limited sensitivity for both predictions. Prediction accuracy varied across racial groups, raising concerns of bias. Predicting Emergency Severity Index scores and hospital admissions proved challenging due to their subjective nature.","['Natural Language Processing', 'Machine learning and predictive modeling', 'Ethical, legal, and social issues']"
60,Repurposing Clinical De-Identification Software for Source Code Repositories,,"Publicly shared source code is an often-overlooked risk for accidental disclosure of protected health information (PHI). Clinical de-identification tools exist but have not been evaluated on source code. We evaluated three de-identification tools: Philter, deid, and ClinDeID, and noted varying performance. Overall, the tools performed well as highly sensitive detectors for potential PHI, and several classes of common false positives are noted.","['Data security and privacy', 'Digital research enterprise', 'Open Science for biomedical research and translational medicine']"
61,Machine learning Based Acute Kidney Injury Sub-phenotyping With Time Series Serum Creatinine Data,,"Acute Kidney injury (AKI) is a life-threatening clinical syndrome prevalent in hospitalized patients and is associated with increased mortality and poor patient outcomes. Pathophysiology of AKI is highly divergent. AKI sub-phenotyping can lead to better understanding of the AKI pathophysiology and help develop etiology-based personalized treatment. Most existing sub-phenotyping methods are based-on static data, with time-series data like vital signs and biomarkers converted to point estimates, where information in the dynamic data is often ignored. To address these limitations, we propose to use the Dynamic Time Warp algorithm to capture information from the full time-series of Serum Creatinine (SCr) measurements for AKI sub-phenotyping. We aimed to discover sub-phenotypes of AKI patients in ICU (n=5781) and AKI patients in general units (n=5034). For each patient cohort, we identified 4 sub-phenotypes and analyses showed that they are divided by two major characteristics: AKI stage-1 vs AKI stage-2/3 and resolving vs Non-resolving AKI.","['Data mining and knowledge discovery', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
62,Enabling efficient data management through FAIR principles in clinical studies,Implementation Science and Deployment in Informatics: From Theory to Practice,"Effective data management in clinical studies is crucial for the successful execution of research projects in medical informatics. The incorporation of the FAIR (Findable, Accessible, Interoperable and Reusable) principles in clinical study execution is increasingly significant providing guidelines for the data management in such projects. They improve the quality, transparency, and efficiency of clinical studies, where reproducability and reusability is crucial for future works. Hence, it empowers researchers to utilize data effectively, ensuring transparent research processes and advancing scientific insights. Here we present a clinical workflow featuring an ETL pipeline while ensuring the compliance for each step with the FAIR principles. The implementation provides captured data from a clinical study in the standardized FHIR format through automated extraction, transform, and storage while adhering to the FAIR guidelines. This approach facilitates data discoverability, accessibility, interoperability, and reusability, amplifying its value and contributing to streamlined data management.","['Data transformation/ETL', 'Data/system integration, standardization and interoperability', 'Clinical and research data collection, curation, preservation, or sharing']"
63,Automatically Evaluating LLM-Generated Text in the Medical Domain,Harnessing the Power of Large Language Models in Health Data Science,A methodology for establishing the quality of LLM output is critical to developing AI assistant tools in the medical domain. We describe a set of methodologies (statistics + LLM) to automatically evaluate the quality and accuracy of AI-generated patient treatment recommendations against a human-generated reference set. Our results demonstrate that an automated evaluation approach can accurately assess the quality of AI-generated text.,"['Natural Language Processing', 'Data quality', 'Machine learning and predictive modeling']"
64,Genetic Variant Data - Min(d)ing the Freetext Gap,Implementation Science and Deployment in Informatics: From Theory to Practice,"The acquisition, storage, and analysis of genetic variant data continues to face critical flow gaps, a major one being free text siloing. In this poster, we will review gaps identified in prior research and propose a clinical natural language processing (CNLP)-based information flow framework to capture, normalize, and store genetic variant data. Finally, we detail a proof-of-concept technical implementation.","['Natural Language Processing', 'Data quality', 'Data mining and knowledge discovery']"
65,The AnVIL Clinical Resource: Bringing Tools for Genomic-Based Clinical Research Data to the NIH Cloud,,"The NHGRI Genomic Data Science Analysis, Visualization, and Informatics Lab-space (AnVlL) is a cloud-based platform to support clinical genomic research communities through a scalable, shared environment with powerful analysis tools. AnVIL is now embarking on the AnVIL Clinical Environment for Innovation and Translation (ACE-IT). The goal of ACE-IT is to enable clinicians to use AnVIL with clinical genomic datasets and to provide tools such as polygenic risk score calculators and machine-learning diagnostic tools.","['Clinical genomics/omics and interventions based on omics data', 'Data commons', 'Data-driven research and discovery']"
66,Early and Adequate Antibiotic Therapy in Hospital-Onset Sepsis: A Target Trial Emulation Applying Machine Learning on Real-World Data,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Antimicrobial resistance presents challenges in treating hospital-onset sepsis. Given constraints of randomized trials, we leveraged real-world data, including electronic health records, and machine learning to estimate causal effects of early and adequate antibiotic treatment. Results emphasize the importance of adequate treatment, revealing specific patient groups with a critical need for treatment optimization. By merging diverse data sources and expert-driven modeling, this study highlights the potential of both modern and traditional methodologies in improving sepsis outcomes.","['Secondary use of EHR data', 'Machine learning and predictive modeling', 'Outcomes research, clinical epidemiology, population health']"
67,Predicting Future Mental Health Diagnoses in Patients with Cancer Based on the NCCN Distress Thermometer and Electronic Health Record Data,,"In this study, we assessed the independent association between the National Comprehensive Cancer Network Distress Thermometer (NCCN DT) and time to mental health diagnosis (MHD) in patients with cancer. NCCN DT responses demonstrated a persistent relationship with future MHD while controlling for other characteristics derived from patient electronic health records (EHR). Therefore, the NCCN DT and EHR data together may have utility in machine learning models identifying risk of future MHD in patients with cancer.","['Clinical decision support for translational/data science interventions', 'Secondary use of EHR data', 'Social determinants of health']"
68,Cost-effectiveness of Telemedicine: An analysis of telehealth visits in New York State from March 2020 to March 2021,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","Objective:This study aimed to quantify the cost-utility and cost-effectiveness of telemedicine by analyzing data from 2000 telehealth visits in Upstate New York between March 2020 and March 2021.Methods:A subset of 2000 telehealth visits was randomly selected from a total dataset of 512,683 visits from Rochetser Regional Health System. The data encompassed various telehealth modes, and the variables calculated included median distance, time, and carbon saved per visit. Cost estimations were based on fuel efficiency data, gasoline costs, and IRS's standard mileage rate. The study also evaluated environmental impacts in terms of carbon savings.Results:Of the 1974 visits (after excluding 26 outliers), family medicine comprised 30.1% and internal medicine 26.6%. The median distance saved per visit was 13.39 miles, with a median time saving of 0.43 hours. This translated to a gasoline saving of approximately 0.55 gallons per visit and $13.95 when considering IRS's standard mileage rate and hourly wage values. The estimated carbon saving was 4.92 kg per visit. Projected to the entire annual patient group, the potential savings could be roughly 8,957,607 miles, 239,126 hours, $8,603,164, and a carbon reduction of approximately 3,289,515 kg.Conclusion:The findings highlight the substantial cost and environmental benefits of telemedicine in New York State from March 2020 to March 2021. However, a more comprehensive analysis incorporating various parameters and potential disparities in care quality between in-person and telemedicine visits is necessary.","['Data-driven research and discovery', 'Public health informatics', 'Mobile Health, wearable devices and patient-generated health data']"
69,DrugWAS X PheWAS: A pharmacoepidemiologic framework to investigate the effect of drug exposure during pregnancy on pediatric outcomes,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Due to the regulations that restrict pregnant women's participation in drug development trials and the absence of clinical trials involving children, information about safety and efficacy of many drugs or drug combinations used by mothers during and before pregnancy is limited. Leveraging electronic health records (EHRs) of mother-child dyads, we developed a pharmacoepidemiologic framework for conducting large-scale associations between drug exposures of mothers and adverse outcomes of their children.","['Secondary use of EHR data', 'Data-driven research and discovery', 'Drug discovery, repurposing, and side-effect discovery']"
70,"Reporting Implementation Strategies and their Alignment with Implementation Science Outcomes in the Release of a Technology to Facilitate Multidisciplinary, Family-Centered Rounding",Implementation Science and Deployment in Informatics: From Theory to Practice,"In this case study, we use an implementation framework to describe measures capturing different components of the implementation process for a novel team rounding software tool called Q-rounds. The tool facilitates multi-disciplinary, family-centered rounds by sending real-time updates to care teams and families and helping them to join remotely or in-person. Measuring the process of implementation of new informatics innovations within hospitals is important for identifying barriers to implementation and promoting future uptake.","['Patient centered research and care', 'Implementation Science', 'Mobile Health, wearable devices and patient-generated health data']"
71,"Shared Health Research Information Network (SHRINE): System Architecture, Adoption, and Roadmap",,"I2b2 is an open-source clinical data query and analysis platform used at 200+ sites worldwide. We created the Shared Health Research Information Network (SHRINE), a federated network tool that distributes queries to the i2b2 instances at multiple institutions. Each site runs the queries locally and returns the result back to the investigator. This poster compares SHRINE's architecture to other network designs, describes uses cases and adoption across institutions, and lists potential next steps.","['Cohort discovery', 'Secondary use of EHR data', 'Informatics research/biomedical informatics research methods']"
72,Quantifying Diagnostic Uncertainty in Sepsis: Towards Real-Time Clinical Decision Support,,"A sepsis decision-making construct considering infection risk and disease severity has been proposed but never validated on real-world data. 133,524 emergency visits were used to generate modified Early Warning Scores and fit a machine learning infection model. Theses variables were used for linear regression of time to antibiotics. Patients with delayed antibiotics had a higher rate of ICU stay and death (p<0.001). Thus, this could be a useful construct for identifying potentially missed opportunities.","['Clinical decision support for translational/data science interventions', 'EHR-based phenotyping', 'Infectious disease modeling']"
73,Incorporating Stakeholder Input in the Development of a Health Disparities Data Exploration Tool in a Pediatric Hospital Setting,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,"To monitor and address health disparities in both processes and outcomes, we developed a data exploration tool to allow stakeholders to examine questions related to health equity and health disparities through a dynamic data visualization dashboard. We took a user experience approach to understanding how this dashboard may be used from a hospital leader perspective and from a clinician perspective. This poster will discuss qualitative user feedback and how this feedback shaped future design.","['Secondary use of EHR data', 'Advanced data visualization tools and techniques', 'Outcomes research, clinical epidemiology, population health']"
74,Automated Monitoring and Evaluation of a Clinical Decision Support Tool: Application to an Inpatient Early Warning Score,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Monitoring of CDS tools is an important part of governance. An important question is how big of a window size to use to assess drift. We conducted a simulation study to understand the role of window size. We found that larger windows, with greater sample sizes, gave us more power to detect drift while also being flexible enough to capture changes early enough. We applied this approach to our EWS CDS.","['Clinical decision support for translational/data science interventions', 'Measuring outcomes', 'Learning healthcare system']"
75,A User-Centered Approach to Adapt Interoperable Clinical Decision Support Tools for Chronic Pain Management,Implementation Science and Deployment in Informatics: From Theory to Practice,"Updated patient pain information is necessary for providers to optimize chronic pain management. Primary care providers often lack this information beforehand to discuss with patients. This study aimed to assess and identify adaptation to tailor two electronic clinical decision support tools, MyPAIN and PainManager, to the needs of a healthcare system.","['Clinical decision support for translational/data science interventions', 'FHIR', 'Implementation Science']"
76,Unlocking the Potential of Synthetic Data: A Critical Examination of its Role in Real-World Healthcare Research,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"This abstract highlights the use of real-world data (RWD) from electronic health records (EHRs) for assessing COVID-19 treatment effectiveness through the Edge Tool suite. The study explores incorporating synthetic data to enhance sample size and analysis robustness, comparing results with RWD from the pilot site.","['Secondary use of EHR data', 'Drug discovery, repurposing, and side-effect discovery']"
77,Using Natural Language Processing for Data Harmonization: Comparing Large Language Models and Fuzzy Matching Approaches,Harnessing the Power of Large Language Models in Health Data Science,We developed and validated natural language processing (NLP) methods (Fuzzy Matching and Large Language Models [LLMs]) to align variables from two GERAS (European and Japan) cohort studies that used similar protocols to collect data but named variables differently. Each NLP method used variable definitions to calculate a similarity score for each EU-Japan variable pair. Evaluation using 160 manually aligned variable pairs showed that LLMs outperformed Fuzzy Matching on hit ratio and mean reciprocal rank.,"['Natural Language Processing', 'Data Integration', 'Clinical and research data collection, curation, preservation, or sharing']"
78,Detecting Multimorbidity Patterns with Association Rule Mining in Patients with Alzheimer's Disease and Related Dementias,Harnessing the Power of Large Language Models in Health Data Science,"Researchers estimate the number of dementia patients to triple by 2050¹. Dementia seldom occurs in isolation; it’s frequently accompanied by other health conditions². The coexistence of conditions further complicates the management of dementia. In this study, we embarked on an innovative approach, applying association rule mining to analyze National Alzheimer’s Coordinating Center (NACC) data. First, we completed a literature review on the utilization of association rules, heatmaps, and network analysis to detect and visualize comorbidities. Then, we conducted a secondary data analysis on the NACC data using association rule mining. This algorithm uncovers associations of comorbidities that are diagnosed together in patients who have Alzheimer's disease and related dementias (ADRD). Also, for these patients, the algorithm provides the probability of a patient developing another comorbidity given the diagnosis of an associated comorbidity. These findings can enhance treatment planning, advance research on high-association diseases, and ultimately enhance healthcare for dementia patients.","['Data mining and knowledge discovery', 'Clinical decision support for translational/data science interventions', 'Outcomes research, clinical epidemiology, population health']"
79,Development of an Adaptable Cost-Analysis Tool to Support the Implementation of the CONCERN Early Warning System,,"Cost as a component of feasibility when implementing clinical decision support systems is often overlooked. Our work demonstrates and agile cost analysis of Communicating Narrative Concerns Entered by RNs (CONCERN), an early warning system based on nursing generated data. We developed an Excel-based cost estimation tool which uses cost data based on literature and national averages. This tool can be repurposed and reused with local data to create an easily sharable and executable cost model to determine the feasibility of implementing CONCERN (or other CDS interventions).","['Reproducible research methods and tools', 'Clinical decision support for translational/data science interventions', 'Measuring outcomes']"
80,Informative Sampling to Enhance Clinical Chart Review Representativeness,,"“Gold-standard” labels from clinicians are crucial for developing computational phenotyping algorithms. Typically, charts are sampled randomly. However, random sampling may not be able to capture the diverse manifestations of the patient population. To address this issue, this project introduces an informative sampling approach to select medical charts for review, enhancing clinical chart review efficiency.","['Data mining and knowledge discovery', 'Clinical and research data collection, curation, preservation, or sharing']"
81,Socio-economic Disparities in Infection-related Hospitalizations among the U.S. Home Health Care Population: Insights from a National Study,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,"This study aims to understand the association between socioeconomic status (SES) of home health care (HHC) patients and infection risk. SES is quantified by the Area Deprivation Index (ADI) using multiple national datasets. The study sample includes 3,656,734 Medicare beneficiaries receiving HHC during 2019 from 8,133 HHC agencies. We used logistic regression models to investigate the association between ADI and infection risk and found significant associations for female and dual-eligible patients.","['Social determinants of health', 'Public health informatics', 'Patient centered research and care']"
82,Large Language Models and Biomedical Annotators to Extract Information from Scientific Literature in Inflammatory Bowel Disease,Harnessing the Power of Large Language Models in Health Data Science,This poster discusses two automated approaches for identifying important information from scientific literature to assist literature reviews. A Large Language Model (LLM) and biomedical text annotator (UMLS-based MetaMap) were used to identify and ascertain keywords and methods from a collection of Inflammatory Bowel Disease (IBD) abstracts. The results were assessed by human experts for accuracy and relevancy.,"['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Clinical and research data collection, curation, preservation, or sharing']"
83,Precision phenotyping of schizophrenia in an EHR-linked biobank,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Schizophrenia (SCZ) is a highly heritable and relatively rare neuropsychiatric condition whose pathogenic mechanisms are largely unknown. Scalable EHR-based methods are needed to accurately identify individuals with SCZ for large studies across diverse populations and healthcare settings. Using structured clinical data from the Vanderbilt University Medical Center electronic health record (EHR), we constructed 72 phenotype definitions and tested their performance against manual chart review labels. Applying these approaches to our EHR-linked biobank, we found that the definitions with the highest positive predictive values had the highest genomic specificity to SCZ. This study demonstrates the utility of EHR-based approaches in ascertaining individuals with SCZ for future genetic and epidemiological studies.","['EHR-based phenotyping', 'Genotype-phenotype association studies (including GWAS)', 'Informatics research/biomedical informatics research methods']"
84,Ink: Non-repudiation for Large Language Models (LLMs) in Healthcare,Harnessing the Power of Large Language Models in Health Data Science,"We are increasingly likely to see Large Language Models (LLMs) used in a healthcare context. To address potential issues around liability when this occurs, we introduce Ink, an LLM-backed chatbot that can be used to generate securely signed, non-repudiable records of chats that have taken place. These chats can then be validated at a later date if required. As a proof-of-concept, Ink is connected to several predominant LLMs, including GPT-3.5/4.","['Data security and privacy', 'Machine learning and predictive modeling', 'Ethical, legal, and social issues']"
85,ICT for Cost Effective Improvement of Routine Childhood Immunization,,"This research project offers a gradual replacement of the current immunization process in a low-resource setting using a low-cost LETUS (Lightweight Electronic Traceable and Updatable System) solution to increase immunization coverage, and traceability. The eHealth solution will improve the coverage of childhood immunization and reduce the need for supplemental immunization campaigns.","['Public health informatics', 'Secondary use of EHR data', 'Data/system integration, standardization and interoperability']"
86,A Software Ecosystem for FAIR Deep Learning in Digital Pathology,Citizen Science and Democratizing AI and Informatics for Healthcare,"Deep learning has transformed digital pathology, but the number of reusable trained models remains low. We address this need in the present work by developing a repository of open and reusable pre-trained models for slide-level inference across cancers, as well as software tools to efficiently deploy these models on digital pathology images. Our hope is that this new ecosystem will help to democratize deep learning in digital pathology.","['Reproducible research methods and tools', 'Bioimaging techniques and applications', 'Machine learning and predictive modeling']"
87,The Impact of Spiritual Care on Comfort in Older Adults with Chronic Illnesses: An Event Study Design,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Using interoperable nursing care plan data from electronic health records, our findings suggest that spiritual care improves physical comfort in older adults chronically ill after the second nursing shift. Nurses may integrate spiritual care more frequently into their usual care to better assist patients experiencing distress. Further research is needed to better comprehend the association between spiritual care and other well-being measures.","['Secondary use of EHR data', 'Patient centered research and care', 'Data/system integration, standardization and interoperability']"
88,External Validation of a Machine Learning Model to Predict Postpartum Hemorrhage in a Large Dataset from Northeast US,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Postpartum hemorrhage is the leading cause of severe maternal morbidity and mortality. As the current predictive tools are lacking and a new machine learning model has been developed, we validate its performance in a retrospective cohort of all deliveries between 2015-2022 in our healthcare system. The model had an area under the curve (AUC) of 0.77. These results demonstrate the potential of machine learning models to add value to care at the time of delivery.","['EHR-based phenotyping', 'Machine learning and predictive modeling', 'Ethical, legal, and social issues']"
89,Predicting Organ Rejections for Pediatric Heart Transplantations with a Combined Use of Transplant Registry Data and Electronic Health Records,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Donor organs are a limited resource with significant waitlist time and waitlist mortalities. Even though overall 5-year survival rate for pediatric heart transplant recipient continues to improve, ongoing concerns on the rates of late acute rejection (LAR) and hospitalization within this population remain. Prior research has provided initial evidence that machine learning algorithms can be used to predict posttransplant outcomes in pediatric organ transplantation, but these prediction models offer unsatisfactory predictive accuracy, possibly due to the use of only organ registry data but not fine-grained clinical data. In this study, we linked a transplant center patients’ electronic health records (EHRs) with the United Network for Organ Sharing (UNOS) registry data, allowing for the use of ML to identify at-risk patients with high accuracy and risk factors for poor posttransplant outcomes.","['Data mining and knowledge discovery', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
90,Enhancing Suicide Risk Detection in EHRs: Leveraging Large Language Models to Identify Explicit and Implicit Suicidal Indications,,"This study utilizes Large Language Models (LLMs) to improve the identification of both explicit and implicit suicidal mentions within Electronic Health Records (EHRs). Using the MIMIC database, 4,360 clinical notes were annotated, from which 2,134 were identified as relevant for suicidal behaviors. Deep Learning models, especially Clinical BERT, outperformed traditional methods, achieving up to 87% precision and 85% recall. The research highlights LLMs' potential in enhancing suicide risk detection.","['Natural Language Processing', 'Public health informatics', 'Machine learning and predictive modeling']"
91,Evaluating Temporal Characterization of EHR in BERT-based Model Architectures to Predict Multi-morbidity in Diabetes Patients,Harnessing the Power of Large Language Models in Health Data Science,"The Transformers architecture, notably BERT, revolutionized contextual learning and has been applied effectively to Electronic Health Records (EHR) due to similarities with natural language sequences. BERT efficiently constructs comprehensive EHR representations, capturing intricate medical history details. This study focuses on predicting major complications in diabetes patients, comparing prediction performance across diverse BERT architectures with various temporal representations. It also assesses the value of incorporating temporal data compared to context-time-unaware models like XG-Boost classifiers for risk prediction.","['Data-driven research and discovery', 'Data mining and knowledge discovery', 'Machine learning and predictive modeling']"
92,A Human-Centric Approach for Self-Service Analytics of Longitudinal Health Data,,"Efficient analytical access to longitudinal data for clinician scientists is crucial for translational medicine. However, typical analysis tasks require cross-sectional tabular data representations, so transformations need to be applied to longitudinal facts. However, established self-service data warehouse platforms offer limited aggregation functionalities for longitudinal data and specialized query languages are rather complex with a steep learning curve. We introduce a human-centric approach to longitudinal data transformation for self-service analytics, based on a domain-specific language, paired with a graphical editor and analytical tools. Our versatile framework integrates seamlessly with common data warehouse platforms. At Charité, the approach is used to provide oncologists with analytical access to clinical cancer registry data based on Informatics for Integrating Biology and the Bedside (i2b2).","['Data-driven research and discovery', 'Secondary use of EHR data', 'Advanced data visualization tools and techniques']"
93,Incorporating Natural Language Processing (NLP) into the EMERSE Information Retrieval System,Implementation Science and Deployment in Informatics: From Theory to Practice,"EMERSE, a search engine for clinical documents, has been enhanced to include an 'aligned-layer retrieval model' that allows for powerful search capabilities including negation and uncertainty status, semantic type labeling, case-sensitivity, and more. This was achieved by layering attributes over the indexed terms. Despite the index size increasing by 26%, it has not noticeably affected search time. These additions make the tool more efficient and comprehensive for non-technical clinical researchers.","['Informatics research/biomedical informatics research methods', 'Natural Language Processing', 'Data Integration']"
94,Beyond off-the-shelf Machine Learning: case for clinician-in-the-loop,Implementation Science and Deployment in Informatics: From Theory to Practice,Unlocking the potential of machine learning in healthcare demands a tailored approach that cannot be replaced by the recent advancements of “one-size-fit-all” large deep learning models and off-the-shelf solutions. In this paper we emphasize the need for more nuanced clinician-in-the-loop methodologies where clinical input should be considered in the development of every predictive model from the design stage using appropriate algorithms that allow this input beyond the mere formulation of the clinical question.,"['Learning healthcare system', 'Collaborative workflow systems', 'Machine learning and predictive modeling']"
95,Variability of Correlation Structures of Synthetic Data in Machine Learning Algorithms,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Synthetic data is computationally-derived data that is designed by algorithms to similarly represent real world data. It is often employed in the use of big data for machine learning algorithms, which are an increasingly common occurrence in the field of medicine. Synthetic data promises to provide more accessible, less expensive, and safer alternative that preserves the biological and medical meaning of the data to the use of real world data in healthcare. It has broad use in many new and advancing technologies that target predictive analytics and discovery analytics, among others. This research aims to determine how well machine learning (ML) models are able to maintain the integrity of variable correlation relationships between both synthetic and real data. It also aims to ascertain the presence or absence of biases within the artifact subspace structure of synthetic data when comparing queries by evaluating the efficacy of ML models trained on multiple MDClone-generated synthetic queries using Epic clinical breast cancer data to predict mortality. The findings indicate that tree-based models are most effective at maintaining feature relationships between real world and synthetically generated data. Additionally, a notable reduction in model performance when the model is trained on combined synthetic data, possibly due to the disturbance in the artifact subspace structure.","['Data sharing / interoperability', 'Health Information and biomedical data dissemination strategies', 'Machine learning and predictive modeling']"
96,Harnessing consumer wearable digital biomarkers for individualized recognition of postpartum depression within the All of Us Research Program,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","Postpartum depression (PPD) affects one in seven women, with detection challenges due to limited in-person visits and subjective screening methods. In women with PPD, intra-individual machine learning (ML) models using wearable-derived digital biomarkers were developed to distinguish between different phases of pregnancy (pre-pregnancy, pregnancy, postpartum without depression, and postpartum with depression (PPD)). Furthermore, individualized models outperform conventional ML approaches, highlighting personalized ML for early disease detection.","['Patient centered research and care', 'Mobile Health, wearable devices and patient-generated health data', 'Machine learning and predictive modeling']"
97,EchoGPT: Extracting Echocardiogram Entities using Large Language Models,Harnessing the Power of Large Language Models in Health Data Science,"Large Language Models (LLMs) can potentially standardize unstructured electronic health data with increased superiority to traditional natural language models. To assess their entity extraction capabilities, we compared the performance of zero-shot and few-shot learning of GPT-4 to extract and classify data from echocardiogram reports against gold standard clinician annotations. We found that a relaxed matching approach combined with either learning modality provided the best performance while ensuring data is transformed into a more standardized structure.","['Natural Language Processing', 'Secondary use of EHR data', 'Data/system integration, standardization and interoperability']"
98,Quantifying Pre-Hospital Delays Using Natural Language Processing,Harnessing the Power of Large Language Models in Health Data Science,"Longer prehospital delays can worsen outcomes, but wide-scale research is limited by lack of data. This study uses free-text clinical notes to extract information about the time elapsed between symptom onset and hospital arrival. I evaluate two approaches for end-to-end relation extraction of symptom-timing pairs: supervised machine learning with rule-based extraction and few-shot learning using large language models. Preliminary results suggest these methods hold promise for shedding light on delays in patient access to care.","['Natural Language Processing', 'Secondary use of EHR data']"
99,Network Graph Solutions for Data Pipeline Diagnostics,,"A key challenge for studies using electronic health records is the development of a data pipeline that maps the raw EHR data to an analytic dataset. Here we propose the use of directed bipartite graph models to visualize, interrogate, and refine the data engineering process. By promoting both transparency and data integrity, this diagnostic approach may help to improve the reproducibility and quality of studies that rely on EHR data.","['Reproducible research methods and tools', 'Advanced data visualization tools and techniques', 'Knowledge representation, management, or engineering']"
100,Pediatric Site Response to the Rapid Implementation of Decentralized Clinical Trials,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","The COVID-19 pandemic led to rapid implementation of telehealth services to conduct clinical research. Increased use of decentralized clinical trials (DCTs) has resulted in gaps in evidence-based outcomes and lack of standardization across research entities, making research sites hesitant to adopt DCT practices from sponsors and CROs. This research aims to identify and compare perceived barriers and facilitators for pediatric research sites conducting DCTs to other research sites for clinical research professionals.","['Clinical trials innovations', 'Patient centered research and care', 'Data/system integration, standardization and interoperability']"
101,Developing and Simulating a Clinical Machine Learning Model to Predict Acute Kidney Injury (AKI) in NICU Patients,,"Acute Kidney Injury (AKI) is an abrupt reduction in kidney function that is associated with higher mortality in the Neonatal Intensive Care Unit (NICU) and can lead to chronic kidney disease in infancy and early childhood. A timely diagnostic and management response to infants in the NICU who are at risk of AKI is critical. Our goal is to develop and implement an actionable machine learning model that continuously monitors patients and alerts providers if a patient is at high risk of developing AKI within the next 7 days.We collected a retrospective dataset of all patients in our own NICU spanning from 2017-2021, resulting in 5,395 patient encounters. We identified 486 episodes of AKI affecting 7% of patients. As machine learning features, we curated a set of 41 clinically interpretable variables based on prior literature and expert opinion. We chose a LASSO regularized logistic regression model to achieve full model explainability and reduce our features to a small set of clinically actionable risk factors. We trained and validated the model using 10-fold cross validation.Our final model consists of 12 risk factors and achieves a cross-validated ROC AUC of 0.74. Simulating the model in real-time, this corresponds to correctly predicting 60% of AKI episodes up to 7 days in advance when alerting on an average of 15% of NICU patients per day. We are currently working with our Epic informatics team to implement the model as part of our EHR.","['Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling', 'Implementation Science']"
102,Derivation and validation of a rule-based small cell masking tool for privacy protection in aggregated tabular reports,,"In biomedical research, protecting patient privacy is crucial for data sharing, whether patient-level or aggregated. Low patient counts in aggregated reports increases disclosure risk and compromises privacy. Therefore, masking low-patient counts is required. For complex reports with several thousand cells, manual masking is time-consuming, and human error-prone, warranting an automated solution. We have developed and validated an automated cell-masking tool in R which applies to one- two- and three-way frequency tables with high accuracy.","['Data security and privacy', 'Sustainable research data infrastructure', 'Clinical and research data collection, curation, preservation, or sharing']"
103,MyChart Messaging: Patient Expectations for Providers,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"MyChart messaging allows for convenient patient-provider communication. Portal messaging has grown recently, leading to increased physician workload. A patient-facing survey was administered to better understand patient expectations for provider message responses. Results show that patients prefer prompt responses from providers and providers are meeting these expectations, despite the large message volume they face. Patients also prefer unrestricted hours of messaging. Solutions to reduce burden must be created that do not limit patients' access to messaging.","['Health literacy issues and solutions', 'Clinical and research data collection, curation, preservation, or sharing', 'Stakeholder (i.e., patients or community) engagement']"
104,Using Large Language Models to Assess Scientific Portfolio of Research Projects in the All of Us Research Program,Harnessing the Power of Large Language Models in Health Data Science,"The All of Us Research Program is building the largest, most diverse research biorepositories. The program created Scientific Priorities Roadmap to characterize scientific inquiries researchers are investigating. We used large language model (LLM) to classify All of Us projects focusing on genetics, health equity, maternal/child health, healthy aging, and lifestyle/substance/behavioral. We compared LLM to 116 annotated projects. Health equity had highest F1 (0.67). Our analysis showed the possibility of using LLM to classify scientific projects.","['Natural Language Processing', 'Data mining and knowledge discovery', 'Implementation Science']"
105,Evolution of Phenotype Algorithms: A Case Study with Type 2 Diabetes,,"Phenotype algorithms are disseminated to the scientific community for adaptation and reuse, but little is known about how a phenotype algorithm is adopted and adapted for a new setting. Using type 2 diabetes mellitus as a case study, we reviewed a single phenotype algorithm’s 183 citations in PubMed, identifying 67 studies that implemented the algorithm in some form, with 21 of those making modifications. Common adaptations included adding ICD-10 codes and removing or relaxing criteria.","['EHR-based phenotyping', 'Secondary use of EHR data', 'Knowledge representation, management, or engineering']"
106,Enhancing COACH for Effective Hypertension Management: Executing Implementation and Deployment Strategies,Implementation Science and Deployment in Informatics: From Theory to Practice,"This study addresses the significant public health challenge of hypertension, which elevates the risk of cardiovascular disease. We introduce COACH, a web-based tool for hypertension care planning and patient self-management, and seek feedback on user interface design, alerts, notifications, and emergency instructions. Focus groups and clinic visits informed programming recommendations, prioritized using the MoSCoW method. Key COACH features, informed by the focus groups, include dual BP alerts and clear patient instructions.","['Patient centered research and care', 'Public health informatics', 'Implementation Science']"
107,Visualizing Computable Phenotypes,,"The Centralized Interactive Phenomics Resource (CIPHER) hosts novel visualization tools and thousands of phenotype definitions: https://phenomics.va.ornl.gov/web/. The tools are directly linked to the phenotypes within the knowledgebase. With a single click, users can explore phenotype details by navigating to the phenotype definition from the visualization. Users can also immediately navigate to the tool from the phenotype details. These visualizations promote interoperability and enhance the user experience by providing resources to examine, develop, and refine phenotypes.","['EHR-based phenotyping', 'Advanced data visualization tools and techniques', 'Data/system integration, standardization and interoperability']"
108,An efficient Python PheWAS tool for analysis on large-scale biobank data,,"With the rapid growth of genetic and healthcare data as well as computing infrastructure, association studies, such as the phenome-wide association study (PheWAS), have become powerful discovery tools in biomedical research. PheWAS is an analysis method to study gene-phenotype associations utilizing genetic and longitudinal electronic medical record data.[1] Previous packages have been developed for PheWAS analysis, however, the Python PheWAS package described here was written to fulfill the need for a tool that is easy to use while capable of handling biobank scale data efficiently.[2 3] References1. Denny JC, Ritchie MD, Basford MA, et al. PheWAS: demonstrating the feasibility of a phenome-wide scan to discover gene-disease associations. Bioinformatics 2010;26(9):1205-10 doi: 10.1093/bioinformatics/btq126[published Online First: Epub Date]|.2. Carroll RJ, Bastarache L, Denny JC. R PheWAS: data analysis and plotting tools for phenome-wide association studies in the R environment. Bioinformatics 2014;30(16):2375-6 doi: 10.1093/bioinformatics/btu197[published Online First: Epub Date]|.3. Kerley CI, Chaganti S, Nguyen TQ, et al. pyPheWAS: A Phenome-Disease Association Tool for Electronic Medical Record Analysis. Neuroinformatics 2022;20(2):483-505 doi: 10.1007/s12021-021-09553-4[published Online First: Epub Date]|.","['Data-driven research and discovery', 'Phenomics and phenome-wide association studies', 'Reproducible research methods and tools']"
109,Machine Learning Approaches to Investigate Association Between Overall Survival and Comorbidity and Concurrent Medications Use in Senior Prostate Cancer Patients,,"In the US, most cancers occur in senior patients having on average 3 comorbidities and taking 6 medications. The amount of confounding data needed to account for both disease-cancer and drug-cancer interactions overwhelms typical randomized clinical trials. This study leverages large-scale retrospective medical records at Moffitt for machine learning modeling of overall survival and feature analysis.","['Data-driven research and discovery', 'Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling']"
110,Is Your Mapping of Medications to a Standard Terminology Correct?,Implementation Science and Deployment in Informatics: From Theory to Practice,"Achieving semantic harmonization of medication data is critical for data interoperability. However, once a mapping from a local to a standard terminology is generated, a pressing question arises: How can we reliably assess the accuracy of this mapping? To address this challenge, we analyzed the behavior of selected attributes of medication concepts being mapped, augmenting the customary lexical comparisons.","['Data sharing / interoperability', 'Data quality', 'Secondary use of EHR data']"
111,Predicting Hospital Readmission for Patients with OSA and Other Comorbidities Using Natural Language Processing,,"Obstructive Sleep Apnea (OSA) is a prevalent sleep disorder associated with serious health conditions. Our project utilized the Blue Bert language model to identify informative tetragrams specific to OSA subphenotypes. Additionally, we trained a Logarithmic regression model for predicting hospital readmission and diagnostic codes among OSA and Atrial Fibrillation patients using unstructured discharge notes. Our results showed 0.82 AUC for OSA phenotype diagnosis, but future work is needed to improve hospital readmission performance.","['EHR-based phenotyping', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
112,Predictors of 30-Day Hospital Readmission After Atrial Fibrillation Admission: A 2017 Nationwide Readmission Analysis in the United States,,"Atrial fibrillation (AF), the most common cardiac arrhythmia, leads to 15% of AF patients experiencing readmissions within 30 days in the US. This study aimed to uncover all-cause 30-day readmission rate, readmission predictors, and performance of the predictive models using the 2017 Nationwide Readmission Database. A hierarchical mixed linear model was used on the best performing model to identify the predictors of readmission based on index admission. Among 281,035 AF adult patients surviving their initial hospitalization, 43,375 (15.4%) faced readmission within 30 days. Readmitted patients were predominantly older (median age 75 vs. 72) and more frequently female (55.6% vs. 52.2%), compared to those not readmitted. Comorbidities at the AF index event, like metastatic cancer, lymphoma, and severe renal failure predicted higher 30-day readmission rates. This underscores comorbidities' pivotal role in readmission risk, warranting further research for streamlined models to capture AF-related readmission factors within healthcare systems.","['Public health informatics', 'Outcomes research, clinical epidemiology, population health', 'Machine learning and predictive modeling']"
113,Use of Large Language Models to Automate the Risk-Stratified Screening Colonoscopy Interval Determination,Harnessing the Power of Large Language Models in Health Data Science,"We describe the use of LLMs to provide an automated screening colonoscopy interval when evaluated on synthetic data. 100 examples were randomly selected for the synthetic testing set. 3 prompts were created to test the ability to determine the correct screening colonoscopy interval. GPT 3.5 had a superior average performance (55%) compared to PALM (51%) and Dolly (3.5%). Subsequently, the performance of GPT 4 improved to 98%. Further evaluation using actual clinical data is required.","['Clinical decision support for translational/data science interventions', 'Natural Language Processing', 'Clinical and research data collection, curation, preservation, or sharing']"
114,Trans-Balance: Reducing Demographic Disparity for Prediction Models in the Presence of Class Imbalance,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,"Risk prediction, including early disease detection, prevention, and intervention, is essential to precision medicine. However, inappropriate use of risk prediction models can worsen health inequities, in that the systematic bias in risk estimation caused by the heterogeneity across different demographic groups can lead to inappropriate or misinformed treatment decisions. In addition, low incidence (class-imbalance) outcomes negatively impact the classification performance of many standard learning algorithms which further exacerbates the racial disparity issues. Therefore, it is crucial to improve the performance of statistical and machine learning models in underrepresented populations in the presence of heavy class imbalance. In this study, we leverage recent advances in imbalance learning, transfer learning, and federated learning to develop a new framework for bias-corrected models that borrow information across different cohorts without sharing individual patient data. We show that the proposed Trans-Balance framework improves upon existing approaches by explicitly accounting for heterogeneity across demographic subgroups and cohorts. We demonstrate the feasibility and validity of our methods through numerical experiments and a real application to a multi-cohort study with data from participants of four large, NIH-funded cohorts for stroke risk prediction.","['Informatics research/biomedical informatics research methods', 'Data Integration', 'Machine learning and predictive modeling']"
115,Optimal Duration for Steroid Therapy in Inflammatory Bowel Disease: A Causal Analysis using the UK Biobank,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,The submission is a poster.,"['Data-driven research and discovery', 'Machine learning and predictive modeling', 'Outcomes research, clinical epidemiology, population health']"
116,Fostering communication between parents and clinicians using behavioral visualizations of children with autism,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Autism Spectrum Disorder (ASD) is diagnosed in children with developmental and behavioral difficulties. The Centers for Disease Control and Prevention (CDC) states that 1 in 44 children in the United States have autism. Early diagnosis of autism can help parents and clinicians better plan interventions to help the child. Parents of the child need to understand the social behaviors of their child to help with the appropriate interventions. Communication between parents and clinicians is still an area of research that needs to be further studied. Several screening methods like the RapidABC (Rapid Attention Back and Forth Communication) protocol have made it difficult to generate a behavioral model that can help express micro and macro behaviors of the child at a glance. Tools like EnGaze and Plexlines can help visualize these social behaviors of the child. These visualizations use different colors to encode gaze, vocals, and gestures of the child in the form of bars and circles respectively. These visualizations can serve as a longitudinal record for multiple clinician visits and can be used to compare different types of behaviors. We have augmented the interfaces of these tools using an annotations bar for notes. We conducted interviews to understand parent-clinician communication surrounding these visualizations. We are also exploring the advantages and disadvantages of encoding behaviors using artificial intelligence techniques. Our goal is to foster parent-clinician interactions using behavioral visualizations of children who have autism.","['Data-driven research and discovery', 'Advanced data visualization tools and techniques', 'Stakeholder (i.e., patients or community) engagement']"
117,Institutional Characteristics Associated with Sharing and Accessing Electronic Health Record Data Centralized by the National COVID Cohort Collaborative (N3C) for COVID-19 Research,,"Clinical data sharing for research is crucial for timely real-world analyses. For example, the National COVID Cohort Collaborative (N3C) was established early 2020 to gather electronic health records (EHRs) across institutions for COVID-19 research. N3C is now one of the largest centralized US repositories of de-identified EHRs. Despite enormous success, some institutions do not share data. We tested institutional characteristics for associations with N3C data sharing to identify addressable barriers for future data sharing initiatives.","['Data sharing / interoperability', 'Data-driven research and discovery', 'Clinical and research data collection, curation, preservation, or sharing']"
118,Unsupervised Natural Language Processing to Identify Topics in Cancer Center Patient Portal Messages,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Patient portal messaging has surged, leading to increased workloads. We employed BERTopic, an NLP-based technique using BERT, to identify topic categories and frequencies in patient-generated messages sent to a cancer center from 2011 to 2023. Four hundred topics were detected from 2,280,851 messages, which were later condensed to 62. The most prevalent topics included expressing appreciation, messages about prescription, and scheduling discussions. NLP has efficiently identified real-world topics, suggesting potential applications for automating message routing.","['Natural Language Processing', 'Data-driven research and discovery', 'Data mining and knowledge discovery']"
119,Improving the Financial Sustainability of Telemedicine by Addressing Peritelehealth Administrative Tasks,,"The department of psychiatry has one of the highest proportions of telehealth at Penn Medicine; 73-76% of visits are conducted via telemedicine. The department, and other high telehealth users like it, experience many challenges around peri-telehealth administrative activities, such as collecting pre-visit payments. These problems have many downstream effects, including increased financial burden, and are attributed, in part, to the current telehealth platform which does not integrate with the electronic health record (EHR) system. Health system leadership decided to pilot a new/EHR integrated telehealth platform to address these challenges and wanted to determine whether such changes affected the provider and patient experience.","['Reproducible research methods and tools', 'Secondary use of EHR data', 'Implementation Science']"
120,Exploring the applicability of the pre-hospital electrocardiogram transmission system through the user-centered design,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","Pre-hospital electrocardiography is crucial for medical direction during patient transport and treatment post-arrival. Nonetheless, conducting 12-lead ECG tests in an ambulance and over long distances have both technical and human challenges. for solving the problems, we made a prototype transmission system for pre-hospital electrocardiography. and We simulated the prototype system through real-world users, involving two groups: EMTs/nurses and doctors. after simulation, they assessed usability by interviews and PSSUQ. Results showed relatively satisfactory system usefulness, but information quality is not satisfied. This study holds significance for enhancing system feasibility and gathering feedback from actual users. ultimately, we can suggest more better system than before.","['Collaborative workflow systems', 'Clinical trials innovations', 'Mobile Health, wearable devices and patient-generated health data']"
121,Patient2Trial: A Knowledge Guided Large Language Model-based System for Matching Patients to Clinical Trials,Harnessing the Power of Large Language Models in Health Data Science,"The recruitment of suitable patients for clinical trials is a critical aspect in evaluating new treatments and interventions. This study proposes Patient2Trial, a system that leverages the advanced GPT-4 model and domain knowledge to efficiently match patients to appropriate clinical trials. Patient2Trial is composed of three components: candidate retrieval, eligibility identification, and trial ranking. The first step of candidate retrieval involves filtering disease-specific trials, expanding patient information using GPT-4 and expert curated knowledge guidelines, and retrieving candidates trials from the filtered collection given an expanded patient information. The second step involves using GPT-4 to identify trial eligibility as well as to generate matching scores for each inclusion criterion of a candidate trial identified as eligible. The third step involves ranking the eligible trials based on the matching scores of inclusion criteria. The system was evaluated on 80 patient-trial pairs using synthetic patient templates covering multiple diseases. The results, reviewed by three independent clinicians, showed a promising NDCG@10 score of 0.9661 and an accuracy of 80%. Furthermore, GPT-4's reasoning descriptions were found to be 85% accurate. Patient2Trial effectively addresses the limitation of 'lack of medical domain-specific knowledge' pointed out in prior work.","['Natural Language Processing', 'Clinical trials innovations', 'Informatics research/biomedical informatics research methods']"
122,"Early Alerts, Timely Actions: Evaluating the Impact of the CONCERN Early Warning System on Reducing Sepsis Risk",,"The Communicating Narrative Concerns Entered by RNs (CONCERN) is an early warning system that identifies patients at risk of clinical deterioration by leveraging nursing documentation as a proxy of nurses' shifting surveillance. In this ancillary analysis from our cluster-randomized trial, we investigate CONCERN's influence on sepsis care trajectories, focusing on the time duration between CONCERN score changes and the initiation of sepsis-related clinical interventions. Preliminary findings show CONCERN”s potential to impact sepsis care management.","['Clinical decision support for translational/data science interventions', 'Data-driven research and discovery', 'Implementation Science']"
123,VIOLIN In 2024: 15 Years of Vaccine Resource Development,,"The Vaccine Investigation and Online Information Network (VIOLIN) is a comprehensive and integrative vaccine research database and analysis platform accessible at https://violinet.org. Initial in 2008, VIOLIN now includes over 4,550 vaccines targeting 216 pathogens and eight noninfectious diseases, including cancers and allergies. VIOLIN has since hosted >20 independent programs for vaccine research. While the majority of these VIOLIN programs are databases, many ontology- and bioinformatics-based methods and tools for transcriptome analysis or natural language processing (NLP) analysis have also been developed to dissect vaccine data and discover novel scientific insights. Key components of VIOLIN include various vaccine component databases (e.g., Protegen vaccine antigen knowledgebase, Vaxjo vaccine adjuvant database), knowledgebases for specific diseases such as CanVaxKB for cancers and Cov19VaxKB for COVID-19, vaccine immune factor database (VaximmutorDB) and associated gene expression analysis tool (i.g., VIGET), and vaccine literature search (VO-SciMiner), and vaccine design tool (Vaxign2). These tools facilitate the discovery of mechanistic patterns integral to protective antigens and effective vaccine-induced immune response. The Vaccine Ontology is employed to ensure standardization and integration within VIOLIN, which also hosts other ontologies, such as the Ontology of Vaccine Adverse Events (OVAE) and Vaccine Investigation Ontology (VIO). Collectively, VIOLIN stands as a robust and holistic hub for vaccine-related information.","['Data Integration', 'Ontologies', 'Data mining and knowledge discovery']"
124,Linking EHR Prescribing Data with Pharmacy Dispensing Records: A Method to Reduce Misclassification in Pediatric Antidepressant Prescriptions,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"EHR based medication data are limited by only observing prescription information. We developed an approach to link prescription data with fills data from SureScripts. Using pediatric antidepressant prescriptions as a use case, we assessed factors associated with fill completion and impact of using prescribed vs filled data in downstream analyses. 78% of children filled their prescription with demographic and clinical differences observed. Medication definition impacted downstream inference.","['Data/system integration, standardization and interoperability', 'Outcomes research, clinical epidemiology, population health', 'Drug discovery, repurposing, and side-effect discovery']"
125,Assessing the Impact of Activity Levels on Weight Change in Individuals with Obesity: Addressing Analytic Challenges in User Tracking Data,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","In a study of 368 individuals with obesity, we integrated Fitbit data with electronic health records (EHR) to analyze weight change in relation to activity levels. Challenges arose in defining data completeness for Fitbit users. Results revealed a positive correlation between activity intensity and weight loss, that was relatively robust to completeness definitions. The study emphasized both the potential and challenges of utilizing the tracking data to monitor weight change.","['Data Integration', 'EHR-based phenotyping', 'Mobile Health, wearable devices and patient-generated health data']"
126,Prevalence of Racial Disparity in the Performance of Prediction Models for Teenage Hospitalization,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,Racial biases associated with AI algorithms threaten to perpetuate the cycle of health disparity. A knowledge gap in AI fairness research in medicine comes from the lack of assessment of the prevalence of racial biases in health risk prediction models. This study trained models to predict teenage hospitalization using different sampling and learning algorithms. Our analyses found racial disparities in model performance to be common but not statistically significant.,"['Machine learning and predictive modeling', 'Ethical, legal, and social issues', 'Outcomes research, clinical epidemiology, population health']"
127,Conditions for Enhanced Rare Event Prediction with Multi-Label Learning,,"The application of deep learning models for rare disease prediction faces formidable challenges due to data scarcity and class imbalances. This study explores the potential of multi-label learning as a strategy to improve rare event predictions. Using synthetic datasets, we experimentally investigate the usage conditions for multi-label learning efficacy, revealing promising but nonlinear performance improvement with higher event relevance and secondary event rates. The findings lay groundwork for more targeted applications of multi-label learning for rare diseases.","['Reproducible research methods and tools', 'Data commons', 'Machine learning and predictive modeling']"
128,Trustworthy Artificial Intelligence in Patient-Centered Outcomes Research,,The Department of Health and Human Services Office of the Assistant Secretary for Planning and Evaluation aims to promote Trustworthy Artificial Intelligence in its portfolio of intradepartmental projects that build data capacity for patient-centered outcomes research (PCOR). An environmental scan and key informant semi-structured discussions with experts in AI were conducted to gather information on the implementation of Trustworthy AI principles in the context of PCOR and other healthcare research.,"['Patient centered research and care', 'Ethical, legal, and social issues', 'Outcomes research, clinical epidemiology, population health']"
129,Detecting Favorable Effect of Combination Therapies on cardiotoxicity,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Drug-induced cardiotoxicity represents a significant risk to patients, particularly when it results in lasting harm to the heart muscle. To mitigate risks and enhance treatment outcomes, combination therapies have gained attraction, offering the promise of increased efficacy, and reduced toxicity, with the underlying rationale of reducing required drug concentrations of individual drugs and poly-pharmacological effects. In this study, we proposed a systematic workflow aimed at detecting the favorable effect of combination therapies on cardiotoxicity, leveraging the data from the Food and Drug Administration Adverse Event Reporting System (FAERS), a valuable resource that compiles real-world, spontaneous reports of adverse drug events. We first identified 751 drugs with signals of cardiotoxicity from the AERS-DM based on the rationale of contrasting all the system organ class (SOC) level AEs of any drug in the AERS-DM. We then compared cardiotoxicity signals of drugs of interest between the scenarios of single drug uses and drug combinations. Results showed that out of the 751 drugs, 144 of them exhibited no signals of cardiotoxicity when used together in 1,153 different drug-drug combinations. Ad hoc validation was done for doxorubicin. The drug-drug pairs potentially mitigating cardiotoxicity can be freely accessible at https://github.com/OHNLP/Cardiotoxicity. In the future, we will prepare a knowledge-enhanced dataset for all available FAERS data and further validate the potential favorable effects of drug-drug pairs systematically.","['Public health informatics', 'Drug discovery, repurposing, and side-effect discovery', 'Outcomes research, clinical epidemiology, population health']"
130,Generating and Validating a Multi-Health System Pipeline to Obtain Social Drivers of Health Data,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,"There is a growing interest in linking external social drivers of health (SDOH) with electronic health record (EHR) data to understand how upstream factors may impact health. We developed a generalizable pipeline featuring DeGAUSS, an open-source geocoding tool, to enable acquisition and sharing of neighborhood-level SDOH data for patients from multiple health systems. In addition, we performed a validation of the geocoding results of DeGAUSS against a private third-party vendor. The pipeline was successfully implemented on a cohort of Duke patients resulting in SDOH data obtained for 98.0% of addresses. There was low disagreement (high concordance) between DeGAUSS and the third-party vendor FIPS assignments: 6.7% and 4.6% disagreement at the census block group and tract levels, respectively. At the census tract level, there were no significant differences in percent disagreement in FIPS classification among urban/rural strata, years, or ADI quintiles. However, disagreement proportion differed significantly by year and by urban/rural category at the census block group level, with larger disagreement in the rural category than in both micropolitan and metropolitan categories. This suggests that geocoding error present at this scale can be problematic. Our flexible data pipeline can facilitate the acquisition of location-based SDOH in a secure way that is suitable for cross-health system sharing. We are currently validating the pipeline in a multicenter research consortium, and in other surgical populations.","['Social determinants of health', 'Data sharing / interoperability', 'Clinical and research data collection, curation, preservation, or sharing']"
131,OncoOpenIE – an Expert-Based NLP System for Precision Oncology,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Capturing real world data (RWD) generated from oncology practice, especially clinical data available in electronic health records (EHR) has become critical to meet the urgent needs for precision oncology. To meet the needs of improving structured data capture in EHRs to augment the readiness of EHRs for cancer research and patient care, we initiated the development of an open natural language processing (NLP) system for precision oncology, OncoOpenIE as a baseline system. OncoOpenIE was developed by integrating expert knowledge engineering and sublanguage analysis of EHR data generated through precision oncology practice and research. It is freely available through the Open Health Natural Language Processing (OHNLP) (https://github.com/OHNLP/OncoOpenIE), and can be run through backbone (https://github.com/OHNLP/Backbone). In the future, we will finetune OncoOpenIE based on multi-site case studies, develop advanced NLP algorithms to expand the capability of the OncoOpenIE to extract more entities and relations. We will also adopt standards (i.e., The Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) and Findable Accessible Interoperable Reusable (FAIR)) to encode critical clinical information using context-aware learning strategies and an open collaborative development framework.","['Natural Language Processing', 'Secondary use of EHR data', 'EHR-based phenotyping']"
132,Cancer Risk Prediction and Prevention Among Older Adults,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Enhancing cancer preventive care is urgently needed for individuals with Alzheimer's disease and related dementias (AD/ADRD) who face cognitive and care challenges and are vulnerable to health disparities. By applying machine learning methods to electronic health records (EHRs) datasets from Michigan Medicine and the AllofUs program, our study aims to narrow the divide in comprehension, involvement, and compliance with cancer preventive care practice, with the goal of enhancing public health results and establishing the foundation for customized cancer prevention initiatives","['Secondary use of EHR data', 'Health Information and biomedical data dissemination strategies', 'Public health informatics']"
133,An Explainable Risk Prediction Model for Hospital-Wide Mortality (HWM) Leveraging OHDSI and XGBoost,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Hospital-Wide Mortality (HWM) prediction is vital in modern healthcare for timely interventions, better patient outcomes, and cost reduction. Existing in-hospital mortality models often lack performance, interpretability, and standardization, limiting their clinical practicality. We present XG-HWM, a high-performance risk prediction model with an AUC-ROC range of 0.9146-0.9163. XG-HWM forecasts Hospital-Wide Mortality after 24-hour inpatient stays, enhancing clinical data reliability through OHDSI Common Data Model mapping and medication normalization. Outperforming traditional and deep learning models, XG-HWM offers transparency with SHAP integration, establishing its critical role in early mortality prediction and patient safety in clinical settings.","['Clinical decision support for translational/data science interventions', 'Measuring outcomes', 'Machine learning and predictive modeling']"
134,"Applying CTME maturity for organizational improvement, a case study",,The University of Iowa leveraged a CTSA-developed maturity assessment for Clinical Trials Management Ecosystems (CTME) to establish processes to improve the organization’s clinical research processes. This poster describes how the CTME maturity assessment was done and how the results of the assessment are driving incremental steps to improve clinical research operations at the University of Iowa.,"['Clinical trials innovations', 'Digital research enterprise', 'Learning healthcare system']"
135,Driving Precision of Pediatric VTE Risk-stratification through Genetics,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Venous thromboembolism (VTE) is a major cause of morbidity and mortality, especially in hospitalized and acutely ill patients. While rarer in children than adults, pediatric VTE is increasing in occurrence. This study aims to meet the escalating need for risk-stratified VTE prophylaxis tools in pediatric clinical settings. Our objective is to create a robust tool by validating a VTE phenotype, then developing a polygenic risk score (PRS), which will summarize the influence of genetic variants on an individual's risk of VTE. We will assess whether adding the PRS to known clinical risk factors improves prediction of pediatric VTE cases. Currently, our study has identified cases and controls, and generated a predictive PRS using UK Biobank summary statistics. A PheWAS and logistic regression demonstrated the value of our PRS in prediction of VTE. Further work will include integration of the PRS into clinical risk stratification models.","['Genotype-phenotype association studies (including GWAS)', 'Phenomics and phenome-wide association studies', 'EHR-based phenotyping']"
136,Wise Instance Selection Algorithms Help Reduce Annotation Work in Multi-Task Multi-Class Urinary Tract Dilation Prediction,Harnessing the Power of Large Language Models in Health Data Science,"We present an investigation into optimizing annotation efficiency on a real-life task of predicting urinary tract dilation (UTD) using infant hydronephrosis ultrasound reports. Leveraging a cohort of 2,479 infants and a range of instance selection algorithms, including Temperature Scaling + Entropy and K-Means + Entropy, all our algorithms outperform the random sampling baseline and show stabilized performance with fewer annotations. K-Means + Entropy emerges as the top performer, maximizing information uncertainty and density.","['Natural Language Processing', 'Learning healthcare system', 'Machine learning and predictive modeling']"
137,Cloud Based Interactive Chatbot Solution to Increase Post Delivery Outreach,Implementation Science and Deployment in Informatics: From Theory to Practice,A crucial period in the lives of newborn babies and their mothers is the postnatal and postpartum period. Manual outreach for providing timely newborn and postpartum follow-up is extremely resource intensive and reaching out to every patient post-delivery is an extremely tedious task. We have developed an automated outreach solution using real-time EHR data to generate a list of patients to be contacted by an interactive chatbot within 24 hours of discharge to provide both educational and safety related content tailored to their birth experience.,"['Data mining and knowledge discovery', 'Data transformation/ETL', 'Implementation Science']"
138,Improving Large Language Model Performance on Domain-Specific Responses Utilizing Embeddings,Harnessing the Power of Large Language Models in Health Data Science,"Large language models (LLMs) have become an increasingly available resource for information retrieval and answering user questions. These systems are typically pre-trained on a static corpus of text data. This poses a potential limitation in domains with rapidly changing treatments, guidelines, and literature. In this investigation, we explore using embeddings to supplement LLMs with recently published research and measure model performance on domain-specific queries using this approach compared to other models.","['Data Integration', 'Natural Language Processing', 'Biomedical informatics and data science workforce education']"
139,Large Language Models for Translating Clinical Trial Eligibility Criteria into Structured Data,Harnessing the Power of Large Language Models in Health Data Science,"Matching cancer patients to clinical trials represents an important mechanism for empowering patients and expanding clinical research to a broader population. We evaluated the possibility of using LLMs for converting free-text clinical trial eligibility into structured eligibility criteria. Our goal was to develop ChatGPT prompts to translate trial eligibility text into a structured data format (MQL). Translation directly from free text to MQL was inefficient and frequently failed to separate criteria into discrete rules. Problem decomposition was used to break prompts into multiple smaller components. We qualitatively evaluated the results of these trials with a separate data set (n=5) of therapeutic clinical trials. We evaluated the number of predicates in the inclusion and exclusion criteria from ClinicalTrials.gov versus the MQL predicates. The system identified all inclusion criteria in 4 trials and missed 4 predicates from one trial, due to the OpenAI API limitation in number of tokens (16k) per request. In total, 101 out of 105 (96%) predicates were included in MQL. Due to the same limitation, the system didn’t classify the exclusion criteria in 2 trials. In the remaining 3, our implementation identified 100% of the predicates in the exclusion criteria (39 in total). We identified several key considerations. First, translation worked best independently by trial followed by a standardization process. Secondly, problem decomposition is an essential aspect to utilizing LLMs. By separating tasks into identifying inclusion/exclusion predicates and then managing the translation to a structured format, we provide data supporting the feasibility of the approach.","['Recruitment technologies', 'Data/system integration, standardization and interoperability', 'Clinical and research data collection, curation, preservation, or sharing']"
140,Designing a Consumer-centric Care Management Program by Prioritizing Interventions Using Deep Learning Causal Inference,Implementation Science and Deployment in Informatics: From Theory to Practice,"Care management is a team-based and patient-centered approach to reduce health risks and improve outcomes for managed populations. Post Discharge Management (PDM) is an important care management program at Elevance Health, which is aimed to reduce 30-day readmission risk for recently discharged patients. Current PDM program suffers from low engagement. When assigning interventions to patients, case managers choose the interventions to be conducted in each call only based on their limited personal experiences. In this work, we use deep learning causal inference to analyze the impact of interventions conducted on the first call on consumer's engagement in PDM program, which provides reliable reference for case managers to select interventions to promote consumer's engagement. With three experiments cross validating the results, our results show that consumers will engage more in the program if the case manager conducts interventions that require more nurse-patient interactions on the first call. On the other hand, conducting less interactive and more technical interventions on the first call leads to relatively poor consumer's engagement. These findings correspond to the clinical sense of experienced nurses and are consistent with previous findings in patient engagement in hospital settings.","['Clinical decision support for translational/data science interventions', 'Patient centered research and care', 'Machine learning and predictive modeling']"
141,Effects of De-identification on Named Entity Recognition of Emergency Department Reports,,"Although numerous performance studies of named entity recognition and de-identification have been conducted individually, to our knowledge no published studies have compared the effect of de-identification on NER of clinical text. We performed this study because our research medical records service will only release the results of NER (e.g., Unified Medical Language System concept codes, CUIs) on text that they have de-identified. We believe others may encounter similar issues. Our research medical records service obtained a random set of ED reports for 120 patients over three years from five UPMC hospitals in Allegheny County, Pennsylvania, and de-identified the reports using NLM Scrubber. They then applied Metamap Lite as an NER tool on both the identified and de-identified reports. The overall number of concepts found in the original compared to the de-identified reports was significantly different The precision and recall of NER on de-identified reports were 0.936 and 0.985, respectively. De-identification and NER are powerful text processing techniques that may interact adversely when used together. When feasible, we recommend that researchers perform a measurement study to understand which extraneous concepts to ignore when using de-identification tools in an NER pipeline. A suggestion to authors of NER tools is to include an option to ignore PHI placeholders output by de-identification tools to improve precision.","['Data transformation/ETL', 'Data security and privacy', 'Natural Language Processing']"
142,Rule-Based Natural Language Processing to Extract Clinical Trial and Research Study Enrollment History from Unstructured Notes,,"Clinical trials are vital for advancing care. However, a systematic approach to tracking trial participation across different facilities and sponsors has been lacking. We developed natural language processing (NLP) methods to extract study enrollment history, including enrollment status, consent date, and study title from information on clinical trial participation recorded in clinical notes in the electronic health record based on national Veterans Affairs electronic health record data. The method exhibited high test-set precision for enrollment status (0.94), consent date (0.97), and study title (0.87) and acceptably high recall (0.76, 0.70, and 0.84, respectively). From a single center, the classifier correctly identified 111 of 125 trial participants (88.8%) across 12 distinct trials. Our study demonstrates the feasibility of using NLP to capture trial enrollment from a nationwide healthcare system. This algorithm creates a novel data resource for analyzing and tracking trial enrollment at the population level.","['Clinical trials innovations', 'Natural Language Processing', 'Clinical and research data collection, curation, preservation, or sharing']"
143,Accelerating Precision Medicine Through Integration of Medical and Veterinary Electronic Health Record Data,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"The goal of this research is integrating veterinary and human health data to improve patient care. This investigation advances construction of datasets to allow such analyses. A proof-of-concept study was designed to determine the frequency of household medical record overlap between geographically-overlapping human and veterinary medical academic institutions. We examine the feasibility of developing a comprehensive interdisciplinary registry to investigate similarities in risk factors, diagnoses, and therapies for diseases shared by people and their pets.","['Clinical decision support for translational/data science interventions', 'Data Integration', 'EHR-based phenotyping']"
144,Performance Trade-Offs for the Safe Sharing of a Fully De-Identified SVM Model for Child Abuse and Neglect,Implementation Science and Deployment in Informatics: From Theory to Practice,"Natural language processing methods applied to unstructured clinical notes have the potential to improve early detection of child abuse and neglect (CAN) cases. However, sharing a CAN risk model between institutions raises ethical concerns that the model features may patients to new risks by including patient details. We report on training a model with de-identified notes and manually redacted n-gram (word) features to demonstrate a successful means for 'de-risking' models with limited impact on performance.","['Natural Language Processing', 'Data security and privacy', 'Ethical, legal, and social issues']"
145,Advancing Pharmacovigilance through Health System Collaborations: A Real-World Example of Methods for Supporting External Validation,Proactive Machine Learning in Biomedical Applications: The Power of Generative AI and Reinforcement Learning,"The use of electronic health records (EHRs) for predictive modeling has the potential to increase accuracy, strength, and efficiency in adverse event signal detection. Aspects of leveraging artificial intelligence driven predictive algorithms to detect adverse drug reactions are currently being explored in scientific research. One challenge in the methodology for the use of EHR data for predictive modeling and signal detection is connected to the need for separate data sources for the variety of external validations. This submission provides a real-world example of health system collaboration to support the external validation of predictive modeling algorithms in immunotherapy/checkpoint inhibitors.","['Collaborative workflow systems', 'Biomedical informatics and data science workforce education', 'Drug discovery, repurposing, and side-effect discovery']"
146,"Three Decades of Federal Regulations: Impact on the RWD Infrastructure, Challenges and Current Opportunities",Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,How legislative changes over the last three decades have driven key infrastructure developments for RWD. Starting with the HIPAA in 1996 and the ARRA of 2009 significantly impacted the collection and use of healthcare data. ARRA provided funding to invest into infrastructure and information technology along with establishing ONC and lead to HITECH Act. Understanding the history of how the regulatory environment influenced RWD helps researchers anticipate and engage in future endeavors for RWD ecosystem.,"['Data quality', 'Data standards', 'Ethical, legal, and social issues']"
147,Monitoring Generative AI Solutions For Corrective Action,Proactive Machine Learning in Biomedical Applications: The Power of Generative AI and Reinforcement Learning,"In the realm of healthcare services utilizing generative AI solutions, it's vital to maintain strict control over the training data that shapes these solutions. The training content plays a direct role in influencing the performance and ethical considerations of AI models. Implementing a corrective action framework capable of evaluating the training data can detect potential bias or misinformation in the AI solutions, triggering alerts when necessary.","['Education and Training', 'Health Information and biomedical data dissemination strategies', 'Machine learning and predictive modeling']"
148,Using a semi-supervised approach for predicting diagnosis of Heart Failure in MIMIC-IV dataset,Citizen Science and Democratizing AI and Informatics for Healthcare,"We developed a classifier for diagnosing Heart Failure (HF) one month before admission, using semi-supervised approach, where we used the number of heart failure diagnosis in the health record to create a silver standard for developing models. The best classifier achieving an AUROC of 0.81 and has potential to facilitate early diagnosis of HF.","['Secondary use of EHR data', 'Data-driven research and discovery', 'Machine learning and predictive modeling']"
149,Preventing Wrong-Drug and Wrong-Patient Errors with Indication Alerts in CPOE Systems,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Delivering the correct medication to the correct patient is critical in medication safety, yet wrong-drug and wrong-patient errors persist. Linking medication orders to patient problem list diagnoses helps prevent wrong-drug and wrong-patient errors. To improve problem list documentation and decrease the rate of errors, we implemented indication alerts to notify prescribers when ordered drugs do not match the patients’ problems and find that alerts increase the rate of problem list placements and self-intercepted ordering errors.","['Secondary use of EHR data', 'Learning healthcare system', 'Reproducible research methods and tools']"
150,Assessing Utilization of Patient-Reported Outcomes in the Context of Virtual Reality Facilitated Randomized Controlled Trials: A Scoping Review,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","Virtual Reality (VR) is an emerging class of wearable technology in Randomized Controlled Trials (RCTs)1. Patient-Reported Outcomes (PRO) aid in the standardization of data collection in trials with a VR component, benefitting the translation of representative outcomes into real-world healthcare solutions. Through a scoping review, our aim is to showcase current VR practices in RCTs and prompt continued exploration of PRO as a trial outcome measure in VR facilities trials.","['Clinical trials innovations', 'Data standards', 'Public health informatics']"
151,Assessing the Performance of Large Language Models in Identifying Hormonal Therapy Medication Consumption from Online Discussions,Harnessing the Power of Large Language Models in Health Data Science,"This study assesses Large Language Models (LLMs) in extracting hormonal therapy information from online forums. Posts from breastcancer.org were annotated and analyzed using LLMs, including ChatGPT. Using Jaccard metrics, ChatGPT showed the highest accuracy in identifying key elements. The study suggests LLMs can help healthcare professionals and researchers extract valuable information from online health discussions without the need for natural language processing expertise.","['Natural Language Processing', 'Data mining and knowledge discovery', 'Drug discovery, repurposing, and side-effect discovery']"
152,Identification of Clinical Features for Predicting Prolonged ICU Stay for Pneumonia Patients,,"The length of stay (LOS) in the Intensive Care Unit (ICU) holds significant importance in patient management and resource allocation. The COVID-19 pandemic intensified the challenges associated with ICU allocation, resulting in crises in hospital management particularly in cases of pneumonia. This study employed various machine learning models to predict extended ICU stays for pneumonia patients. XGBoost delivered the best performance with an F1 score of 0.80 and an AUC score of 0.68. Key predictors were identified, including COVID-19 status, ECMO use, and GCS scores. Additionally, the model highlighted external transfer status as an admission factor often overlooked in ICU stay prediction. These insights enable early risk assessment and targeted interventions, potentially improving patient outcomes and ICU management.","['Data-driven research and discovery', 'Machine learning and predictive modeling']"
153,Opioid and Antimicrobial Prescription Patterns During Emergency Medicine Encounters Among Uninsured Patients,Fairness and Disparity in Health and Biomedical Informatics: Addressing Inequities through Innovation,"This study examined opioid and antimicrobial prescribing patterns among uninsured patients seeking emergency medical care. Over a two-year period, we studied prescribing patterns for opioid pain medication, non-opioid pain medication, and antimicrobials. We examined 68,969 Emergency Department (ED) visits during the two-year study period. Uninsured patients were younger, had fewer comorbidities, less acute ED complaints, and were less likely to have multiple ED visits. Accounting for these differences, uninsured patients were less likely to receive an opioid prescription (OR = 0.93, p = 0.063), more likely to receive a non-opioid pain medication prescription (OR = 1.90, p < 0.001), and less likely to receive an antimicrobial (OR 0.96, p = 0.457). We use a combination of contributing factors including a patient’s housing status, ethnicity, age etc. to predict opioid and antibiotic prescription patterns for uninsured patients using machine learning (ML) algorithms. The most impactful contributing factors in predicting the outcome of visits were housing status, comorbidities, and ED recidivism.","['Social determinants of health', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
154,Evaluating AI Reporting Guideline Adherence of Medical AI Research Using Large Language Model-based Systems,Harnessing the Power of Large Language Models in Health Data Science,"In recent years, artificial intelligence (AI) has been transforming healthcare with advanced models for risk prediction, disease classification, as well as diagnosis, prognosis, and treatment. However, there are still major challenges regarding the deployment of AI models in healthcare due to inadequate transparency of the prediction, and potential bias. To ensure a certain level of transparency and fairness of the medical AI models, reporting guidelines such as TRIPOD (Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis), MINIMAR (MINimum Information for Medical AI Reporting), CONSORT (The consolidated standards of reporting trials) have been proposed and adopted by many publishers.3 However, it is still challenging for publishers, editors, and reviewers to manually check the AI model-related manuscripts against these reporting guidelines. Large language models (LLMs) such as ChatGPT have recently gained traction due to their robustness and accuracy in answering various types of questions. Therefore, in this study, we aim to use LLM-based systems to automatically evaluate the adherence of AI papers against the TRIPOD reporting guidelines and analyze the areas in which LLMs cannot be used to evaluate TRIPOD reporting guidelines adherence for real-world medical AI publications.","['Open Science for biomedical research and translational medicine', 'Data mining and knowledge discovery', 'Machine learning and predictive modeling']"
155,Lessons Learned from Implementing Genomic Indicators at Learning Health System Hospital,Implementation Science and Deployment in Informatics: From Theory to Practice,"Many institutions with a clinical pharmacogenomics (PGx) program recognize the value of clinical decision support (CDS) in aiding the clinical translation of PGx results. However, commercial EHR vendors have only recently developed systems specifically designed to facilitate the implementation of PGx CDS. This poster highlights the advantages and lessons learned from implementing genomic indicators, a PGx phenotype repository built into the EHR, at an institution with a well-established PGx program.","['Clinical decision support for translational/data science interventions', 'Pharmacogenomics', 'Implementation Science']"
156,Architectural Considerations for a One Health Informatics Ecosystem,Integrating Multi-Modal health Data to Enhance the Power of Informatics,"Health is often determined by a complex interaction between humans, animals and the environment. The One Health approach is being considered for obtaining a comprehensive understanding of zoonotic disease and antimicrobial resistance. Modern data systems, therefore require to ingest, integrate and analyze these diverse data. In this study we perform a domain analysis of One Health to propose a reference architecture for an informatics platform, and identify its key characteristics.","['Public health informatics', 'Data/system integration, standardization and interoperability', 'Exposome and data integration']"
157,Assessment of Data Quality in the EHR – Discrete Data Missingness of Pancreatic and Breast Cancer Patients in UC Health’s EHR,,"This study investigates missing data in electronic health records for breast and pancreatic cancer patients. We compare missing data elements between 2019 and 2022 in the UC Health Epic EHR and contrast them with the Tumor Registry as a pseudo-control group. Results reveal significant disparities across demographics, social, biomarkers, and cancer staging categories. This study highlights the need for improved discrete data quality in electronic health records, impacting clinical care and research.","['Data quality', 'Sustainable research data infrastructure', 'Cohort discovery']"
158,Unveiling Patterns and Insights in Multiple Myeloma Studies: A Large Language Model Approach to Clinical Trial Analysis,Harnessing the Power of Large Language Models in Health Data Science,"In this study, we utilized a large language model to extract granular level data from 263 multiple myeloma clinical trials, concentrating on CAR-T cell therapy, bispecific antibody/BiTE, and antibody-drug conjugates. With precision at 94.92%, recall at 95.58%, and an F1 score of 95.16%, we extracted over 80 data elements. Our analysis unveiled disparities in adverse events, offering insights for clinical decisions and facilitating data-driven treatment comparisons, enhancing clinical trial comprehension.","['Clinical trials innovations', 'Data-driven research and discovery', 'Natural Language Processing']"
159,Figma-Powered Dashboard Prototype for Hearing Aid Device Comparison,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","Hearing loss is a life-altering condition that affects millions of people, yet there is no existing platform where consumers can search through all commercially available, FDA-registered hearing aid devices. With the CLEARdashboard – Consumer Led Evidence - Amplification Resources dashboard, users are able to compare and contrast all available over-the-counter hearing aids and make informed decisions about which hearing aids are best suited for them. The dashboard prototype was created using Figma, a cloud-based design and prototyping tool, using input from an advisory panel consisting of the targeted demographic. With Figma tools, the dashboard prototype provides an interactive environment for users to explore all hearing aid options and compare their specifications.","['Health literacy issues and solutions', 'Advanced data visualization tools and techniques', 'Mobile Health, wearable devices and patient-generated health data']"
160,Statin Adverse Drug Event Modeling and Prediction Using a Clinical Data Warehouse,,"Background: Cardiovascular disease (CVD) is the leading cause of clinical morbidity and mortality in the United States and worldwide. Fortunately, a number of therapies including lipid-lowering statin drugs have proven to be effective in preventing or treating cardiovascular disease. Statin therapies lower cholesterol, one of the key risk factors in cardiovascular disease. However, statin related symptomatic adverse drug events (ADEs) limit the benefits of statin therapies and can negatively impact treatment management. It is then of primary interest to understand and prevent the occurrence of statin related ADEs among statin users if we were to reap the full benefits of statin therapies.Objective: To facilitate the detection and surveillance of statin ADEs in electronic medical record repositories by leveraging statin data, International Classification of Diseases (ICD) diagnosis codes, laboratory data, clinical notes, and advanced analytic tools.Methods: Using advanced analytics tools in data science and machine learning we developed solutions that are easily reproducible and replicable. We primarily developed tree based ensemble models and best practice approaches for the detection and surveillance of adverse drug events in general and statin related adverse drug events in particular.Results: We developed algorithms for the detection of statin related myopathy and rhabdomyolysis, disease of the liver, and renal disease. These algorithms can be used on any data with similar features for the detection of potential statin related ADEs. In the same token, we also developed tools for clinical data cohort quality improvement and adverse drug events reporting.","['Clinical decision support for translational/data science interventions', 'Informatics research/biomedical informatics research methods', 'Machine learning and predictive modeling']"
161,A Comparison of Google and ChatGPT for Automatic Generation of Health-related Multiple-choice Questions,Harnessing the Power of Large Language Models in Health Data Science,"Accessible content is important for patient health literacy in a range of mediums. Critical to producing accessible content is an understanding of what characteristics affect understanding and comprehension. To answer this question, we are producing a large corpus of health-related texts with associated questions that can be read or listened to by study participants to measure the difficulty of the underlying content, which can later be used to better understand text difficulty and user comprehension. To this goal, in this paper, we examine methods for automatically generating multiple-choice questions using Google’s related questions and ChatGPT. We compare both the question quality as well as the suggested wrong answers using automated metrics and two user studies. Overall, we find both algorithms generate reasonable questions that are complementary. Google questions use more accessible language and are easier to answer while ChatGPT questions appear easier, but are more difficult to answer and have better coverage over the entire text. For wrong answer generation, we find ChatGPT produces higher quality wrong answers that are more likely to be good distractors and are more closely related to the text content. We recommend both questions as options for studies with wrong answers generated by ChatGPT.","['Natural Language Processing', 'Health literacy issues and solutions', 'Data mining and knowledge discovery']"
162,Approaches to Data Quality Improvement in the Development of a Data Bank for Emerging and Re-emerging Infectious Diseases,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Our databank project collects clinical data from electronic medical records and medical claims information from medical accounting systems. By validating data obtained from different systems for the same medical practice, we propose a way to improve the quality of data when building a clinical registry.","['Clinical trials innovations', 'Secondary use of EHR data', 'Clinical and research data collection, curation, preservation, or sharing']"
163,Quantifying digital health documentation in real-world clinical care,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","A data-driven approach is taken to characterize digital health terms documented in over 100 million clinical notes from a large, academic hospital. Digital health terms were frequently documented in endocrinology and cardiology departments, and were primarily found in clinical notes of younger patients who self-reported as “White” and English speaking.","['Natural Language Processing', 'Data mining and knowledge discovery', 'Mobile Health, wearable devices and patient-generated health data']"
164,Characterizing Dynamics of Vital-Sign Signals Using Switching State Space Modeling to Assess Fluid Responsiveness in ICU Patients,,"Fluid responsiveness is crucial when administering fluids to patients, as it must be tailored to the patient's personal needs and medical state. Traditional 'one-size-fits-all' approach to patient treatment often falls short of achieving optimal outcomes. To address this, our main goal is to create a robust machine-learning algorithm to offer valuable insights to healthcare professionals making treatment decisions. Specifically, we aim to explore whether the state representation derived from the AR-HMM (Autoregressive Hidden Markov Model) can predict fluid responsiveness in various scenarios using minute-by-minute, high-resolution data from PhysioNet MIMIC III. Ultimately, this research aims to uncover dynamic markers and states indicative of various treatment outcomes.","['Data mining and knowledge discovery', 'Clinical decision support for translational/data science interventions', 'Machine learning and predictive modeling']"
165,Linking Home Environments and Health through Computer Vision,"Telehealth, Wearable Devices, and Patient-Generated Health Data: The New Frontiers of Informatics","The impact of daily environments on health and behavior is well-acknowledged, yet quantifying environments individually and extensively remains a challenge. In this study, we use computer vision (Faster R-CNN) to detect objects in 14000+ images of the home environments of 1,101 participants. We then fit a Latent Dirichlet Allocation to the detected objects to identify 25 distinct scene types. Our findings reveal associations between specific scene types and self-reported measures of psychosocial health, including stress.","['Data-driven research and discovery', 'Public health informatics', 'Advanced data visualization tools and techniques']"
166,Analyzing Age-Related Differences in Glioblastoma Disease Trajectories Through Dynamic Time Warping of Electronic Health Record Data,,"Glioblastoma, the most common primary malignant brain tumor in adults with a median survival of only 8 months, has poorer outcomes in elderly patients. However, little investigation exists into differences between the temporal progression of clinical course in old and young GBM patients. Dynamic time warping of diagnosis codes from electronic health records can be leveraged to generate longitudinal patient disease trajectories. Age-stratifying these trajectories allows for examination of age-related differences in glioblastoma clinical course.","['EHR-based phenotyping', 'Secondary use of EHR data', 'Machine learning and predictive modeling']"
167,"Wiping Fingerprints: Using Synthetic Data to Create a Secure, Shareable Merged Dataset",Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"There is a growing need for combined data sets that can better represent individuals’ clinical status. However, data fingerprints in individual data sets creates a privacy risk when the data sources are linked across patients. Synthetic data may be helpful in protecting privacy for merged datasets. We studied the ability of synthetic data to remove data fingerprints from data sources used in a Privacy-Preserving Record Linkage (PPRL) study. We created a unique identifier or fingerprint for each record from a combination of biomedical data features. We then used a weighted Euclidean distance calculation to compute a fingerprinting distance between individuals. The results showed that fingerprints are easily identified without synthetic data, but the application of synthetic data generation removes the data fingerprint such that inferring the correct record would be impossible. Our study indicates that it is possible to mitigate the risk of re-identification while enabling valuable data integration for research.","['Data security and privacy', 'Sustainable research data infrastructure', 'Secondary use of EHR data']"
168,LIVES: An Interactive Living Evidence Synthesis System for Systematic Review and Meta-Analysis,Implementation Science and Deployment in Informatics: From Theory to Practice,"Systematic reviews (SR) and meta-analyses (MA) are invaluable tools for aggregating research findings and offering decision-makers more precise effect estimates, surpassing the limitations of individual studies. However, they confront several noteworthy challenges, for instances,1. Time-Consuming Process: Conducting SRMAs is a labor-intensive endeavor, typically demanding an average of 67 weeks to complete, which can strain resources and hinder timely decision-making.2. Rapid Obsolescence: SRMAs swiftly lose relevance as they struggle to keep up with the constant influx of new evidence, potentially rendering their conclusions outdated.3. Limited Information Depth: Traditional SRMAs often rely on static tables and figures, which can restrict the comprehensive presentation of critical information, hampering their utility etc. A promising remedy lies in adopting a 'living systematic review' approach anchored in standardized protocols. This innovative approach allows for the continuous updating of study findings through an iterative pipeline, significantly reducing the time needed to disseminate new insights. Embracing living systematic reviews holds the potential to overcome many of the challenges inherent in traditional SRMAs, making evidence synthesis more dynamic, accessible, and relevant to the evolving landscape of research and decision-making.","['Clinical decision support for translational/data science interventions', 'Clinical trials innovations', 'Informatics research/biomedical informatics research methods']"
169,Using Electronic Health Records to Compare Past-Year Mental Health Diagnoses Among Patients with Intentional or Unintentional Drug Overdoses,Real-World Evidence in Informatics: Bridging the Gap between Research and Practice,"Differentiating intentional and unintentional overdoses using large-scale, real-world electronic health records (EHRs) remains under-investigated. This retrospective analysis leveraged EHRs between 2010-2019 from the PCORI-funded INSIGHT Clinical Research Network. The findings, based on a sample of 57,798 patients, revealed that those with intentional overdoses exhibited significantly higher rates of past-year substance use disorders, suicidal ideation/attempt, and psychiatric disorders compared to those with unintentional overdoses. These results highlight the intricate relationship between suicidal behavior and overdose.","['Measuring outcomes', 'EHR-based phenotyping', 'Public health informatics']"
170,Large Language Model-based Natural Language Processing to Extract PD-L1 Expression from Clinical Notes,Harnessing the Power of Large Language Models in Health Data Science,"Introduction: A difficulty in using PD-L1 expression to predict a patient’s response to and eligibility for immunologic treatments is that PD-L1 expression status is typically found in unstructured clinical notes increasing the difficulty of clinical research. Manual annotation is a lengthy and resource-intensive process.Methods: We developed and evaluated a transformer Large Language Model-based natural language processing (NLP) tool to extract PD-L1 expression values from the nationwide Veterans Affairs electronic health record system and label them with the type of test and units. Results: In this study, using the technique of selecting notes according to a regular expression, 3843 clinical notes were analyzed corresponding to lab results obtained for 594 patients. The average cohen kappa score of the annotations by the pairs of annotators was 0.71. We selected between annotations randomly. Using the scikit-learn Python library, we determined that the SciBERT model that classified PD-L1 expression by test and unit had a weighted precision of 0.79 and recall of 0.77. The precision and recall for each label varied.Conclusion: We have developed a model that allows us to not only extract PD-L1 values but also allows researchers to predict the type of PD-L1 lab performed and the units of the value. By providing an expedient method to extract this PD-L1 expression data from clinical notes, we further support population-level studies in cancer immunotherapy.","['Natural Language Processing', 'Informatics research/biomedical informatics research methods', 'Informatics for cancer immunotherapy']"
